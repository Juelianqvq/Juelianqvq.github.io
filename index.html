<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hexo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/07/16/LLM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/07/16/LLM/" class="post-title-link" itemprop="url">LLM</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-07-16 00:46:38" itemprop="dateCreated datePublished" datetime="2023-07-16T00:46:38+08:00">2023-07-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-02-06 12:50:08" itemprop="dateModified" datetime="2024-02-06T12:50:08+08:00">2024-02-06</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>– [1.LLM](# 1.LLM)</p>
<p>– [2.vLLM](# 2.vLLM)</p>
<p>– [3.Attention 优化](# 3.Attention 优化)</p>
<p>– [4.TensorRT-LLM](# 4.TensorRT-LLM)</p>
<p>– [5.lmdeploy](# 5.lmdeploy)</p>
<p>– [6.Coroutine &amp; Thread &amp; Process](# 6.Coroutine &amp; Thread &amp; Process)</p>
<p>– [7.Frontier](# 7.Frontier)</p>
<p>– [8.Triton](# 8.Triton)</p>
<p>– [9.CUDA](# 9.CUDA)</p>
<p>– [10.Quantization](# 10.Quantization)</p>
<h4 id="1-LLM"><a href="#1-LLM" class="headerlink" title="1.LLM"></a>1.LLM</h4><p>TPS QPS 并发数 吞吐量: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/337708438">https://zhuanlan.zhihu.com/p/337708438</a></p>
<p>2023 技术总结: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/675287417">https://zhuanlan.zhihu.com/p/675287417</a></p>
<p>2024 技术展望: <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/637480772/answer/3351110317">https://www.zhihu.com/question/637480772/answer/3351110317</a></p>
<p>内存带宽和cpu算力简单计算: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/661062002">https://zhuanlan.zhihu.com/p/661062002</a></p>
<p>前沿6问LLM推理: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/670980266">https://zhuanlan.zhihu.com/p/670980266</a></p>
<p>Cache miss &amp; 分块矩阵一致性: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/342923482">https://zhuanlan.zhihu.com/p/342923482</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">因为a[0][0]本身就不在缓存中，所以肯定有一次 cache miss 啊</span><br></pre></td></tr></table></figure>

<p>fp32 fp16 bf16: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/667163603">https://zhuanlan.zhihu.com/p/667163603</a></p>
<p>device_map&#x3D;’auto’ 不然多卡会卡死</p>
<p>Transformer-1: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/662489503">https://zhuanlan.zhihu.com/p/662489503</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">正余弦交替的位置编码只与偏移量k有关，这意味着两个正弦位置嵌入的点乘可以反应两个tokens的距离，且该距离对称</span><br></pre></td></tr></table></figure>

<p>Transformer-4: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/662624035">https://zhuanlan.zhihu.com/p/662624035</a> 手撕多头</p>
<p>Transformer-3: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/662900859">https://zhuanlan.zhihu.com/p/662900859</a> paged attention 清晰图解</p>
<p>国内 LLM 面经: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/657826357">https://zhuanlan.zhihu.com/p/657826357</a></p>
<p>Nvidia 面经: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/658609960">https://zhuanlan.zhihu.com/p/658609960</a></p>
<p>HPC面试: </p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/634557901">https://zhuanlan.zhihu.com/p/634557901</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/663917237">https://zhuanlan.zhihu.com/p/663917237</a></p>
<p>LLM 面经: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/672632008">https://zhuanlan.zhihu.com/p/672632008</a></p>
<p><strong>模型侧</strong></p>
<p>Scaling law: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/669193585">https://zhuanlan.zhihu.com/p/669193585</a></p>
<ul>
<li><input disabled="" type="checkbox"> ChatGLM1&amp;2 &#x2F; Llama1&amp;2 mask: <a target="_blank" rel="noopener" href="https://github.com/THUDM/ChatGLM2-6B/issues/535">https://github.com/THUDM/ChatGLM2-6B/issues/535</a></li>
</ul>
<p>Llama 1&amp;2 模型结构: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/636784644">https://zhuanlan.zhihu.com/p/636784644</a></p>
<p>Decoding: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/631847634">https://zhuanlan.zhihu.com/p/631847634</a></p>
<p>Bloom单机版: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/625911234">https://zhuanlan.zhihu.com/p/625911234</a></p>
<p>Bloom TP版: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/626444817">https://zhuanlan.zhihu.com/p/626444817</a></p>
<p>AR AE: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/163455527">https://zhuanlan.zhihu.com/p/163455527</a></p>
<p>训练显存占用: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/650846284">https://zhuanlan.zhihu.com/p/650846284</a></p>
<p><strong>推理侧</strong></p>
<p>LLM推理优化探索: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/653735572">https://zhuanlan.zhihu.com/p/653735572</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int4 分块，kv cache fp8 存储</span><br><span class="line">kv cache 显存占用: b * (s + l) * h * n * 2 * 2</span><br></pre></td></tr></table></figure>

<p>混合精度: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/604764475">https://zhuanlan.zhihu.com/p/604764475</a></p>
<p>为何不用4090: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/655402388">https://zhuanlan.zhihu.com/p/655402388</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Adam需要用fp32来计算，fp16误差太大，容易不收敛。</span><br><span class="line">每个参数需要存4字节的32位版本（模型forward是fp16，optimizer是fp32，mixed-precision）以及4字节的momentum和4字节的variance，共12字节。SGD可以不存variance，只需要8字节。</span><br><span class="line"></span><br><span class="line">pipeline不可取: </span><br><span class="line">1)中间状态存储容量巨大，经过大量流水级后才会被用到(一共N个流水级，N-1个forward + N-1个backward)</span><br><span class="line">2)相邻流水级之间需要通信，级数越多，通信的总数据量和总延时就越高</span><br><span class="line">3)batch_size需要等于transformer里的层数，pipeline才能流动起来，再乘以dp的并行数，batch_size会很大，影响收敛速度以及收敛后的精度</span><br></pre></td></tr></table></figure>

<p>推理框架概述: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/659792625">https://zhuanlan.zhihu.com/p/659792625</a></p>
<ul>
<li><input checked="" disabled="" type="checkbox"> LLM部署代价评估: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/658868628">https://zhuanlan.zhihu.com/p/658868628</a></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">fp16 312 TFlops/s / 1350 GB/S = 231</span><br><span class="line">2blh * sizeof(data) / bandwidth 计算耗时</span><br><span class="line">计算受限之前都可以做w8，也就是2b&lt;Imax（fp16占满带宽，int8降半）;之后可考虑w8a8</span><br><span class="line">batch size = (GPU显存 - W模型) / KVcache显存</span><br><span class="line"></span><br><span class="line">优化建议:</span><br><span class="line">KVcache 8bit化对准确率几乎无损，并且成倍提升attention部分速度，对增加并发帮助最大</span><br><span class="line">如果处于访存受限区域，将权重8bit化，对准确率接近无损，提高矩阵乘的计算强度</span><br><span class="line">如果仍然访存受限，考虑权重4bit化，准确率可能有损，可用分块分组量化或者非线性量化的方式缓解，进一步提高矩阵乘的计算强度</span><br><span class="line">如果已处于计算受限区域，使用a8w8的提高计算性能</span><br><span class="line">TP策略调整，增加TP维度提高并发和GEMM计算强度，直至达到单机上限或跨越计算受限区间</span><br><span class="line"></span><br><span class="line">** 5.1 总并发度 延迟 最终吞吐量公式 **</span><br></pre></td></tr></table></figure>

<ul>
<li><input checked="" disabled="" type="checkbox"> 推理优化综述: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/656485997">https://zhuanlan.zhihu.com/p/656485997</a></li>
<li><input disabled="" type="checkbox"> 推理优化论文算法: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/660986039">https://zhuanlan.zhihu.com/p/660986039</a></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">显存优化:  KVcache 避免重复运算</span><br><span class="line">自回归特点: 每次推理只预测单个token,当前轮输出token与历史输入tokens相拼接作为下一轮的输入</span><br><span class="line">cache_per_token = 2 * 2 * n_layer * n_head * d_head * dtype_size</span><br><span class="line">total_cache = batch * context_length  * cache_per_token</span><br><span class="line">预填充阶段 用prompt计算第一个token GEMM 计算密集</span><br><span class="line">解码阶段 第二个输出token到最后一个token GEMV 访存密集</span><br><span class="line"></span><br><span class="line">算子融合: 1）LN+QKV 2）Attention 3）残差+LN+MLP+Act：将第一个FC上下相关的算子合并为一个</span><br><span class="line"></span><br><span class="line">分布式: </span><br><span class="line">Column Parallel 权重按列拆分到多个GPU，每个GPU上的本地计算结果需要在列方向拼接为最终结果</span><br><span class="line">Row Parallel 每个GPU上的本地结果需要进行AllReduce规约</span><br><span class="line"></span><br><span class="line">MLP： CP + RP + AllReduce</span><br><span class="line">Attention: CP(QKV) + RP + AllReduce</span><br><span class="line">InputEmbedding: RP</span><br><span class="line">OutputEmbedding: CP</span><br></pre></td></tr></table></figure>

<p>Continuous batching: 迭代调度处理，当部分序列处理完成，插入新序列</p>
<p>RoPE: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/647109286">https://zhuanlan.zhihu.com/p/647109286</a></p>
<p>​           <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/642884818">https://zhuanlan.zhihu.com/p/642884818</a></p>
<p>实现差异分析: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/627536105">https://zhuanlan.zhihu.com/p/627536105</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">假设Ra表示角度为a的旋转矩阵，那么R具有如下性质：</span><br><span class="line"></span><br><span class="line">1. Ra^T = R(-a)</span><br><span class="line">2. Ra Rb = R(a+b)</span><br><span class="line"></span><br><span class="line">回到旋转位置编码，我们可以去证明 &lt;RaX, RbY&gt; = &lt;X, R(b-a)Y&gt; ，证明如下：</span><br><span class="line">&lt;RaX, RbY&gt;</span><br><span class="line">= (RaX)^T RbY</span><br><span class="line">= X^T Ra^T RbY</span><br><span class="line">= X^T R(b-a) Y</span><br><span class="line">= &lt;X, R(b-a)Y&gt;</span><br></pre></td></tr></table></figure>

<p>LM-Infinite: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/656709745">https://zhuanlan.zhihu.com/p/656709745</a></p>
<p>GPU参数列表: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/643292970">https://zhuanlan.zhihu.com/p/643292970</a></p>
<p>解码策略: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/653926703">https://zhuanlan.zhihu.com/p/653926703</a></p>
<p>分词: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/652520262">https://zhuanlan.zhihu.com/p/652520262</a></p>
<p>__ldg: 只能用于读取全局内存中的单个数据，不能用于读取数组或结构体中的数据</p>
<p> <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_42536162/article/details/129892382">https://blog.csdn.net/qq_42536162/article/details/129892382</a></p>
<ul>
<li><input checked="" disabled="" type="checkbox"> 大模型架构要点: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/648050614">https://zhuanlan.zhihu.com/p/648050614</a></li>
</ul>
<p>Tokenizer: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/651430181">https://zhuanlan.zhihu.com/p/651430181</a></p>
<ul>
<li><input checked="" disabled="" type="checkbox"> Transformer时空复杂度: <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/606514058/answer/3078324182">https://www.zhihu.com/question/606514058/answer/3078324182</a></li>
</ul>
<p>Decoder only 完美回答: <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/588325646/answer/3357252612">https://www.zhihu.com/question/588325646/answer/3357252612</a></p>
<p>hf多卡推理: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/639850033">https://zhuanlan.zhihu.com/p/639850033</a></p>
<p>split k: <a target="_blank" rel="noopener" href="https://blog.csdn.net/u013701860/article/details/128674224">https://blog.csdn.net/u013701860/article/details/128674224</a></p>
<ul>
<li><input checked="" disabled="" type="checkbox"> LLM 技术原理: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/647843722">https://zhuanlan.zhihu.com/p/647843722</a></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Transformer 计算量 l*(24bNh^2) 和 显存占用 l*(34bNh+5bH^2a) 都是序列长度N的二次方</span><br><span class="line">时空复杂度都是O(N^2) Self-Attention 内存受限</span><br></pre></td></tr></table></figure>

<p>微调: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/635710004">https://zhuanlan.zhihu.com/p/635710004</a></p>
<p>Deepnorm: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/480783670">https://zhuanlan.zhihu.com/p/480783670</a></p>
<p>量化: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/651874446">https://zhuanlan.zhihu.com/p/651874446</a></p>
<p>​          <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/645308698">https://zhuanlan.zhihu.com/p/645308698</a></p>
<p>​          <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/645362500">https://zhuanlan.zhihu.com/p/645362500</a></p>
<p>剪枝: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/630902012">https://zhuanlan.zhihu.com/p/630902012</a></p>
<p>encoder decoder: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/427311331">https://zhuanlan.zhihu.com/p/427311331</a></p>
<p>给定前面的对话内容，续写后续的对话内容。前面给定的信息就是这里的Context。</p>
<p>enc: 给一个向量，输出一个同样长度的向量</p>
<p>解码器输出一个向量，长度为 词表 长度 。这个向量是一个概率分布，表示取得对应词的概率。</p>
<p>自回归解码器 将解码器自己当前步的输出加入下一步的输入，解码器融合所有已经输入的向量来输出下一个向量，所以越往后的输出考虑了更多输入。在一定程度上自己预测自己</p>
<p>解码器和编码器的另一个区别是：在解码器block的第一个自注意力是 <em>masked</em> multi-head attention。在训练阶段，其输出序列的所有位置（时间步）的标记都是已知的；然而，在预测阶段，其输出序列的标记是逐个生成的。因此，在任何解码器时间步中，只有生成的标记才能用于解码器的自注意力计算中</p>
<p>Left padding: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/646852375">https://zhuanlan.zhihu.com/p/646852375</a></p>
<p>bos_token: <a target="_blank" rel="noopener" href="https://huggingface.co/docs/transformers/main_classes/tokenizer">https://huggingface.co/docs/transformers/main_classes/tokenizer</a></p>
<p>token pruning：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/570832732">https://zhuanlan.zhihu.com/p/570832732</a></p>
<p>多batch推理: <a target="_blank" rel="noopener" href="https://github.com/THUDM/ChatGLM-6B/issues/745">https://github.com/THUDM/ChatGLM-6B/issues/745</a></p>
<p>LLM微调: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/635710004">https://zhuanlan.zhihu.com/p/635710004</a></p>
<p>PPT简析: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/636329188">https://zhuanlan.zhihu.com/p/636329188</a></p>
<p>Gpipe: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/613196255">https://zhuanlan.zhihu.com/p/613196255</a> 流水线并行 压缩空闲气泡 切分更细碎的batch forward的时候不存中间结果 bp的时候重新计算</p>
<p>ZeRO: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/618865052">https://zhuanlan.zhihu.com/p/618865052</a> 数据并行 ZeRO 优化器 梯度 模型参数 分散各卡 减少通讯</p>
<p>TP: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/622212228">https://zhuanlan.zhihu.com/p/622212228</a> 横向纵向切分 推理结果累加还是拼接 梯度还要累加 </p>
<h4 id="2-vLLM"><a href="#2-vLLM" class="headerlink" title="2.vLLM"></a>2.vLLM</h4><p>PRs:</p>
<ul>
<li><input disabled="" type="checkbox"> torch.compile: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/pull/1795">https://github.com/vllm-project/vllm/pull/1795</a></li>
<li><input disabled="" type="checkbox"> align sampling: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/pull/1885">https://github.com/vllm-project/vllm/pull/1885</a></li>
<li><input disabled="" type="checkbox"> Refactor worker &amp; InputMetadata: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/pull/1843">https://github.com/vllm-project/vllm/pull/1843</a></li>
<li><input disabled="" type="checkbox"> Paged_AttentionV2: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/pull/1348">https://github.com/vllm-project/vllm/pull/1348</a></li>
<li><input disabled="" type="checkbox"> add streaming: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/pull/1052">https://github.com/vllm-project/vllm/pull/1052</a></li>
<li><input disabled="" type="checkbox"> Support fused rmsnorm: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/pull/1667">https://github.com/vllm-project/vllm/pull/1667</a></li>
<li><input disabled="" type="checkbox"> Prefix Caching: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/pull/1669">https://github.com/vllm-project/vllm/pull/1669</a></li>
<li><input disabled="" type="checkbox"> int8 fp8 KVCache: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/pull/1507">https://github.com/vllm-project/vllm/pull/1507</a></li>
<li><input disabled="" type="checkbox"> fix peak memory: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/pull/2031">https://github.com/vllm-project/vllm/pull/2031</a></li>
</ul>
<p>​       <a target="_blank" rel="noopener" href="https://discuss.pytorch.org/t/cuda-allocation-lifetime-for-inputs-to-distributed-all-reduce/191573">https://discuss.pytorch.org/t/cuda-allocation-lifetime-for-inputs-to-distributed-all-reduce/191573</a></p>
<ul>
<li><p><input disabled="" type="checkbox"> 
GPTQ: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/pull/916">https://github.com/vllm-project/vllm/pull/916</a></p>
</li>
<li><p><input disabled="" type="checkbox"> 
Prefix Prompt Cache: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/pull/2296">https://github.com/vllm-project/vllm/pull/2296</a></p>
</li>
<li><p><input disabled="" type="checkbox"> 
CUDA Graph: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/pull/1926">https://github.com/vllm-project/vllm/pull/1926</a></p>
</li>
<li><p><input disabled="" type="checkbox"> 
Speculative decoding: </p>
<p><a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/pull/2188">https://github.com/vllm-project/vllm/pull/2188</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/pull/2424">https://github.com/vllm-project/vllm/pull/2424</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/pull/2336">https://github.com/vllm-project/vllm/pull/2336</a></p>
</li>
<li><p><input disabled="" type="checkbox"> 
Faster and memory-efficient top-p top-k kernel: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/pull/2169">https://github.com/vllm-project/vllm/pull/2169</a></p>
</li>
<li><p><input disabled="" type="checkbox"> 
Fix the non-blocking behavior of the sampler: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/pull/2190">https://github.com/vllm-project/vllm/pull/2190</a></p>
</li>
<li><p><input disabled="" type="checkbox"> 
Fast all-reduce: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/pull/2192">https://github.com/vllm-project/vllm/pull/2192</a></p>
</li>
<li><p><input disabled="" type="checkbox"> 
Prefix cacheing: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/pull/1669">https://github.com/vllm-project/vllm/pull/1669</a></p>
</li>
<li><p><input disabled="" type="checkbox"> 
multi-LORA: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/pull/1804">https://github.com/vllm-project/vllm/pull/1804</a></p>
</li>
<li><p><input disabled="" type="checkbox"> 
Optimize cuda graph memory: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/pull/2437">https://github.com/vllm-project/vllm/pull/2437</a></p>
</li>
<li><p><input disabled="" type="checkbox"> 
Custom all reduce kernels: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/pull/2192">https://github.com/vllm-project/vllm/pull/2192</a></p>
</li>
</ul>
<p>Issues:</p>
<ul>
<li><input disabled="" type="checkbox"> 16 byte chunks: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/issues/1630">https://github.com/vllm-project/vllm/issues/1630</a></li>
<li><input disabled="" type="checkbox"> Support context length exceeding about 13k: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/issues/905">https://github.com/vllm-project/vllm/issues/905</a></li>
<li><input disabled="" type="checkbox"> options to increase performance: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/issues/2073">https://github.com/vllm-project/vllm/issues/2073</a></li>
<li><input disabled="" type="checkbox"> optimized kernel: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/issues/1880">https://github.com/vllm-project/vllm/issues/1880</a></li>
<li><input disabled="" type="checkbox"> +34%: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/issues/421">https://github.com/vllm-project/vllm/issues/421</a></li>
<li><input disabled="" type="checkbox"> lessen memory: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/issues/1571">https://github.com/vllm-project/vllm/issues/1571</a></li>
<li><input disabled="" type="checkbox"> performance down due to the scheduler: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/issues/1985">https://github.com/vllm-project/vllm/issues/1985</a></li>
<li><input disabled="" type="checkbox"> memory_efficient_attention_forward: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/issues/1895">https://github.com/vllm-project/vllm/issues/1895</a></li>
<li><input disabled="" type="checkbox"> CPU affinity: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/issues/1838">https://github.com/vllm-project/vllm/issues/1838</a></li>
<li><input disabled="" type="checkbox"> SparQ Attention: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/issues/2039">https://github.com/vllm-project/vllm/issues/2039</a></li>
<li><input disabled="" type="checkbox"> Slowdown in batch request handling: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/issues/1707">https://github.com/vllm-project/vllm/issues/1707</a></li>
<li><input disabled="" type="checkbox"> Lookahead decoding: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/issues/1742">https://github.com/vllm-project/vllm/issues/1742</a></li>
<li><input disabled="" type="checkbox"> Automatic Prefix Caching: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/issues/2614">https://github.com/vllm-project/vllm/issues/2614</a></li>
<li><input disabled="" type="checkbox"> </li>
</ul>
<p>Warp-level Primitives: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/572820783">https://zhuanlan.zhihu.com/p/572820783</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">T __shfl_sync(unsigned mask, T var, int srcLane, int width=warpSize);</span><br><span class="line">T __shfl_xor_sync(unsigned mask, T var, int laneMask, int width=warpSize);</span><br></pre></td></tr></table></figure>

<p>Transformer-4: Paged Attention kernel</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/663632255">https://zhuanlan.zhihu.com/p/663632255</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/663719053">https://zhuanlan.zhihu.com/p/663719053</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">一个线程组处理16个字节，一个线程8个字节相当于两个fp16</span><br><span class="line">K_vec 和 Q_vec 都表示这样的 vector：类型是fp16，大小为4</span><br><span class="line"></span><br><span class="line">加载q向量: q 是传入的关于整体 q 所在的显存起始地址，q_ptr 是当前 head 下当前 seq 的 q 的地址</span><br><span class="line">q_stride = num_head*head_size，表示要越过前面所有 seq 所有 head 的 q，当前处理的 head 的 idx 是 head_idx，那么在此 head 之前有关于当前 seq 的 head_idx 个 HEAD_SIZE 数量，也要越过，才是当前 seq 在当前 head 下的 q 的显存地址 q_ptr</span><br><span class="line"></span><br><span class="line">vec_idx * VEC_SIZE 求出包含的 fp16 个数，vec_idx 实际为 0 ~ 63</span><br><span class="line">const int offset1 = (vec_idx * VEC_SIZE) / x;  (0,4,8,12,...,252) / 8 = (0,0,1,1,...,31,31)</span><br><span class="line">const int offset2 = (vec_idx * VEC_SIZE) % x;  (0,0,0,0,4,4,4,4,...)</span><br></pre></td></tr></table></figure>

<p>Transformer-8: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/671316667">https://zhuanlan.zhihu.com/p/671316667</a> init_cache</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">max_num_batched_tokens: 单次迭代中可处理的 token 上限</span><br><span class="line">max_num_seqs: 单次迭代中可处理的 sequence 上限</span><br><span class="line">max_model_len: 单个 seq 最大长度</span><br><span class="line">max_paddings: 一个 batch 可增加的最大 padding 数量</span><br><span class="line"></span><br><span class="line">根据 num_gpu_blocks 和每个 block 的大小 key_block_shape，分配了 gpu_cache</span><br><span class="line">对 k 做了更细粒度的划分，</span><br><span class="line">cuda流在GPU上并发执行任务</span><br></pre></td></tr></table></figure>

<p>Transformer-10: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/671344566">https://zhuanlan.zhihu.com/p/671344566</a> SchedulerOutputs</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">num_batched_tokens = len(new_seq_lens) * max(new_seq_lens)</span><br><span class="line">当前运行的 seq 总数 x 最大长度不能超过 profile 预设</span><br><span class="line">有新加入 scheduled 的 seq 就做 prompt run 并提前 return</span><br><span class="line">在 not self.swapped 的情况下，从 waiting 中拿 seq group 构造的 SchedulerOutputs 是promopt 阶段的调度；反之是在 running 和可以 swap_in 的 list 中拿数据，是generator阶段的调度</span><br><span class="line"></span><br><span class="line">generation 阶段的 每个 seq 都只持有一个 token slot，所以此后的 num_batched_tokens == running 中的 seq 数目</span><br><span class="line">两种抢占策略</span><br></pre></td></tr></table></figure>

<p>Transformer-11: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/671443606">https://zhuanlan.zhihu.com/p/671443606</a> Sequence 类等</p>
<p>Paged Attention: </p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/662900859">https://zhuanlan.zhihu.com/p/662900859</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/660192497">https://zhuanlan.zhihu.com/p/660192497</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/664276902">https://zhuanlan.zhihu.com/p/664276902</a></p>
<p>Paged Attention 源码解析:</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/663632255">https://zhuanlan.zhihu.com/p/663632255</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/663719053">https://zhuanlan.zhihu.com/p/663719053</a></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">当前 head 下的 seq 的 q 向量，load到共享内存 q_vecs 中，即 <span class="number">256</span> 个 fp16 的数据，使用第一个 warp load 进来</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = thread_group_idx; i &lt; NUM_VECS_PER_THREAD; i += NUM_THREAD_GROUPS) &#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> vec_idx = thread_group_offset + i * THREAD_GROUP_SIZE;</span><br><span class="line">    q_vecs[thread_group_offset][i] = *<span class="built_in">reinterpret_cast</span>&lt;<span class="type">const</span> Q_vec*&gt;(q_ptr + vec_idx * VEC_SIZE);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">关于NUM_TOKENS_PER_THREAD_GROUP的循环：</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; NUM_TOKENS_PER_THREAD_GROUP; i++) &#123;  <span class="comment">// 按照线程组处理的 token 数量循环，每1个线程组也就是2个线程处理1个token</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> physical_block_offset = (thread_group_idx + i * WARP_SIZE) % BLOCK_SIZE;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> token_idx = block_idx * BLOCK_SIZE + physical_block_offset;  </span><br><span class="line">    ... </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">根据 offset 获得当前线程负责的 token 的 k 向量  j = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> offset1 = (vec_idx * VEC_SIZE) / x;  <span class="number">256</span>个元素，两组<span class="number">128</span>，offset1=<span class="number">0</span>~<span class="number">15</span>,offset2=<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>/<span class="number">0</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> offset2 = (vec_idx * VEC_SIZE) % x;  </span><br><span class="line">类似于展平成一行后重新寻址 一共<span class="number">256</span>个数放到容量为<span class="number">32</span>的寄存器中 每<span class="number">8</span>个数放一起 一个线程放几个 一个线程组一次传输<span class="number">16b</span>yte 也就是一个线程<span class="number">4</span>个数</span><br><span class="line"></span><br><span class="line">kv_head_stride 本质上是一个 block 中所有的 token 乘以 head_size，只算<span class="number">1</span>个头，所占的 fp16 的数量</span><br><span class="line">    </span><br><span class="line">thread_group_offset为<span class="number">0</span>的线程，收集的是当前 group（<span class="number">1</span>个group负责<span class="number">1</span>个token的<span class="number">1</span>个head的head_size个数据）中最大的 qk值</span><br><span class="line"></span><br><span class="line">处理和传输带宽要区分开</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/665609491">https://zhuanlan.zhihu.com/p/665609491</a></p>
<ul>
<li><input checked="" disabled="" type="checkbox"> 源码分析: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/641999400">https://zhuanlan.zhihu.com/p/641999400</a></li>
</ul>
<p>vLLM 推理流程梳理: </p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/649974825">https://zhuanlan.zhihu.com/p/649974825</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/649977422">https://zhuanlan.zhihu.com/p/649977422</a></p>
<p>Paged Attention 核心: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/655561941">https://zhuanlan.zhihu.com/p/655561941</a></p>
<p>一致性 penalty: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/658780653">https://zhuanlan.zhihu.com/p/658780653</a></p>
<p>LLM服务(上): <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/656939628">https://zhuanlan.zhihu.com/p/656939628</a></p>
<ul>
<li><p><input checked="" disabled="" type="checkbox"> 
vLLM top down 概览: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/645251151">https://zhuanlan.zhihu.com/p/645251151</a></p>
<p>vLLM 踩坑:</p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
export PYTHONPATH&#x3D;&#x2F;home&#x2F;kwx&#x2F;vllm: <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/8abf4b9a881d">https://www.jianshu.com/p/8abf4b9a881d</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
精度: fp16 &lt;–&gt; fp32的累积误差使得回答质量不下降但是足够长的序列之后一致性对不齐</p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
Flash Attention v2 issue: <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/issues/485">https://github.com/vllm-project/vllm/issues/485</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
fastapi 部署: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/6256971">https://zhuanlan.zhihu.com/p/6256971</a></p>
<p>fastapi async single threaded: <a target="_blank" rel="noopener" href="https://github.com/tiangolo/fastapi/issues/4265">https://github.com/tiangolo/fastapi/issues/4265</a></p>
</li>
</ul>
<h4 id="3-Attention-优化"><a href="#3-Attention-优化" class="headerlink" title="3.Attention 优化"></a>3.Attention 优化</h4><p>4版本: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/xformers/issues/918">https://github.com/facebookresearch/xformers/issues/918</a></p>
<ul>
<li><p><input checked="" disabled="" type="checkbox"> 
KV cache: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/646577898">https://zhuanlan.zhihu.com/p/646577898</a></p>
<pre><code> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">输入: [b, s=1, h] x [h, h] 得到 Q,K,V [b, s=1, h]</span><br><span class="line">QK^T: [b, head_num, 1, hidden_per_head] x [b, head_num, hidden_per_head, kv_length + 1] -&gt; [b, head_num, 1, kv_length + 1], s = kv_length + 1</span><br><span class="line">score*V: [b, head_num, 1, kv_length + 1] x [b, head_num, kv_length + 1, hidden_per_head] -&gt; [b, head_num, 1, hidden_per_head]</span><br><span class="line">linear(非mlp模块): [b, 1, h] x [h, h] -&gt; [b, 1, h]</span><br><span class="line">计算量为什么是 2bs(kv_length + 1)h</span><br></pre></td></tr></table></figure>
</code></pre>
</li>
</ul>
<p>​      <strong>显存占用 参数量 flops 中间激活 KV cache</strong>：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/624740065">https://zhuanlan.zhihu.com/p/624740065</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">Flops:</span><br><span class="line">QKV: [b,s,h] x [h,h] -&gt; [b,s,h] 计算量 3*2bsh^2</span><br><span class="line">QK^T [b,head_num,s,hidden_per_head] x [b,head_num,hidden_per_head,s] -&gt; [b,head_num,s,s]，2bs^2h</span><br><span class="line">score*V 2bs^2h</span><br><span class="line">attention的线性映射 2bsh^2</span><br><span class="line">mlp_1 [b,s,h] x [h,4h] -&gt; [b,s,4h] 8bsh^2</span><br><span class="line">mlp_2 [b,s,4h] x [4h,h] -&gt; [b,s,h] 8bsh^2</span><br><span class="line"></span><br><span class="line">激活值分析:</span><br><span class="line">== Attention占用显存 11bsh+5bs^a ==</span><br><span class="line">QKV: x [b,s,h] 占用显存 2bsh</span><br><span class="line">QK^T: Q,K [b,s,h] 4bsh</span><br><span class="line">softmax: QK^T 2bs^a a表示注意力头数</span><br><span class="line">Q [b,hn,s,ph] K^T [b,hn,ph,s] 2bs^a</span><br><span class="line">dropout: 保存一个mask矩阵 形状同QK^T bs^a</span><br><span class="line">score*V: score 2bs^a &amp; V 2bsh</span><br><span class="line">输出映射及一个dropout: 输入 2bsh &amp; mask矩阵 bsh</span><br><span class="line">== MLP 19bsh ==</span><br><span class="line">mlp1的输入 2bsh</span><br><span class="line">激活函数的输入 8bsh</span><br><span class="line">mlp2的输入 8bsh</span><br><span class="line">dropout的mask bsh</span><br><span class="line">== 两个LN ==</span><br><span class="line">两个输入各2bsh</span><br><span class="line">l层transformer (34bsh+5bs^a)l</span><br></pre></td></tr></table></figure>

<p>​      参数量: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/649229047">https://zhuanlan.zhihu.com/p/649229047</a></p>
<p>​      运算量: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/648988727">https://zhuanlan.zhihu.com/p/648988727</a></p>
<p>​    	        <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/670583522">https://zhuanlan.zhihu.com/p/670583522</a></p>
<p>​     显存占用: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/648924115">https://zhuanlan.zhihu.com/p/648924115</a></p>
<ul>
<li><p><input checked="" disabled="" type="checkbox"> 
FlashAttention: </p>
<p>只看图: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/663932651">https://zhuanlan.zhihu.com/p/663932651</a></p>
<p>值得和2最后细看: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/607364156">https://zhuanlan.zhihu.com/p/607364156</a></p>
<p>Flops, 复杂度, 访问次数: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/626079753">https://zhuanlan.zhihu.com/p/626079753</a></p>
<p>速度优化原理: <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/611236756/answer/3322413586">https://www.zhihu.com/question/611236756/answer/3322413586</a></p>
<p>v2 两点优化项十分清晰: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/645627275">https://zhuanlan.zhihu.com/p/645627275</a></p>
<p>Triton引子 &amp; FA循序渐进 &amp; 极具含金量: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/665170554">https://zhuanlan.zhihu.com/p/665170554</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
MQA GQA: <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/_4OxoRLxhOcjGf0Q4Tvp2Q">https://mp.weixin.qq.com/s/_4OxoRLxhOcjGf0Q4Tvp2Q</a></p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
Flash decoding: </p>
<p>感觉没说: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/661478232">https://zhuanlan.zhihu.com/p/661478232</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/66426444">https://zhuanlan.zhihu.com/p/66426444</a></p>
</li>
</ul>
<h4 id="4-TensorRT-LLM"><a href="#4-TensorRT-LLM" class="headerlink" title="4.TensorRT-LLM"></a>4.TensorRT-LLM</h4><p>evaluate 本地下载: <a target="_blank" rel="noopener" href="https://blog.csdn.net/misaki_min/article/details/132650725">https://blog.csdn.net/misaki_min/article/details/132650725</a></p>
<p>perf json: <a target="_blank" rel="noopener" href="https://github.com/triton-inference-server/server/issues/5746">https://github.com/triton-inference-server/server/issues/5746</a></p>
<p>Attention kernels: <a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT-LLM/issues/457">https://github.com/NVIDIA/TensorRT-LLM/issues/457</a></p>
<p>max_batch_size 讲究: <a target="_blank" rel="noopener" href="https://github.com/triton-inference-server/tensorrtllm_backend/issues/72">https://github.com/triton-inference-server/tensorrtllm_backend/issues/72</a></p>
<p>perf_analyzer cli: <a target="_blank" rel="noopener" href="https://github.com/triton-inference-server/client/blob/main/src/c%2B%2B/perf_analyzer/docs/cli.md">https://github.com/triton-inference-server/client/blob/main/src/c%2B%2B/perf_analyzer/docs/cli.md</a></p>
<p>perf_analyzer -m ensemble -i grpc –shape “bad_words:1” –shape “max_tokens:1” –shape “stop_words:1” –shape “text_input:1” –streaming</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Cannot send stop request without specifying a request_id.</span><br><span class="line"><span class="keyword">in</span> ensemble <span class="string">&#x27;ensemble&#x27;</span>, Streaming is only supported <span class="keyword">if</span> model is deployed using decoupled mode.</span><br><span class="line">ModelInfer RPC doesn<span class="string">&#x27;t support models with decoupled transaction policy.</span></span><br><span class="line"><span class="string">https://github.com/triton-inference-server/server/issues/4994  + --streaming</span></span><br><span class="line"><span class="string">Failed to init manager inputs: input bad_words contains dynamic shape, provide shapes to send along with the request  + --shape</span></span><br><span class="line"><span class="string">Cannot process new request: Streaming mode is only supported with beam width of 1.</span></span><br></pre></td></tr></table></figure>

<ul>
<li><input disabled="" type="checkbox"> 我不会用 Triton 系列: <a target="_blank" rel="noopener" href="https://www.cnblogs.com/zzk0/p/15510825.html">https://www.cnblogs.com/zzk0/p/15510825.html</a></li>
</ul>
<p>ulimit memlock&#x3D;-1: <a target="_blank" rel="noopener" href="https://gorden5566.com/post/1089.html">https://gorden5566.com/post/1089.html</a></p>
<p>LD_DEBUG&#x3D;libs 查看程序搜索库的路径: </p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/skyie53101517/article/details/45461835">https://blog.csdn.net/skyie53101517/article/details/45461835</a></p>
<p>3个.so: <a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT-LLM/issues/388">https://github.com/NVIDIA/TensorRT-LLM/issues/388</a></p>
<p>result mismatch: </p>
<p><a target="_blank" rel="noopener" href="https://github.com/triton-inference-server/tensorrtllm_backend/issues/77">https://github.com/triton-inference-server/tensorrtllm_backend/issues/77</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT-LLM/issues/208">https://github.com/NVIDIA/TensorRT-LLM/issues/208</a></p>
<p>max_batch_size 讲究: <a target="_blank" rel="noopener" href="https://github.com/triton-inference-server/tensorrtllm_backend/issues/72">https://github.com/triton-inference-server/tensorrtllm_backend/issues/72</a></p>
<p>perf_analyzer cli: <a target="_blank" rel="noopener" href="https://github.com/triton-inference-server/client/blob/main/src/c%2B%2B/perf_analyzer/docs/cli.md">https://github.com/triton-inference-server/client/blob/main/src/c%2B%2B/perf_analyzer/docs/cli.md</a></p>
<p>evaluate 本地下载: <a target="_blank" rel="noopener" href="https://blog.csdn.net/misaki_min/article/details/132650725">https://blog.csdn.net/misaki_min/article/details/132650725</a></p>
<p>LLaMA2详细流程: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/665209786">https://zhuanlan.zhihu.com/p/665209786</a></p>
<p>架构: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/665595557">https://zhuanlan.zhihu.com/p/665595557</a></p>
<p>C++ runtime: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/665792495">https://zhuanlan.zhihu.com/p/665792495</a></p>
<p>Attention &amp; BatchManager: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/665907001">https://zhuanlan.zhihu.com/p/665907001</a></p>
<p>BatchManager: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/665959440">https://zhuanlan.zhihu.com/p/665959440</a></p>
<p>图重写: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/666082166">https://zhuanlan.zhihu.com/p/666082166</a></p>
<p>数值精度: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/666215626">https://zhuanlan.zhihu.com/p/666215626</a></p>
<p>Tensor 设计实现: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/666219289">https://zhuanlan.zhihu.com/p/666219289</a></p>
<p>Python模块: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/667175043">https://zhuanlan.zhihu.com/p/667175043</a></p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">find</span> / -name pybind11Config.cmake</span><br><span class="line"></span><br><span class="line">cmake -DSM=<span class="number">80</span> -DCMAKE_BUILD_TYPE=Release -DBUILD_PYT=ON -DBUILD_MULTI_GPU=ON -Dpybind11_DIR=/usr/local/lib/python3.<span class="number">8</span>/dist-packages/pybind11/share/cmake/pybind11/pybind11Config.cmake ..</span><br><span class="line"></span><br><span class="line">mpirun -n <span class="number">2</span> --allow-run-as-root  python api_server.py --model /data2/dingweihao/llama-<span class="number">2</span>-<span class="number">13</span>b-pretrain-sft-<span class="number">2048</span>-checkpoint-<span class="number">546</span>-<span class="number">20230912</span>/ft/<span class="number">2</span>-gpu/ --tokenizer /data2/dingweihao/llama-<span class="number">2</span>-<span class="number">13</span>b-pretrain-sft-<span class="number">2048</span>-checkpoint-<span class="number">546</span>-<span class="number">20230912</span>/ --lib ../build/lib/ --tensor_para_size <span class="number">2</span> --port <span class="number">7000</span> --host <span class="number">0</span>.<span class="number">0</span>.<span class="number">0</span>.<span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>-Dpybind11_DIR: <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_38163468/article/details/121600290">https://blog.csdn.net/qq_38163468/article/details/121600290</a></p>
<p>remove padding的目的是为了减少padding部分的计算量，FT 中实现的remove padding仅仅减少了layernorm部分以及ffn部分还有self-attention中最后那个全联接部分的padding的计算量</p>
<h4 id="5-lmdeploy"><a href="#5-lmdeploy" class="headerlink" title="5.lmdeploy"></a>5.lmdeploy</h4><p>add_special_tokens 去除 offset</p>
<p>token负值: <a target="_blank" rel="noopener" href="https://github.com/InternLM/lmdeploy/issues/388">https://github.com/InternLM/lmdeploy/issues/388</a></p>
<p>std::promise: <a target="_blank" rel="noopener" href="https://blog.csdn.net/godmaycry/article/details/72844159">https://blog.csdn.net/godmaycry/article/details/72844159</a></p>
<p>std::unique_lock: <a target="_blank" rel="noopener" href="https://blog.csdn.net/fengbingchun/article/details/78638138">https://blog.csdn.net/fengbingchun/article/details/78638138</a></p>
<p>lock_guard &amp; unique_lock: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/340348726">https://zhuanlan.zhihu.com/p/340348726</a></p>
<p>notify_one&#x2F;all: <a target="_blank" rel="noopener" href="https://blog.csdn.net/feikudai8460/article/details/109604690">https://blog.csdn.net/feikudai8460/article/details/109604690</a></p>
<p>cv.wait: <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_34999565/article/details/120874408">https://blog.csdn.net/qq_34999565/article/details/120874408</a></p>
<p>只有当条件为false时调用wait才会阻塞当前线程，并且在收到其他线程的通知后只有当条件为true时才会被解除阻塞</p>
<p>pthread_barrier: <a target="_blank" rel="noopener" href="https://blog.csdn.net/u013748256/article/details/45243473">https://blog.csdn.net/u013748256/article/details/45243473</a></p>
<p>多线程锁住的是什么: <a target="_blank" rel="noopener" href="https://blog.csdn.net/u011754972/article/details/118184053">https://blog.csdn.net/u011754972/article/details/118184053</a></p>
<p>queue.put(None): <a target="_blank" rel="noopener" href="https://blog.csdn.net/u011331731/article/details/106320216">https://blog.csdn.net/u011331731/article/details/106320216</a> 促使消费者退出</p>
<p>c++内存模型: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/647137725">https://zhuanlan.zhihu.com/p/647137725</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">curl -X &#x27;POST&#x27;   &#x27;http://10.141.1.48:5000/generate&#x27;   -H &#x27;accept: application/json&#x27;   -H &#x27;Content-Type: application/json&#x27;   -d &#x27;&#123;</span><br><span class="line">  &quot;prompt&quot;: &quot;写一首李白的诗&quot;,</span><br><span class="line">  &quot;instance_id&quot;: -1,</span><br><span class="line">  &quot;sequence_start&quot;: true,</span><br><span class="line">  &quot;sequence_end&quot;: true,</span><br><span class="line">  &quot;stream&quot;: false,</span><br><span class="line">  &quot;stop&quot;: false,</span><br><span class="line">  &quot;request_output_len&quot;: 512,</span><br><span class="line">  &quot;top_p&quot;: 0.8,</span><br><span class="line">  &quot;top_k&quot;: 40,</span><br><span class="line">  &quot;temperature&quot;: 0.8,</span><br><span class="line">  &quot;repetition_penalty&quot;: 1,</span><br><span class="line">  &quot;ignore_eos&quot;: false</span><br><span class="line">&#125;&#x27;</span><br></pre></td></tr></table></figure>



<h4 id="6-Coroutine-Thread-Process"><a href="#6-Coroutine-Thread-Process" class="headerlink" title="6.Coroutine &amp; Thread &amp; Process"></a>6.Coroutine &amp; Thread &amp; Process</h4><p>并发：由一个处理器快速交替执行多个任务，只是看起来像在“同时执行多个任务”</p>
<p>并行：由多个处理器分别运行多个任务，各任务间严格同时执行</p>
<p>io阻塞: <a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_45393094/article/details/116571687">https://blog.csdn.net/weixin_45393094/article/details/116571687</a></p>
<p>multiprocess &amp; rpc &amp; zeromq:</p>
<p>nccl 仿照 demo debug: <a target="_blank" rel="noopener" href="https://discuss.pytorch.org/t/cuda-allocation-lifetime-for-inputs-to-distributed-all-reduce/191573/6">https://discuss.pytorch.org/t/cuda-allocation-lifetime-for-inputs-to-distributed-all-reduce/191573/6</a></p>
<p>NCCL increased memory: </p>
<p><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/nccl/issues/964">https://github.com/NVIDIA/nccl/issues/964</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/nccl/issues/864">https://github.com/NVIDIA/nccl/issues/864</a></p>
<p>dist.barrier: <a target="_blank" rel="noopener" href="https://blog.csdn.net/Tanqy1997/article/details/124677130">https://blog.csdn.net/Tanqy1997/article/details/124677130</a></p>
<p>torch 分布式接口: <a target="_blank" rel="noopener" href="https://blog.csdn.net/wzj_sxpi/article/details/115488316">https://blog.csdn.net/wzj_sxpi/article/details/115488316</a></p>
<p>pyzmq: <a target="_blank" rel="noopener" href="https://blog.csdn.net/zhangphil/article/details/111185008">https://blog.csdn.net/zhangphil/article/details/111185008</a></p>
<p>pub-sub vs pull-push: <a target="_blank" rel="noopener" href="https://medium.com/@thealmikey/zeromq-with-kotlin-part-2-a-bit-of-push-pull-and-pub-sub-e645108156d0">https://medium.com/@thealmikey/zeromq-with-kotlin-part-2-a-bit-of-push-pull-and-pub-sub-e645108156d0</a></p>
<p>共享内存: <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/376947069">https://www.zhihu.com/question/376947069</a></p>
<p>mp.managers: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/424011522">https://zhuanlan.zhihu.com/p/424011522</a></p>
<p>pipe queue: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/24883194">https://zhuanlan.zhihu.com/p/24883194</a></p>
<p>pool: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/24883077">https://zhuanlan.zhihu.com/p/24883077</a></p>
<p>多进程 + async: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/629916103">https://zhuanlan.zhihu.com/p/629916103</a></p>
<p>pyzmq: <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/04660f746a16">https://www.jianshu.com/p/04660f746a16</a></p>
<p>pipe vs queue vs zmq: <a target="_blank" rel="noopener" href="https://blog.csdn.net/MacwinWin/article/details/110488842">https://blog.csdn.net/MacwinWin/article/details/110488842</a></p>
<p>pytorch 进程通信: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/518802196">https://zhuanlan.zhihu.com/p/518802196</a></p>
<p>zeromq rpc对比: <a target="_blank" rel="noopener" href="https://www.smiletoyou.cn/archives/530">https://www.smiletoyou.cn/archives/530</a> </p>
<p>rpyc踩坑: </p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/Riven_h/article/details/117519846">https://blog.csdn.net/Riven_h/article/details/117519846</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/tomerfiliba-org/rpyc/issues/282">https://github.com/tomerfiliba-org/rpyc/issues/282</a></p>
<p>tcp keep_alive: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/28894266">https://zhuanlan.zhihu.com/p/28894266</a></p>
<p>tcp no_delay: <a target="_blank" rel="noopener" href="https://blog.csdn.net/lclwjl/article/details/80154565">https://blog.csdn.net/lclwjl/article/details/80154565</a></p>
<p>asyncio:</p>
<p>动态添加协程: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/59621713">https://zhuanlan.zhihu.com/p/59621713</a></p>
<p>asyncio lock: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/66050624">https://zhuanlan.zhihu.com/p/66050624</a></p>
<p>event loop: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/69210021">https://zhuanlan.zhihu.com/p/69210021</a></p>
<p>值得详细捋一遍 asyncio: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/59671241">https://zhuanlan.zhihu.com/p/59671241</a> wait gather讲得很清晰</p>
<p>asyncio 示例讲解: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/56084772">https://zhuanlan.zhihu.com/p/56084772</a></p>
<p>asyncio.sleep(0): <a target="_blank" rel="noopener" href="https://blog.csdn.net/nick131410/article/details/126571558">https://blog.csdn.net/nick131410/article/details/126571558</a></p>
<p>wait vs gather: <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/6872bf356af7">https://www.jianshu.com/p/6872bf356af7</a></p>
<p>coroutine &amp; task: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/45521388">https://zhuanlan.zhihu.com/p/45521388</a></p>
<p>最简 event loop: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/83627584">https://zhuanlan.zhihu.com/p/83627584</a></p>
<p>event: <a target="_blank" rel="noopener" href="https://blog.csdn.net/mixintu/article/details/102458809">https://blog.csdn.net/mixintu/article/details/102458809</a></p>
<p>Task 是协程和 future 的桥梁</p>
<p>get &#x2F; set_event_loop: <a target="_blank" rel="noopener" href="https://blog.csdn.net/whatday/article/details/106885916">https://blog.csdn.net/whatday/article/details/106885916</a></p>
<p>loop.run_xxx 家族都是阻塞的，例如 run_until_loop 会等到给定的 coroutine 完成才结束</p>
<p>run_forever 会永远阻塞直到有人停止该 event loop 为止，所以一个线程里无法同时 run 两个 event loop</p>
<p>初始情况下，get_event_loop 只会在主线程帮您创建新的 event loop，并且在主线程中多次调用始终返回该 event loop；而在其他线程中调用 get 则会报错，除非您在这些线程里面手动调用过 set</p>
<p>调用 async def 创建一个协程对象，这是一个类，不执行协程函数</p>
<p>协程可以通过await执行另一个协程</p>
<p>async for 用于遍历异步迭代器，并不会并行执行 for 循环，相反，执行 for 循环的调用协程将挂起并在内部等待迭代器产生的每个可等待对象</p>
<p>asyncio 支持带有子进程（用于执行命令）和流（用于 TCP 套接字编程）的非阻塞 I&#x2F;O</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/601352845">https://zhuanlan.zhihu.com/p/601352845</a></p>
<p>协程可以包装在 asyncio.Task 对象中独立执行，而不是直接在协程中执行</p>
<p>Task 对象提供异步执行协程的句柄</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/602204016">https://zhuanlan.zhihu.com/p/602204016</a></p>
<p>协程只能在事件循环中执行，执行协程的事件循环，管理协程之间的协作多任务处理</p>
<p>启动协程事件循环的典型方法是通过 asyncio.run() 函数</p>
<p>此函数接受一个协程并返回协程的值，提供的协程可以用作基于协程的程序的入口点</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/603230877">https://zhuanlan.zhihu.com/p/603230877</a></p>
<p>事件循环负责管理一个任务列表（协同程序）并尝试在循环的每次迭代中按顺序推进每个任务，以及执行其他任务，如执行回调和处理 I&#x2F;O</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/603230877">https://zhuanlan.zhihu.com/p/603230877</a></p>
<p>访问事件循环的原因:</p>
<p>监控任务的进度; 发布任务并从中获取结果; 解雇并忘记一次性任务。</p>
<p>事件循环可以在程序中用作基于协程任务的线程池的替代方案</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/604041050">https://zhuanlan.zhihu.com/p/604041050</a></p>
<p>可以通过 create_task() 函数调度协程作为任务独立运行，但它可能不会立即运行</p>
<p>直到事件循环有机会运行，直到所有其他协程都没有运行并且轮到任务运行时任务才会执行</p>
<p>task.done()可以用于检测任务是否完成  .cancelled()</p>
<p>.result()获取任务返回的结果 提前先检查任务是否已完成或是被取消 不然会出现 InvalidStateError</p>
<p>.exception() 检索未处理的异常 .cancel()取消计划任务</p>
<p>add_done_callback()向任务里添加回调  remove_done_callback()</p>
<p>task &#x3D; asyncio.create_task(task_coroutine(), name&#x3D;’MyTask’)<br>set_name()  get_name()</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/606363838">https://zhuanlan.zhihu.com/p/606363838</a></p>
<p>asyncio.current_task() 获取当前任务，这将为当前正在运行的任务返回一个任务对象，这可能是：</p>
<ol>
<li>传递给 asyncio.run() 的主协程</li>
<li>通过 asyncio.create_task() 在 asyncio 程序中创建和调度的任务</li>
</ol>
<p>所有协程都可以作为异步事件循环中的任务进行访问</p>
<p>asyncio.all_tasks() 获取一组已计划和正在运行的任务</p>
<p>异步生成器中依次获取值时，可以使用<code>async for</code>来实现</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/607709631">https://zhuanlan.zhihu.com/p/607709631</a></p>
<p>asyncio.gather(): 允许将一组可等待对象视为单个可等待对象</p>
<p>一次执行这些任务协程并等待它们全部完成后再继续，例如具有不同数据的相同任务或协程</p>
<ul>
<li>通过 await 表达式执行并等待组中的所有可等待对象完成。</li>
<li>从所有分组的等待对象中获取结果，稍后通过 result() 方法检索。</li>
<li>要通过 cancel() 方法取消的一组等待对象。</li>
<li>通过 done() 方法检查组中的所有可等待对象是否已完成。</li>
<li>仅当组中的所有任务完成时才执行回调函数。</li>
</ul>
<p>一旦创建了 Future 对象，它就会在事件循环中自动调度</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/608952664">https://zhuanlan.zhihu.com/p/608952664</a></p>
<p>asyncio.wait() 函数可用于等待一组异步任务完成</p>
<p>asyncio 任务是包装协程的 asyncio.Task 类的一个实例</p>
<p>它允许独立调度和执行协程，Task 实例提供任务句柄以查询状态和获取结果</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">done, pending = await asyncio.wait(tasks)</span><br><span class="line">done, pending = await asyncio.wait(tasks, return_when=asyncio.ALL_COMPLETED)</span><br><span class="line">FIRST_COMPLETED 当第一个任务完成并在完成集中返回时，其余任务不会被取消并继续并发执行</span><br><span class="line">FIRST_EXCEPTION 来等待第一个任务因异常而失败</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/609252710">https://zhuanlan.zhihu.com/p/609252710</a></p>
<p>asyncio.wait_for() 函数允许调用者等待 asyncio 任务或协程超时完成。如果没有指定超时，wait_for() 函数将等待直到任务完成。如果在任务完成之前指定了超时并超时，那么任务将被取消</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">await asyncio.wait_for(coro, timeout=10)</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/609956166">https://zhuanlan.zhihu.com/p/609956166</a></p>
<p>asyncio.shield() 保护另一个任务或协程不被取消，它以一个可等待对象作为参数并返回一个 asyncio.Future 对象，然后直接等待 Future 对象或将其传递给另一个任务或协程</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/610881194">https://zhuanlan.zhihu.com/p/610881194</a></p>
<p>asyncio.to_thread() 在后台创建一个 ThreadPoolExecutor 来执行阻塞调用，仅适用于 IO 绑定任务</p>
<p>另一种方法是 loop.run_in_executor()</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loop = asyncio.get_running_loop()</span><br><span class="line">await loop.run_in_executor(None, task)</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/611864797">https://zhuanlan.zhihu.com/p/611864797</a> &amp; <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/612439743">https://zhuanlan.zhihu.com/p/612439743</a></p>
<p>async for</p>
<p>上下文: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/613324037">https://zhuanlan.zhihu.com/p/613324037</a></p>
<p>推导式: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/614335834">https://zhuanlan.zhihu.com/p/614335834</a></p>
<p>非阻塞子进程: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/615048240">https://zhuanlan.zhihu.com/p/615048240</a></p>
<p>非阻塞流: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/615916630">https://zhuanlan.zhihu.com/p/615916630</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/619977951">https://zhuanlan.zhihu.com/p/619977951</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/619978329">https://zhuanlan.zhihu.com/p/619978329</a></p>
<p>asyncio.create_task() 方法安排许多协程在 asyncio 程序中独立运行</p>
<p>可以通过首先通过 asyncio.all_tasks() 函数获取一组所有正在运行的任务，从该集合中删除自身，然后通过 asyncio.wait() 函数等待剩余的任务来实现</p>
<p>通过直接等待 asyncio.Task 对象来等待任务完成</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/622324216">https://zhuanlan.zhihu.com/p/622324216</a></p>
<p>后台运行:</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">task = asyncio.create_task(other_coroutine())</span><br></pre></td></tr></table></figure>

<p>在当前协程出于任何原因挂起之前，任务不会开始执行</p>
<p>可以通过暂停片刻让任务开始运行来帮助解决问题，这可以通过休眠零秒来实现</p>
<p>等待所有后台任务: 从所有任务中剔除当前任务</p>
<p>显示任务进度:</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def progress(task):</span><br><span class="line">    # report progress of the task</span><br><span class="line">    print(&#x27;.&#x27;, end=&#x27;&#x27;)</span><br><span class="line">task.add_done_callback(progress)</span><br></pre></td></tr></table></figure>

<p>await + coroutine &#x2F; task &#x2F; Future</p>
<p>await 能够拿到返回值</p>
<p>协程:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line">## 迭代器</span><br><span class="line">for _ in + 可迭代对象</span><br><span class="line">共同 __iter__</span><br><span class="line"></span><br><span class="line">iter(可迭代对象) 得到 迭代器</span><br><span class="line">共同 __next__ __iter__</span><br><span class="line">超过长度得到 stopiteration </span><br><span class="line"></span><br><span class="line">while循环 模拟 for循环迭代</span><br><span class="line">while True: </span><br><span class="line">    try: </span><br><span class="line">    except StopIteration:</span><br><span class="line"></span><br><span class="line">迭代器的__iter__返回self</span><br><span class="line">使得整个迭代过程只需要迭代器就够了，直接让可迭代对象远离了循环</span><br><span class="line">意思就是不用再去遍历列表等容器类型了</span><br><span class="line"></span><br><span class="line">也就是说 一个可迭代对象可以拥有任意多个迭代器</span><br><span class="line">a=[0] b=iter(a) c=iter(a) b==c False 不同内存地址</span><br><span class="line"></span><br><span class="line">迭代器协议：</span><br><span class="line">__iter__返回迭代器自身</span><br><span class="line">__next__每次返回一个迭代数据，如果没有数据则抛出StopIteration异常</span><br><span class="line"></span><br><span class="line">## 生成器</span><br><span class="line">yield 函数没有运行而是返回一个生成器对象</span><br><span class="line">生成器函数内的代码需要通过生成器对象来执行 生成器函数的作用和类差不多</span><br><span class="line">import inspect</span><br><span class="line">print(inspect.isfunction(gen))</span><br><span class="line">print(inspect.isgeneratorfunction(gen)) 含yield的函数就叫生成器函数</span><br><span class="line">print(inspect.isgenerator(g))</span><br><span class="line">生成器对象一定是迭代器，通过next调用，每次next都会返回yield后的结果，函数运行结束(遇到return或默认返回None)抛出StopIteration异常</span><br><span class="line"></span><br><span class="line">## 内部机制</span><br><span class="line">生成器函数并不直接运行，而是借助于生成器对象间接运行</span><br><span class="line">创建生成器对象的同时创建了帧对象，并且由生成器对象保持引用</span><br><span class="line">每次使用next调用生成器就是将生成器引用的帧对象入栈</span><br><span class="line">next返回，也就是遇到yield暂停的时候，就是将帧出栈</span><br><span class="line">直到迭代结束，帧最后一次出栈并且被销毁</span><br><span class="line"></span><br><span class="line">同步 普通函数</span><br><span class="line">调用：构建帧对象并入栈</span><br><span class="line">函数执行结束：帧出栈并销毁</span><br><span class="line"></span><br><span class="line">异步 生成器函数</span><br><span class="line">创建生成器：构建帧对象</span><br><span class="line">（多次）通过next触发执行：帧入栈</span><br><span class="line">（多次）遇到yield：帧出栈（保留）# 在帧出栈的时候可以插入其他任务的执行</span><br><span class="line">迭代结束：帧出栈并销毁</span><br><span class="line"></span><br><span class="line">生成器对象是一个迭代执行生成器函数的迭代器，针对一个包含很多代码的函数，分段执行其中的代码</span><br><span class="line">让一个函数可以多次迭代运行其中的代码才是生成器对象最根本的作用</span><br><span class="line"></span><br><span class="line">def a():</span><br><span class="line">    print(&quot;here&quot;)</span><br><span class="line">    x = (yield) + 1</span><br><span class="line">    print(x)</span><br><span class="line">g = a()</span><br><span class="line">g.send(None) # here 停在yield处没有print的动作</span><br><span class="line">g.send(1) # 2</span><br><span class="line"></span><br><span class="line">结束协程也是靠异常实现的，GeneratorExit，except之后必须接return或者是循环时的break</span><br><span class="line"></span><br><span class="line">事件通常都是通过回调函数来处理的</span><br><span class="line"></span><br><span class="line">## yield from</span><br><span class="line">大大减少了被动协程的编码</span><br><span class="line">最末端遇到阻塞而不得不主动yield的协程叫做主动协程</span><br><span class="line">中间接收到下游传导而不得不跟随着yield的协程叫做被动协程</span><br><span class="line">用yield from统一yield</span><br><span class="line">总结：Task任务驱动器封装 + yield from 完全体改造 + YieldFromable</span><br><span class="line">协程的传染性也就是yield from的必要性；</span><br><span class="line">明白yield是怎么被隐藏的，从而理解协程的调用链末端发生了什么；</span><br><span class="line">理解协程的开端Task存在的必要性</span><br><span class="line">yield为了暂停 task驱动生成器 yield from链接生成器</span><br><span class="line"></span><br><span class="line">看到yield要等同于理解成函数要出栈了，暂时让出函数运行的权力</span><br><span class="line">yield from/await并不会执行一个出栈的过程，而是透传，层层深入直到遇到了yield</span><br><span class="line"></span><br><span class="line">t1 = Task() # 取消while True</span><br><span class="line">t1.run()</span><br><span class="line">Task().run() # 实际上t1的等待时间是留足的，只是说执行空隙为t2所利用</span><br><span class="line">t1.run()</span><br><span class="line"></span><br><span class="line">event_loop是后台的无限循环，负责完成所有任务的调度</span><br></pre></td></tr></table></figure>



<h4 id="7-Frontier"><a href="#7-Frontier" class="headerlink" title="7.Frontier"></a>7.Frontier</h4><p>HPC 课程笔记: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/671684145">https://zhuanlan.zhihu.com/p/671684145</a></p>
<p>Paper List: <a target="_blank" rel="noopener" href="https://github.com/HuangOwen/Awesome-LLM-Compression">https://github.com/HuangOwen/Awesome-LLM-Compression</a></p>
<p>扩散模型：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/611082996">https://zhuanlan.zhihu.com/p/611082996</a></p>
<p>​				   <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/609075353">https://zhuanlan.zhihu.com/p/609075353</a></p>
<p>RetNet: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/645974065">https://zhuanlan.zhihu.com/p/645974065</a></p>
<p>DepGraph: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/619146631">https://zhuanlan.zhihu.com/p/619146631</a></p>
<p>NeurIPS 2023 | 模型压缩与加速: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/673955376">https://zhuanlan.zhihu.com/p/673955376</a></p>
<h4 id="8-Triton"><a href="#8-Triton" class="headerlink" title="8.Triton"></a>8.Triton</h4><p>Makefile: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/350297509">https://zhuanlan.zhihu.com/p/350297509</a></p>
<p>MLIR文章汇总: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/141256429">https://zhuanlan.zhihu.com/p/141256429</a></p>
<p>软链接: <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_21386275/article/details/79881543">https://blog.csdn.net/qq_21386275/article/details/79881543</a></p>
<p>c++filt -n: <a target="_blank" rel="noopener" href="https://blog.csdn.net/K346K346/article/details/88225726">https://blog.csdn.net/K346K346/article/details/88225726</a></p>
<p>LLVM: <a target="_blank" rel="noopener" href="https://github.com/llvm/llvm-project/issues/63988">https://github.com/llvm/llvm-project/issues/63988</a></p>
<p>&#x2F;usr&#x2F;bin&#x2F;ld: cannot find -lxx: <a target="_blank" rel="noopener" href="https://blog.csdn.net/kuzma_zhang/article/details/131829943/">https://blog.csdn.net/kuzma_zhang/article/details/131829943/</a></p>
<p>ninja install 可以 但是加上 sudo 前缀后提示无该命令: <a target="_blank" rel="noopener" href="https://www.cnblogs.com/lfri/p/16277069.html">https://www.cnblogs.com/lfri/p/16277069.html</a></p>
<p>ninja -C build check-llvm</p>
<p>CMake hidden by files: conda deactivate   .so文件被隐藏</p>
<p>卸载 sudo make install: <a target="_blank" rel="noopener" href="https://blog.csdn.net/charry_win/article/details/126628169">https://blog.csdn.net/charry_win/article/details/126628169</a></p>
<p>入门: <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/622685131/answer/3217107882">https://www.zhihu.com/question/622685131/answer/3217107882</a></p>
<p>0.源码编译: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/628022771">https://zhuanlan.zhihu.com/p/628022771</a></p>
<ul>
<li><p><input disabled="" type="checkbox"> 
1.Triton DSL: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/628394465">https://zhuanlan.zhihu.com/p/628394465</a></p>
</li>
<li><p><input disabled="" type="checkbox"> 
2.Batch GEMM benchmark: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/629654531">https://zhuanlan.zhihu.com/p/629654531</a></p>
</li>
<li><p><input disabled="" type="checkbox"> 
3.Triton-shared: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/672487801">https://zhuanlan.zhihu.com/p/672487801</a></p>
</li>
<li><p><input disabled="" type="checkbox"> 
Memory Coalesce: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/670141785">https://zhuanlan.zhihu.com/p/670141785</a></p>
</li>
<li><p><input disabled="" type="checkbox"> 
DSL 到 PTX: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/671434808">https://zhuanlan.zhihu.com/p/671434808</a></p>
</li>
<li><p><input disabled="" type="checkbox"> 
Layout: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/672720213">https://zhuanlan.zhihu.com/p/672720213</a></p>
</li>
<li><p><input disabled="" type="checkbox"> 
Triton Ampere WMMA: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/675925978">https://zhuanlan.zhihu.com/p/675925978</a></p>
</li>
</ul>
<h4 id="9-CUDA"><a href="#9-CUDA" class="headerlink" title="9.CUDA"></a>9.CUDA</h4><p>CUDA 全局坐标运算: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/675603584">https://zhuanlan.zhihu.com/p/675603584</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x,y,z三维坐标系，先确定z，x*y是平面面积大小</span><br></pre></td></tr></table></figure>

<p>CUDA 入门技巧方法: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/584501634">https://zhuanlan.zhihu.com/p/584501634</a></p>
<p>Code: <a target="_blank" rel="noopener" href="https://github.com/ifromeast/cuda_learning">https://github.com/ifromeast/cuda_learning</a></p>
<p>基础: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/645330027">https://zhuanlan.zhihu.com/p/645330027</a></p>
<p>CUDA内存模型的基本单位是 SP (线程处理器)，每个 SP 都有自己的 register 和 local memory，两者皆只能被自己访问，不同的 SP 之间相互独立</p>
<p>多个 SP 和一块 smem 构成一个 SM (多核处理器)，其中的 SP 互相并行，smem 可以被线程块内的所有线程访问</p>
<p>由 SM 和 全局内存构成 GPU，一个 GPU 的所有 SM 共有一块 全局内存，不同线程块的线程都可使用</p>
<p>以上可以等价表述为：</p>
<p>每个 thread 都有自己的一份 register 和 local memory 的空间</p>
<p>同一个 block 中的每个 thread 则有共享的一份 share memory</p>
<p>此外，所有的 thread (包括不同 block 的 thread) 都共享一份 global memory</p>
<p>不同的 grid 则有各自的 global memory</p>
<p>从软件的角度来讲：</p>
<p>线程处理器 (SP) 对应线程 (thread)</p>
<p>多核处理器 (SM) 对应线程块 (thread block)</p>
<p>设备端 (device) 对应线程块组合体 (grid)</p>
<p>线程块特点: </p>
<p>块内的线程通过共享内存、原子操作和屏障同步进行协作</p>
<p>不同块中的线程不能协作</p>
<p><strong>非常经典的 3 种 torch 自定义 cuda 算子方法</strong></p>
<ul>
<li><input checked="" disabled="" type="checkbox"> CUDA 内存体系: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/654027980">https://zhuanlan.zhihu.com/p/654027980</a></li>
</ul>
<p>在核函数中定义的不加任何限定符的变量一般来说就存放于寄存器中</p>
<p>各种内建变量 blockDim、threadIdx 及 warpSize 都保存在特殊的寄存器中，以便高效访问</p>
<p>Reduction 优化: </p>
<p><strong>V100 A100 H100 L40S 参数比较</strong> </p>
<ul>
<li><input disabled="" type="checkbox"> CUDA GEMM: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/657632577">https://zhuanlan.zhihu.com/p/657632577</a></li>
</ul>
<h4 id="10-Quantization"><a href="#10-Quantization" class="headerlink" title="10.Quantization"></a>10.Quantization</h4><p>FloatFunctional会在prepare_qat之后activation_post_process会挂上FakeQuantize的hook，</p>
<p>然后就会是 <a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/blob/v1.10.0/torch/ao/quantization/fake_quantize.py#L138-L156">https://github.com/pytorch/pytorch/blob/v1.10.0/torch/ao/quantization/fake_quantize.py#L138-L156</a> </p>
<p>observe去更新min_max  min_max_observer里<a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/blob/v1.10.0/torch/ao/quantization/observer.py#L432-L443">https://github.com/pytorch/pytorch/blob/v1.10.0/torch/ao/quantization/observer.py#L432-L443</a></p>
<p>用到_calculate_qparams<a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/blob/36449ea93134574c2a22b87baad3de0bf8d64d42/torch/ao/quantization/observer.py#L253-L322">https://github.com/pytorch/pytorch/blob/36449ea93134574c2a22b87baad3de0bf8d64d42/torch/ao/quantization/observer.py#L253-L322</a></p>
<p>算出scale和zero_point <a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/blob/master/torch/ao/quantization/observer.py#L310-L365">https://github.com/pytorch/pytorch/blob/master/torch/ao/quantization/observer.py#L310-L365</a></p>
<p>Pytorch量化流程：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/299108528">https://zhuanlan.zhihu.com/p/299108528</a></p>
<p>美团技术实践: <a target="_blank" rel="noopener" href="https://tech.meituan.com/2022/09/22/yolov6-quantization-in-meituan.html">https://tech.meituan.com/2022/09/22/yolov6-quantization-in-meituan.html</a></p>
<p>OBS OBQ 推导: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/656316235">https://zhuanlan.zhihu.com/p/656316235</a></p>
<p>GPTQ 进一步深挖: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/646210009">https://zhuanlan.zhihu.com/p/646210009</a></p>
<p>LU分解: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/386954541">https://zhuanlan.zhihu.com/p/386954541</a></p>
<p>Cholesky分解: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/387603571?utm_id=0">https://zhuanlan.zhihu.com/p/387603571?utm_id=0</a></p>
<p>FP8: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/619431625">https://zhuanlan.zhihu.com/p/619431625</a></p>
<p>Resrep: <strong>卷积的等价性</strong></p>
<p>1*1理解成FC，所以它就是输入通道的线性重组（就是加权）</p>
<p>首先去理解为什么图中代码是shape一致的</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/laizi_laizi/article/details/110201274">https://blog.csdn.net/laizi_laizi/article/details/110201274</a></p>
<p>input x  [9,4,10,11]</p>
<p>注意到kernel&#x3D;3，pad&#x3D;1；kernel&#x3D;1，pad&#x3D;0这是为了保证特征图大小也就是10，11不发生改变</p>
<p>而本身ConvM.weight.shape  [3,4,3,3]    ConvP [3,5,1,1]    ConvA [5,4,3,3]</p>
<p>根据卷积 因为input和weight的第二个维度都是out_channel，所以要一致</p>
<p>所以input是ConA.w.p(1,0,2,3) 也就是[4,5,3,3] 让5对齐</p>
<p>卷积出来的结果就是 [4,3,3,3] permute之后恰好就是M的大小</p>
<p>又因为P来自于B，我们B(A)&#x3D;A  又验证了P(A)等价于M，也就是说剪了P就是剪了M</p>
<p>B是compactor,M本身权重的分配就是来自于A（不变）与P（剪完B之后获得） 所以这两者也是一致的</p>
<p>Rep本身是为了剪A，那构造B&#x3D;I,得到B(A)，只对B做裁剪，不影响原来A的结构，于是得到P(A)，</p>
<p>然后这个结果等价于生成一个M。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/04/05/Misc/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/04/05/Misc/" class="post-title-link" itemprop="url">Misc</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-04-05 12:52:27" itemprop="dateCreated datePublished" datetime="2023-04-05T12:52:27+08:00">2023-04-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-02-06 12:39:38" itemprop="dateModified" datetime="2024-02-06T12:39:38+08:00">2024-02-06</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>– [0.Errors](# 0.Errors)</p>
<p>– [1.Tools](# 1.Tools)</p>
<p>– [2.Math](# 2.Math)</p>
<p>– [3.YOLOv5 related](# 3.YOLOv5 related)</p>
<p>– [4.语音](# 4.语音)</p>
<p>– [6.Docker &amp; VSCode](# 6.Docker &amp; VSCode)</p>
<p>– [7.Git](# 7.Git)</p>
<p>Gameboy: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/676908347">https://zhuanlan.zhihu.com/p/676908347</a></p>
<p>各类还款方式: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/594699187">https://zhuanlan.zhihu.com/p/594699187</a></p>
<p>程序员的护城河: <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/604014261/answer/3179844243">https://www.zhihu.com/question/604014261/answer/3179844243</a></p>
<p>德语教辅: <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/395016403/answer/1238715439">https://www.zhihu.com/question/395016403/answer/1238715439</a></p>
<p>男人老了的标志是什么: <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/515229945/answer/2708757895">https://www.zhihu.com/question/515229945/answer/2708757895</a></p>
<p>如何看待自己终有一天会死去: <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/23178728/answer/2682474442">https://www.zhihu.com/question/23178728/answer/2682474442</a></p>
<p>我在贵司这三年: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/654508101">https://zhuanlan.zhihu.com/p/654508101</a></p>
<p>什么是人生的最顶级享受: <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/538449801/answer/2939200080">https://www.zhihu.com/question/538449801/answer/2939200080</a></p>
<p>被人真心爱着（爱过）是什么感觉: <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/55774089/answer/3236902813">https://www.zhihu.com/question/55774089/answer/3236902813</a></p>
<p>妙趣横生的水文： <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/537342945/answer/2640347949">https://www.zhihu.com/question/537342945/answer/2640347949</a></p>
<p><strong>High Priority:</strong></p>
<p>pytorch quantize error：<a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/issues/88800">pytorch&#x2F;pytorch#88800</a></p>
<p>fx wrap：<a target="_blank" rel="noopener" href="https://github.com/ModelTC/MQBench/issues/82">https://github.com/ModelTC/MQBench/issues/82</a></p>
<p>trace：<a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/issues/52721">https://github.com/pytorch/pytorch/issues/52721</a></p>
<p>export onnx quantized elu workaround：<a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/issues/90533">https://github.com/pytorch/pytorch/issues/90533</a></p>
<h4 id="0-Errors"><a href="#0-Errors" class="headerlink" title="0.Errors"></a>0.Errors</h4><p>&#x2F;dev&#x2F;sda1:clean &amp; nvrm can’t find an irq for your nvidia card: <a target="_blank" rel="noopener" href="https://askubuntu.com/questions/214504/splash-screen-flickers-during-every-boot/1386363#1386363">https://askubuntu.com/questions/214504/splash-screen-flickers-during-every-boot/1386363#1386363</a> </p>
<p>RuntimeError: CUDA error: no kernel image is available for execution on the device: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/466793485">https://zhuanlan.zhihu.com/p/466793485</a></p>
<p>NVIDIA-SMI has failed because it couldn’t communicate with the NVIDIA driver: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/89714824">https://zhuanlan.zhihu.com/p/89714824</a></p>
<p>host key verifications failed：<a target="_blank" rel="noopener" href="https://blog.csdn.net/wd2014610/article/details/85639741">https://blog.csdn.net/wd2014610/article/details/85639741</a></p>
<p>conda更换为阿里源: <a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/848988">https://developer.aliyun.com/article/848988</a></p>
<p>Cannot write to &#x2F;.condarc Caused by PermissionError: <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_45779334/article/details/123825436">https://blog.csdn.net/qq_45779334/article/details/123825436</a></p>
<p>conda install torch error: <a target="_blank" rel="noopener" href="https://blog.csdn.net/ermmtt/article/details/132628639">https://blog.csdn.net/ermmtt/article/details/132628639</a></p>
<p>hexo archive 404：<a target="_blank" rel="noopener" href="https://theme-next.js.org/docs/theme-settings/custom-pages">https://theme-next.js.org/docs/theme-settings/custom-pages</a></p>
<p>VPN：<a target="_blank" rel="noopener" href="https://www.duyaoss.com/archives/3/">https://www.duyaoss.com/archives/3/</a></p>
<p>​           <a target="_blank" rel="noopener" href="https://mxwljsq.xyz/user/shop">https://mxwljsq.xyz/user/shop</a></p>
<p><strong>Ubuntu</strong></p>
<p>failed to grab modset ownership: <a target="_blank" rel="noopener" href="https://blog.csdn.net/CC__Vbird__YDD/article/details/128986599">https://blog.csdn.net/CC__Vbird__YDD/article/details/128986599</a></p>
<p>误删除Downloads文件夹：<a target="_blank" rel="noopener" href="https://askubuntu.com/questions/1321623/accidentally-deleted-the-downloads-folder">https://askubuntu.com/questions/1321623/accidentally-deleted-the-downloads-folder</a></p>
<p>du -ah –max-depth&#x3D;1 ~ | sort -n  可以去掉~</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/guikunchen/article/details/88077330">在win10+Ubuntu双系统下，完美卸载Ubuntu_guikunchen的博客-CSDN博客_双系统卸载ubuntu</a></p>
<p><a target="_blank" rel="noopener" href="https://cyfeng.science/2020/05/02/ubuntu-install-nvidia-driver-cuda-cudnn-suits/">深度学习三件套:Ubuntu 20.04 安装 NVIDIA 驱动&#x2F;CUDA&#x2F;cuDNN全流程 | CO + 2Fe &#x3D; COFFee (cyfeng.science)</a></p>
<p><a target="_blank" rel="noopener" href="https://askubuntu.com/questions/1436601/ubuntu-drivers-unboundlocalerror-local-variable-version-referenced-before-as">https://askubuntu.com/questions/1436601/ubuntu-drivers-unboundlocalerror-local-variable-version-referenced-before-as</a></p>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/2a1cce843983">debain unable to bind to codec,导致无法开机 - 简书 (jianshu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/409460098">win10文件夹只读属性无法去除怎么修改？ - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://askubuntu.com/questions/1271611/app-software-updates-not-responding">Ubuntu软件和更新无响应</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_46412818/article/details/116806127">apt update no release</a></p>
<p>删除系统崩溃日志：sudo rm &#x2F;var&#x2F;crash*&#x2F;**</p>
<p>保持版本不更新：sudo apt-mark hold openvpn</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/X_T_S/article/details/110144658?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-110144658-blog-123733984.pc_relevant_antiscanv3&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-110144658-blog-123733984.pc_relevant_antiscanv3&utm_relevant_index=2">完美解决关机左上角光标闪烁</a></p>
<p>deprecated key: <a target="_blank" rel="noopener" href="https://forums.insynchq.com/t/apt-key-deprecation-with-workaround/18100">https://forums.insynchq.com/t/apt-key-deprecation-with-workaround/18100</a></p>
<p><a target="_blank" rel="noopener" href="https://unix.stackexchange.com/questions/588658/override-ubuntu-20-04-dns-using-systemd-resolved">nameserver</a> </p>
<p>nameserver：<a target="_blank" rel="noopener" href="https://askubuntu.com/questions/973017/wrong-nameserver-set-by-resolvconf-and-networkmanager/973025#973025">https://askubuntu.com/questions/973017/wrong-nameserver-set-by-resolvconf-and-networkmanager/973025#973025</a></p>
<p><a target="_blank" rel="noopener" href="https://askubuntu.com/questions/1173738/crash-systemd-journal-failed-to-write-entry-ignoring-read-only-file-system-on">systemd-journald crash</a></p>
<p><a target="_blank" rel="noopener" href="https://itsfoss.com/upgrade-linux-kernel-ubuntu">升级内核</a></p>
<p>wrong fs type,bad option,bad superlock:</p>
<p>dmesg | tail :  see parse_options(): Unrecognized mount option windows_names.<a target="_blank" rel="noopener" href="https://github.com/storaged-project/udisks/issues/932">https://github.com/storaged-project/udisks/issues/932</a></p>
<p>ImportError: &#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libstdc++.so.6: version &#96;GLIBCXX_3.4.xx‘ not found<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_30653631/article/details/107620137">https://blog.csdn.net/qq_30653631/article/details/107620137</a></p>
<p>OSError: cannot load library ‘libsndfile.so’：<a target="_blank" rel="noopener" href="https://blog.csdn.net/SpadgerZ/article/details/127533038">https://blog.csdn.net/SpadgerZ/article/details/127533038</a></p>
<h4 id="1-Tools"><a href="#1-Tools" class="headerlink" title="1.Tools"></a>1.Tools</h4><p>VScode下载慢: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/112215618">https://zhuanlan.zhihu.com/p/112215618</a></p>
<p>linux shell: <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/387878326/answer/2253913399">https://www.zhihu.com/question/387878326/answer/2253913399</a></p>
<p><a target="_blank" rel="noopener" href="https://www.ilovepdf.com/">iLovePDF | Online PDF tools for PDF lovers</a></p>
<p><a target="_blank" rel="noopener" href="https://bigjpg.com/">Bigjpg - AI人工智能图片无损放大 - 使用人工智能深度卷积神经网络(CNN)无损放大图片</a></p>
<h4 id="2-Math"><a href="#2-Math" class="headerlink" title="2.Math"></a>2.Math</h4><p>凸优化：<a target="_blank" rel="noopener" href="https://www.zhihu.com/column/convex">https://www.zhihu.com/column/convex</a></p>
<p>​               <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/270053227/answer/3138297987">https://www.zhihu.com/question/270053227/answer/3138297987</a></p>
<p>​               <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/49689245/answer/3148945726">https://www.zhihu.com/question/49689245/answer/3148945726</a></p>
<p>​               <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/68418633/answer/3178197426">https://www.zhihu.com/question/68418633/answer/3178197426</a></p>
<p>一个大学生的日常笔记：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/28617379">https://zhuanlan.zhihu.com/p/28617379</a></p>
<p>贝尔曼方程：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/86525700">https://zhuanlan.zhihu.com/p/86525700</a></p>
<p>矩阵求导系列：</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/263777564">https://zhuanlan.zhihu.com/p/263777564</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/273729929">https://zhuanlan.zhihu.com/p/273729929</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/288541909">https://zhuanlan.zhihu.com/p/288541909</a></p>
<h4 id="3-YOLOv5-related"><a href="#3-YOLOv5-related" class="headerlink" title="3.YOLOv5 related"></a>3.YOLOv5 related</h4><p><a target="_blank" rel="noopener" href="https://github.com/Syencil/mobile-yolov5-pruning-distillation">https://github.com/Syencil/mobile-yolov5-pruning-distillation</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/Gumpest/YOLOv5-Multibackbone-Compression">https://github.com/Gumpest/YOLOv5-Multibackbone-Compression</a></p>
<p>cifar_resnet：<a target="_blank" rel="noopener" href="https://github.com/chenyaofo/downstream-task-examples/blob/1508bc8ae2f264b8a27b39ce089b24801b63400e/custom/model/resnet.py">https://github.com/chenyaofo/downstream-task-examples/blob/1508bc8ae2f264b8a27b39ce089b24801b63400e/custom/model/resnet.py</a></p>
<p>EagleEye的随机搜索子网：<a target="_blank" rel="noopener" href="https://github.com/Cydia2018/YOLOv5-Light">https://github.com/Cydia2018/YOLOv5-Light</a></p>
<p>YOLORT：<a target="_blank" rel="noopener" href="https://github.com/zhiqwang/yolov5-rt-stack">https://github.com/zhiqwang/yolov5-rt-stack</a></p>
<p>SPPF bad: <a target="_blank" rel="noopener" href="https://github.com/quic/aimet/issues/1067">https://github.com/quic/aimet/issues/1067</a></p>
<p>​                  <a target="_blank" rel="noopener" href="https://github.com/zhiqwang/yolov5-rt-stack/issues/234">https://github.com/zhiqwang/yolov5-rt-stack/issues/234</a></p>
<h4 id="4-语音"><a href="#4-语音" class="headerlink" title="4.语音"></a>4.语音</h4><p>快速理解FFT：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/407885496">https://zhuanlan.zhihu.com/p/407885496</a></p>
<p>傅里叶变换的目的就是将信号转化为无数个不同频率的正弦信号的叠加，然后揭示这些正弦信号的强度和频率的关系</p>
<p>MFCC：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/181718235">https://zhuanlan.zhihu.com/p/181718235</a></p>
<p>语音loss：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/436809988">https://zhuanlan.zhihu.com/p/436809988</a></p>
<p>频谱泄露：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_41716239/article/details/105134887">https://blog.csdn.net/qq_41716239/article/details/105134887</a></p>
<p>滤波器：<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_28836875/article/details/112333448">https://blog.csdn.net/weixin_28836875/article/details/112333448</a></p>
<p>时域卷积&#x3D;频域乘积 的理解：</p>
<p>时域信号可以分解成一串不同频率正弦信号的叠加。根据卷积的分配率，两个时域信号的卷积最终可以展开成两两正弦信号的卷积的和。由于不同频率的正弦信号的卷积为0，所以最终只剩下相同频率的正弦信号的卷积。而卷积的结果就是频率不变，幅度相乘。在频域里边就表现为直接相乘。</p>
<p>stft：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/351634228">https://zhuanlan.zhihu.com/p/351634228</a></p>
<p>librosa：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/99709566">https://zhuanlan.zhihu.com/p/99709566</a></p>
<p>​                <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/8d6ffe6e10b9">https://www.jianshu.com/p/8d6ffe6e10b9</a></p>
<p>librosa &amp; stft：<a target="_blank" rel="noopener" href="https://blog.csdn.net/sinat_35821976/article/details/105739909">https://blog.csdn.net/sinat_35821976/article/details/105739909</a></p>
<p>hop_length语音帧长</p>
<p><strong>librosa.stft的输出帧数为 speech_length &#x2F;&#x2F; hop_length + 1</strong></p>
<p>梅尔频率倒谱系数MFCC：<a target="_blank" rel="noopener" href="https://blog.csdn.net/zzc15806/article/details/79246716">https://blog.csdn.net/zzc15806/article/details/79246716</a></p>
<p>帧移：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_38699252/article/details/109240468">https://blog.csdn.net/qq_38699252/article/details/109240468</a></p>
<p>分帧 帧移 加窗 滤波 降噪 合成：<a target="_blank" rel="noopener" href="https://blog.csdn.net/shixin_0125/article/details/99844048">https://blog.csdn.net/shixin_0125/article/details/99844048</a></p>
<p>ISTFT： <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/280648561/answer/2521849999">https://www.zhihu.com/question/280648561/answer/2521849999</a></p>
<p>LSTM一致性:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"># LSTM逐行一致性</span><br><span class="line">W_ii = self.rnn2.weight_ih_l0.reshape(4, 96, 96)[0, ...]</span><br><span class="line">W_hi = self.rnn2.weight_hh_l0.reshape(4, 96, 96)[0, ...]</span><br><span class="line">b_ii = self.rnn2.bias_ih_l0.reshape(4, 96)[0, ...]</span><br><span class="line">b_hi = self.rnn2.bias_hh_l0.reshape(4, 96)[0, ...]</span><br><span class="line">it = torch.sigmoid(x1 @ W_ii.t() + b_ii + h2_in @ W_hi.t() + b_hi)</span><br><span class="line"></span><br><span class="line">W_if = self.rnn2.weight_ih_l0.reshape(4, 96, 96)[1, ...]</span><br><span class="line">W_hf = self.rnn2.weight_hh_l0.reshape(4, 96, 96)[1, ...]</span><br><span class="line">b_if = self.rnn2.bias_ih_l0.reshape(4, 96)[1, ...]</span><br><span class="line">b_hf = self.rnn2.bias_hh_l0.reshape(4, 96)[1, ...]</span><br><span class="line">ft = torch.sigmoid(x1 @ W_if.t() + b_if + h2_in @ W_hf.t() + b_hf)</span><br><span class="line"></span><br><span class="line">W_ig = self.rnn2.weight_ih_l0.reshape(4, 96, 96)[2, ...]</span><br><span class="line">W_hg = self.rnn2.weight_hh_l0.reshape(4, 96, 96)[2, ...]</span><br><span class="line">b_ig = self.rnn2.bias_ih_l0.reshape(4, 96)[2, ...]</span><br><span class="line">b_hg = self.rnn2.bias_hh_l0.reshape(4, 96)[2, ...]</span><br><span class="line"></span><br><span class="line">tanh_in = x1 @ W_ig.t() + b_ig + h2_in @ W_hg.t() + b_hg</span><br><span class="line">gt = torch.tanh(tanh_in)</span><br><span class="line"></span><br><span class="line">W_io = self.rnn2.weight_ih_l0.reshape(4, 96, 96)[3, ...]</span><br><span class="line">W_ho = self.rnn2.weight_hh_l0.reshape(4, 96, 96)[3, ...]</span><br><span class="line">b_io = self.rnn2.bias_ih_l0.reshape(4, 96)[3, ...]</span><br><span class="line">b_ho = self.rnn2.bias_hh_l0.reshape(4, 96)[3, ...]</span><br><span class="line">ot = torch.sigmoid(x1 @ W_io.t() + b_io + h2_in @ W_ho.t() + b_ho)</span><br><span class="line">ft_ct = ft * c2_in</span><br><span class="line">ct = ft * c2_in + it * gt</span><br><span class="line">ht = ot * torch.tanh(ct)</span><br></pre></td></tr></table></figure>

<h4 id="6-Docker-VSCode"><a href="#6-Docker-VSCode" class="headerlink" title="6.Docker &amp; VSCode"></a>6.Docker &amp; VSCode</h4><p>Error response from daemon: could not select device driver: <a target="_blank" rel="noopener" href="https://blog.csdn.net/li4692625/article/details/123015840">https://blog.csdn.net/li4692625/article/details/123015840</a></p>
<p>修改ssh默认端口: <a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/1253389">https://developer.aliyun.com/article/1253389</a></p>
<p>vscode 修复Remote-SSH XHR failed: <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_45654306/article/details/132047411">https://blog.csdn.net/qq_45654306/article/details/132047411</a>  </p>
<p>strip 参数很关键</p>
<p>sudo docker service stop 停止所有docker进程</p>
<p>docker clean: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/386025157">https://zhuanlan.zhihu.com/p/386025157</a></p>
<p>snap remove docker: <a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/75604510/errno-13-permission-denied-%C2%B4-usr-lib-python3-10-pycache-future">https://stackoverflow.com/questions/75604510/errno-13-permission-denied-%C2%B4-usr-lib-python3-10-pycache-future</a></p>
<p>ubuntu install docker engine: <a target="_blank" rel="noopener" href="https://docs.docker.com/engine/install/ubuntu/">https://docs.docker.com/engine/install/ubuntu/</a></p>
<p>各container明细: <a target="_blank" rel="noopener" href="https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/rel-22-12.html">https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/rel-22-12.html</a></p>
<p>there-was-an-error-while-opening-file-handle: <a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/68052984/there-was-an-error-while-opening-file-handle">https://stackoverflow.com/questions/68052984/there-was-an-error-while-opening-file-handle</a></p>
<h4 id="7-Git"><a href="#7-Git" class="headerlink" title="7.Git"></a>7.Git</h4><p>ssh -T <a href="mailto:&#103;&#x69;&#116;&#64;&#103;&#x69;&#116;&#x68;&#x75;&#98;&#x2e;&#99;&#x6f;&#109;">&#103;&#x69;&#116;&#64;&#103;&#x69;&#116;&#x68;&#x75;&#98;&#x2e;&#99;&#x6f;&#109;</a>: </p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_45869649/article/details/124365483">https://blog.csdn.net/weixin_45869649/article/details/124365483</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43405300/article/details/135814505">https://blog.csdn.net/weixin_43405300/article/details/135814505</a></p>
<p>保持与upstream同步 git remote add</p>
<p>本地创建匹配的分支 git checkout -b zzs  新建并切换分支</p>
<p>git branch: <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq15577969/article/details/107632375">https://blog.csdn.net/qq15577969/article/details/107632375</a></p>
<p>git教程: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/649140159">https://zhuanlan.zhihu.com/p/649140159</a></p>
<p>​              <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/402325945">https://zhuanlan.zhihu.com/p/402325945</a></p>
<p>git stash reset –soft cherry-pick revert reflog: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/671816447">https://zhuanlan.zhihu.com/p/671816447</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/04/05/Cpp/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/04/05/Cpp/" class="post-title-link" itemprop="url">Cpp</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-04-05 12:47:47" itemprop="dateCreated datePublished" datetime="2023-04-05T12:47:47+08:00">2023-04-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-11-20 23:24:52" itemprop="dateModified" datetime="2023-11-20T23:24:52+08:00">2023-11-20</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>[2022](# 2022)</p>
<p>– [1.Cpp](# 1.Cpp)</p>
<p>– [2.Cherno](# 2.Cherno)</p>
<p>– [3.C++ Primer](# 3.C++ Primer)</p>
<p>[2023](# 2023)</p>
<p>– [1.Cpp](# 1.Cpp)</p>
<h2 id="2022"><a href="#2022" class="headerlink" title="2022"></a>2022</h2><h4 id="1-Cpp"><a href="#1-Cpp" class="headerlink" title="1.Cpp"></a>1.Cpp</h4><table>
<thead>
<tr>
<th>引用类型</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th>使用场景</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>非常量左值</td>
<td>常量左值</td>
<td>非常量右值</td>
<td>常量右值</td>
<td></td>
</tr>
<tr>
<td>非常量左值引用</td>
<td>Y</td>
<td>N</td>
<td>N</td>
<td>N</td>
<td>无</td>
</tr>
<tr>
<td>常量左值引用</td>
<td>Y</td>
<td>Y</td>
<td>Y</td>
<td>Y</td>
<td>常用于类中构建拷贝构造函数</td>
</tr>
<tr>
<td>非常量右值引用</td>
<td>N</td>
<td>N</td>
<td>Y</td>
<td>N</td>
<td>移动语义、完美转发</td>
</tr>
<tr>
<td>常量右值引用</td>
<td>N</td>
<td>N</td>
<td>Y</td>
<td>Y</td>
<td>无实际用途</td>
</tr>
</tbody></table>
<p>清晰的左右值，左右引用：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/2ed2689afa49">https://www.jianshu.com/p/2ed2689afa49</a></p>
<p>左值右值：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/402251966">https://zhuanlan.zhihu.com/p/402251966</a></p>
<p>std::map：<a target="_blank" rel="noopener" href="https://blog.csdn.net/loveC__/article/details/88702666">https://blog.csdn.net/loveC__/article/details/88702666</a></p>
<p>set vector互转：<a target="_blank" rel="noopener" href="https://blog.csdn.net/SL_World/article/details/114664645">https://blog.csdn.net/SL_World/article/details/114664645</a></p>
<p><strong>容易错误的左值：</strong></p>
<blockquote>
<p>1.字符串字面量，如：<code>&quot;Hello&quot;</code><br>2.内置的前++与前–，如：<code>++a</code><br><strong>3.变量类型是右值引用的表达式</strong>，如：<code>TestClassA&amp;&amp; ra = TestClassA(1000);</code>ra是左值<br>4.转型为左值引用的表达式，如：<code>static_cast&lt;double&amp;&gt;(fValue)</code>;<br>5.内置*解引用的表达式，如：<code>*pkValue</code></p>
</blockquote>
<p><strong>容易错误的右值：</strong></p>
<blockquote>
<p>1.非字符串的字面量以及枚举项，如：<code>nullptr</code>,<code>true</code><br>2.内置的后++与后–，如：<code>a--</code><br>3.内置的算术，逻辑，比较表达式，如：<code>a+b</code>，<code>a&amp;b</code>，<code>a||b</code>, <code>a&lt;b</code><br>4.内置取地址表达式，this指针，如:<code>&amp;a</code><br>5.lamda表达式,如：<code>[](int a)&#123; return 2*a; &#125;</code><br>6.转型为非引用的表达式，如：<code>static_cast&lt;double&gt;(fValue)</code>, <code>(float)42</code><br>7.转型为右值引用的表达式，如：<code>static_cast&lt;double&amp;&amp;&gt;(fValue)</code>，<code>std::move(x)</code>;</p>
<p>8.<strong>亡值：生命周期即将结束的表达式，如TestClassA(100)</strong></p>
</blockquote>
<h4 id="2-Cherno"><a href="#2-Cherno" class="headerlink" title="2.Cherno"></a>2.Cherno</h4><p>1.<strong>指针和引用</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> Log(x) std::cout &lt;&lt; x &lt;&lt; std::endl;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Increment_1</span><span class="params">(<span class="type">int</span> val)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    val++;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Increment_2</span><span class="params">(<span class="type">int</span>* val)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    (*val)++;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Increment_3</span><span class="params">(<span class="type">int</span>&amp; val)</span> <span class="comment">//引用传递</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    val++;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> a = <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">Increment_1</span>(a);</span><br><span class="line">    <span class="built_in">Log</span>(a);</span><br><span class="line">    <span class="built_in">Increment_2</span>(&amp;a);</span><br><span class="line">    <span class="built_in">Log</span>(a);</span><br><span class="line">    <span class="built_in">Increment_3</span>(a);</span><br><span class="line">    <span class="built_in">Log</span>(a);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>2.<strong>Static</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="comment">//1.类内</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">entity</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">static</span> <span class="type">int</span> x, y; <span class="comment">//本质上不属于类，而更像是类命名空间下的普通变量</span></span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">Print</span><span class="params">()</span> <span class="comment">//共享一个内存，只有一个实例</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; x &lt;&lt; <span class="string">&quot;,&quot;</span> &lt;&lt; y &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">//commenting following 2 lines will meet an error,因为一定需要定义才能访问到,这两行是必须要有的</span></span><br><span class="line"><span class="type">int</span> entity::x;</span><br><span class="line"><span class="type">int</span> entity::y;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 1:Instance</span></span><br><span class="line">    entity e;</span><br><span class="line">    e.x = <span class="number">2</span>;</span><br><span class="line">    e.y = <span class="number">2</span>; </span><br><span class="line">    <span class="comment">// 2:Namespace</span></span><br><span class="line">    entity::x = <span class="number">2</span>;</span><br><span class="line">    entity::y = <span class="number">3</span>;</span><br><span class="line">    entity::<span class="built_in">Print</span>();  <span class="comment">// One instance</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>3.<strong>单例类</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="comment">//与2一致，主要是int-&gt;Singleton*，实例为Singleton</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//1：不使用局部静态创建单例类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Singleton</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">private</span>:<span class="comment">//这也是为什么需要用Get去访问得到</span></span><br><span class="line">	<span class="type">static</span> Singleton* s_Instance;  <span class="comment">// 静态成员变量，Singleton类型的指针实例</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="function"><span class="type">static</span> Singleton&amp; <span class="title">Get</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> *s_Instance; &#125;;<span class="comment">// 返回Singleton类实例的引用，解引用*是为了得到类，而不是类的指针</span></span><br><span class="line">	<span class="function"><span class="type">void</span> <span class="title">Hello</span><span class="params">()</span></span>&#123; std::cout &lt;&lt; <span class="string">&quot;Hello&quot;</span> &lt;&lt; std::endl; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">Singleton* Singleton::s_Instance = <span class="literal">nullptr</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    	<span class="comment">// Singleton::Get()就得到一个单例的对象，由于是类似命名空间直接调用类的方法得到的，而不是对象的方法，因此只有一个实例</span></span><br><span class="line">	Singleton::<span class="built_in">Get</span>().<span class="built_in">Hello</span>();</span><br><span class="line">	std::cin.<span class="built_in">get</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//2：使用</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Singleton</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>: <span class="comment">// 返回Singleton类型的实例的引用</span></span><br><span class="line">	<span class="function"><span class="type">static</span> Singleton&amp; <span class="title">Get</span><span class="params">()</span> <span class="comment">//不加static,在堆栈上创建变量，在运行到花括号时就会销毁，返回引用(复制)就会出问题</span></span></span><br><span class="line"><span class="function">	</span>&#123; </span><br><span class="line">		<span class="type">static</span> Singleton instance;   <span class="comment">// 这里的static，和函数中的local static是一样的功能</span></span><br><span class="line">		<span class="keyword">return</span> instance;</span><br><span class="line">	&#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>5.<strong>虚函数</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">//虚函数允许在子类中重写方法</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Entity</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> std::string <span class="title">GetName</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="string">&quot;Entity&quot;</span>; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Player</span> : <span class="keyword">public</span> Entity</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::string m_Name;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Player</span>(<span class="type">const</span> std::string&amp; name) : <span class="built_in">m_Name</span>(name) &#123;&#125; <span class="comment">//构造函数接收输入的字符串作为m_Name进行初始化</span></span><br><span class="line">    <span class="function">std::string <span class="title">GetName</span><span class="params">()</span> <span class="keyword">override</span> </span>&#123; <span class="keyword">return</span> m_Name; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">PrintName</span><span class="params">(Entity* entity)</span> <span class="comment">//写了virtual就会往子类去找，为什么这里需要传一个指针，指针能区分 到底是哪个类</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    std::cout &lt;&lt; entity -&gt; <span class="built_in">GetName</span>() &lt;&lt; std::endl; <span class="comment">//指针指向的是类的实例</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Entity* e = <span class="keyword">new</span> <span class="built_in">Entity</span>();  <span class="comment">//分配内存</span></span><br><span class="line">    <span class="built_in">PrintName</span>(e);</span><br><span class="line"></span><br><span class="line">    Player* p = <span class="keyword">new</span> <span class="built_in">Player</span>(<span class="string">&quot;Cherno&quot;</span>);</span><br><span class="line">    <span class="built_in">PrintName</span>(p);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//Entity* entity = p;//指向player的实例，但得到的是Entity</span></span><br><span class="line">    <span class="comment">//std::cout &lt;&lt; entity -&gt; GetName() &lt;&lt; std::endl;</span></span><br><span class="line">    std::cin.<span class="built_in">get</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>6.<strong>纯虚函数</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Entity</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> std::string <span class="title">GetName</span><span class="params">()</span> </span>= <span class="number">0</span>; <span class="comment">//不写明</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Player</span> : <span class="keyword">public</span> Entity</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::string m_Name;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Player</span>(<span class="type">const</span> std::string&amp; name) : <span class="built_in">m_Name</span>(name) &#123;&#125;</span><br><span class="line">    <span class="function">std::string <span class="title">GetName</span><span class="params">()</span> <span class="keyword">override</span> </span>&#123; <span class="keyword">return</span> m_Name; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">PrintName</span><span class="params">(Entity* entity)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    std::cout &lt;&lt; entity -&gt;<span class="built_in">GetName</span>() &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Entity* e = <span class="keyword">new</span> <span class="built_in">Player</span>(<span class="string">&quot;Kwx&quot;</span>);</span><br><span class="line">    <span class="built_in">PrintName</span>(e);</span><br><span class="line"></span><br><span class="line">    Player* p = <span class="keyword">new</span> <span class="built_in">Player</span>(<span class="string">&quot;Cherno&quot;</span>);</span><br><span class="line">    <span class="built_in">PrintName</span>(p);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>7.<strong>接口</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Printable</span>  <span class="comment">//接口就是一个类</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> std::string <span class="title">GetClassName</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Entity</span> : <span class="keyword">public</span> Printable</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">std::string <span class="title">GetClassName</span><span class="params">()</span> <span class="keyword">override</span> </span>&#123; <span class="keyword">return</span> <span class="string">&quot;Entity&quot;</span>; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Player</span> : <span class="keyword">public</span> Entity</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::string m_Name;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Player</span>(<span class="type">const</span> std::string&amp; name) :<span class="built_in">m_Name</span>(name) &#123;&#125;</span><br><span class="line">    <span class="function">std::string <span class="title">GetClassName</span><span class="params">()</span> <span class="keyword">override</span> </span>&#123; <span class="keyword">return</span> <span class="string">&quot;Player&quot;</span>; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Print</span><span class="params">(Printable* obj)</span> <span class="comment">//因为有继承关系，所以要用指针区分？ 和7没区别</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    std::cout &lt;&lt; obj-&gt;<span class="built_in">GetClassName</span>() &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        Entity* e = <span class="keyword">new</span> <span class="built_in">Entity</span>();</span><br><span class="line">        Player* p = <span class="keyword">new</span> <span class="built_in">Player</span>(<span class="string">&quot;Kwx&quot;</span>);</span><br><span class="line">        <span class="built_in">Print</span>(e);</span><br><span class="line">        <span class="built_in">Print</span>(p);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>14.<strong>拷贝构造函数</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">String</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">char</span>* m_Buffer;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> m_Size; </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">String</span>(<span class="type">const</span> <span class="type">char</span>* string) <span class="comment">//默认浅拷贝，指针就是地址，区别在于是否重新开辟</span></span><br><span class="line">    &#123;</span><br><span class="line">        m_Size = <span class="built_in">strlen</span>(string);</span><br><span class="line">        m_Buffer = <span class="keyword">new</span> <span class="type">char</span>[m_Size + <span class="number">1</span>]; <span class="comment">// 分配内存</span></span><br><span class="line">        <span class="comment">// 在对含有指针成员的对象进行拷贝时，必须自己定义拷贝构造函数，达到深拷贝的目的，才能避免内存重复释放</span></span><br><span class="line">        <span class="comment">// 类中存在指针成员变量的时候，并且这个指针是指向堆上的内存。浅拷贝复制的时候仅仅复制指针，而不会复制指针指向的内存的数据</span></span><br><span class="line">        <span class="comment">// for (int i = 0; i &lt; m_Size; i++)</span></span><br><span class="line">        <span class="comment">//     m_Buffer[i] = string[i]；</span></span><br><span class="line">        <span class="built_in">memcpy</span>(m_Buffer, string, m_Size + <span class="number">1</span>); <span class="comment">// 从源内存地址拷贝若干字节到目标地址，两个都是地址</span></span><br><span class="line">        m_Buffer[m_Size] = <span class="number">0</span>;</span><br><span class="line">    &#125; <span class="comment">//这是一个有参构造函数，构造完自动给你分配一个内存</span></span><br><span class="line"></span><br><span class="line">    ~<span class="built_in">String</span>()</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">delete</span>[] m_Buffer;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">char</span>&amp; <span class="keyword">operator</span>[](<span class="type">unsigned</span> <span class="type">int</span> index)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> m_Buffer[index];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 深拷贝：在堆区创建新内存，实际上就是other的地址，other的地址是作为成员变量时自动分配的属性</span></span><br><span class="line">    <span class="comment">// 拷贝构造函数也是有参构造函数，区别就是，把源地址other.m_buffer完全拷贝到新开辟的m_buffer</span></span><br><span class="line">    <span class="built_in">String</span>(<span class="type">const</span> String&amp; other) <span class="comment">// 深拷贝，因为是字符串，所以一定带有终止符，在用一个对象初始化时，开辟新的内存</span></span><br><span class="line">        :<span class="built_in">m_Size</span>(other.m_Size)</span><br><span class="line">    &#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Copy&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">        m_Buffer = <span class="keyword">new</span> <span class="type">char</span>[m_Size + <span class="number">1</span>]; <span class="comment">//开辟一块新的内存</span></span><br><span class="line">        <span class="built_in">memcpy</span>(m_Buffer, other.m_Buffer, m_Size + <span class="number">1</span>); </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// String(const String&amp; other)</span></span><br><span class="line">    <span class="comment">// &#123;</span></span><br><span class="line">    <span class="comment">//     memcpy(this, &amp;other, sizeof(String)); 这个才是地址</span></span><br><span class="line">    <span class="comment">// this指针是类的一个自动生成、自动隐藏的私有成员，存在于类的非静态成员函数中，指向被调用函数所在的对象。</span></span><br><span class="line">    <span class="comment">// 也就是理解成当前对象的地址(拷贝到的地址)                                           </span></span><br><span class="line">    <span class="comment">// &#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">friend</span> std::ostream&amp; <span class="keyword">operator</span>&lt;&lt;(std::ostream&amp; stream, <span class="type">const</span> String&amp; string);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">std::ostream&amp; <span class="keyword">operator</span>&lt;&lt;(std::ostream&amp; stream, <span class="type">const</span> String&amp; string)</span><br><span class="line">&#123;</span><br><span class="line">    stream &lt;&lt; string.m_Buffer;</span><br><span class="line">    <span class="keyword">return</span> stream; </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 不改写成引用，会出现三次copy,const表示不能编辑现有的字符串</span></span><br><span class="line"><span class="comment">// 除此之外也意味着可以把临时的右值传递到实际的函数中, 出现三次的原因是调用了拷贝构造函数，而引用时不进行拷贝</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">PrintString</span><span class="params">(<span class="type">const</span> String&amp; string)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    std::cout &lt;&lt; string &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//调用有参构造函数生成cherno，然后复制给新对象，默认的拷贝是浅拷贝，只复制指针，&#x27;=&#x27;可以是浅也可以是深</span></span><br><span class="line">    String string = <span class="string">&quot;Cherno&quot;</span>; <span class="comment">//没有分配新的内存块来存储</span></span><br><span class="line">    <span class="comment">// 这里的 = 就是一次deepcopy 是必定会调用copy的</span></span><br><span class="line">    String second = string;  <span class="comment">// 当前一个对象被释放的时候，其指针成员变量一并被释放，导致这块内存无效。</span></span><br><span class="line">                             <span class="comment">// 而后一个对象的指针成员变量还是指向堆上的这块内存，当后一个对象被释放的时候它再次尝试释放堆上的这块内存，从而报错。</span></span><br><span class="line">    second[<span class="number">2</span>] = <span class="string">&#x27;a&#x27;</span>; <span class="comment">//引用不进行拷贝</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">PrintString</span>(string); <span class="comment">// 两个对象都得到了保留，没有出现内存重复释放的话意味着非引用的传参也是深拷贝</span></span><br><span class="line">    <span class="built_in">PrintString</span>(second); </span><br><span class="line">    std::cin.<span class="built_in">get</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>19.<strong>函数指针</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Hi</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Hi&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Hello</span><span class="params">(<span class="type">int</span> a)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Hello&quot;</span> &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; a &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">PrintValue</span><span class="params">(<span class="type">int</span> value)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Value:&quot;</span> &lt;&lt; value &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">ForEach</span><span class="params">(<span class="type">const</span> std::vector&lt;<span class="type">int</span>&gt;&amp; values, <span class="type">void</span>(*func)(<span class="type">int</span>))</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> value : values)</span><br><span class="line">        <span class="built_in">func</span>(value);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 函数指针是将一个函数赋值给一个变量的方法,</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// auto func = Hi(); 因为没有返回值，所以无法推断auto</span></span><br><span class="line">    <span class="comment">// auto func = Hi;</span></span><br><span class="line">    <span class="comment">// func();</span></span><br><span class="line">    <span class="comment">// 将function作为一个变量名进行调用，将函数参数化</span></span><br><span class="line">    <span class="built_in">void</span>(*func)() = Hi; <span class="comment">// 函数指针变量的命名是在中间</span></span><br><span class="line">    <span class="built_in">func</span>();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">typedef</span> <span class="title">void</span><span class="params">(*HiFunction1)</span><span class="params">()</span></span>; <span class="comment">// 为类型取一个新的名字，无参</span></span><br><span class="line">    HiFunction1 function1 = Hi;</span><br><span class="line">    <span class="built_in">function1</span>();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">typedef</span> <span class="title">void</span><span class="params">(*HiFunction2)</span><span class="params">(<span class="type">int</span>)</span></span>; <span class="comment">// 有参</span></span><br><span class="line">    HiFunction2 function2 = Hello; <span class="comment">// 需要改变这里的函数定义</span></span><br><span class="line">    <span class="built_in">function2</span>(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    std::vector&lt;<span class="type">int</span>&gt; values = &#123;<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>&#125;;</span><br><span class="line">    <span class="built_in">ForEach</span>(values, PrintValue);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">ForEach</span>(values, [](<span class="type">int</span> value) &#123; std::cout &lt;&lt; <span class="string">&quot;Value:&quot;</span> &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; value &lt;&lt; std::endl; &#125; );</span><br><span class="line">    std::cin.<span class="built_in">get</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">ForEach1</span><span class="params">(<span class="type">const</span> std::vector&lt;<span class="type">int</span>&gt;&amp; values, <span class="type">void</span>(*func)(<span class="type">int</span>))</span> <span class="comment">// 这里使用的是原始函数指针</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> value : values)</span><br><span class="line">        <span class="built_in">func</span>(value);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;functional&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">ForEach2</span><span class="params">(<span class="type">const</span> std::vector&lt;<span class="type">int</span>&gt; values, <span class="type">const</span> std::function&lt;<span class="type">void</span>(<span class="type">int</span>)&gt;&amp; func)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> value : values)</span><br><span class="line">        <span class="built_in">func</span>(value);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 只要有一个函数指针就可以用匿名函数lambda</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    std::vector&lt;<span class="type">int</span>&gt; values = &#123;<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>&#125;;</span><br><span class="line">    <span class="keyword">auto</span> it = std::<span class="built_in">find_if</span>(values.<span class="built_in">begin</span>(), values.<span class="built_in">end</span>(), [](<span class="type">int</span> value) &#123; <span class="keyword">return</span> value &gt; <span class="number">1</span>; &#125;); <span class="comment">// 返回迭代器，即满足条件的第一个元素</span></span><br><span class="line">    std::cout &lt;&lt; *it &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 前面的函数指针需要一个int参数 void(*func)(int),lambda指定未来想要运行的代码</span></span><br><span class="line">    <span class="keyword">auto</span> lambda = [](<span class="type">int</span> value) &#123; std::cout &lt;&lt; <span class="string">&quot;Value:&quot;</span> &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; value &lt;&lt; std::endl; &#125;;</span><br><span class="line">    <span class="built_in">ForEach1</span>(values, lambda);</span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> a = <span class="number">5</span>;</span><br><span class="line">    <span class="comment">// auto lambda = [](int value) &#123;std::cout &lt;&lt; &quot; Value:&quot; &lt;&lt; a &lt;&lt; std::endl;&#125;;      //不传递任何外部变量</span></span><br><span class="line">    <span class="keyword">auto</span> lambda1 = [=](<span class="type">int</span> value) &#123;std::cout &lt;&lt; <span class="string">&quot; Value:&quot;</span> &lt;&lt; a &lt;&lt; std::endl;&#125;;     <span class="comment">//拷贝这个变量然后传入，=a就是值传递a</span></span><br><span class="line">    <span class="keyword">auto</span> lambda2 = [&amp;](<span class="type">int</span> value) &#123;std::cout &lt;&lt; <span class="string">&quot; Value:&quot;</span> &lt;&lt; a &lt;&lt; std::endl;&#125;;     <span class="comment">//&amp;a就是引用传递a</span></span><br><span class="line">    std::cin.<span class="built_in">get</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>24.<strong>虚析构函数</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Base</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Base</span>() &#123; std::cout &lt;&lt; <span class="string">&quot;Base Constructed\n&quot;</span>; &#125;</span><br><span class="line">    <span class="comment">// 加了virtual意味着这个类有可能被扩展为子类，可能还有一个析构函数会被调用，需要调用派生类的析构函数(如果存在的话)</span></span><br><span class="line">    <span class="keyword">virtual</span> ~<span class="built_in">Base</span>() &#123; std::cout &lt;&lt; <span class="string">&quot;Base Destructed\n&quot;</span>; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Derived</span> : <span class="keyword">public</span> Base</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Derived</span>() &#123; m_array = <span class="keyword">new</span> <span class="type">int</span> [<span class="number">5</span>]; std::cout &lt;&lt; <span class="string">&quot;Derived Constructed\n&quot;</span>; &#125;</span><br><span class="line">    ~<span class="built_in">Derived</span>() &#123; <span class="keyword">delete</span>[] m_array; std::cout &lt;&lt; <span class="string">&quot;Derived Destructed\n&quot;</span>; &#125; <span class="comment">// 也就是这句话永远没有被调用，导致内存泄漏</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">int</span>* m_array;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Base* base = <span class="keyword">new</span> <span class="built_in">Base</span>();</span><br><span class="line">    <span class="keyword">delete</span> base;</span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;---------------\n&quot;</span>;</span><br><span class="line"></span><br><span class="line">    Derived* derived = <span class="keyword">new</span> <span class="built_in">Derived</span>();</span><br><span class="line">    <span class="keyword">delete</span> derived; </span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;---------------\n&quot;</span>;</span><br><span class="line"></span><br><span class="line">    Base* poly = <span class="keyword">new</span> <span class="built_in">Derived</span>(); <span class="comment">// 多态：基类指针指向派生类对象</span></span><br><span class="line">    <span class="keyword">delete</span> poly; <span class="comment">// 调用了派生类的构造函数但是没有调用其析构函数</span></span><br><span class="line"></span><br><span class="line">    std::cin.<span class="built_in">get</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>29.<strong>再探单例类</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// c++中的单例只是一种组织一堆全局变量和静态函数的方式</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Singleton</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Singleton</span>(<span class="type">const</span> Singleton&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">    <span class="function"><span class="type">static</span> Singleton&amp; <span class="title">Get</span><span class="params">()</span> <span class="comment">// 2.提供静态访问该类的方法,返回这种特定类型的引用或指针</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> s_Instance; <span class="comment">// 3.需要返回某种Singleton的实例，对于整个程序单例类只有一个实例</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">Function</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="built_in">Singleton</span>() &#123;&#125; <span class="comment">// 1.如果有公共的构造函数就会允许被实例化，不能在外部被实例化</span></span><br><span class="line">    <span class="type">float</span> m_Member = <span class="number">0.0f</span>;</span><br><span class="line">    <span class="type">static</span> Singleton s_Instance; <span class="comment">// 4.传统方法是在私有成员里创建单例类的静态实例</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">Singleton Singleton::s_Instance; <span class="comment">// 5.static需要类外定义, get方法可直接返回s_Instance</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Singleton::<span class="built_in">Get</span>().<span class="built_in">Function</span>(); <span class="comment">// 6.访问单例的方法</span></span><br><span class="line">    <span class="comment">// 7.如果这样做，单例的所有数据都被复制，所以通常要删除拷贝构造函数，标记其为delete</span></span><br><span class="line">    <span class="comment">// Singleton instance = Singleton::Get();</span></span><br><span class="line">    Singleton&amp; instance = Singleton::<span class="built_in">Get</span>(); <span class="comment">// 必须写成引用 或者auto&amp; .. = ..</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Random</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Random</span>(<span class="type">const</span> Random&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">    <span class="comment">// 单例的核心就是Get函数，此处有一个单独实例，它只会在第一次使用时创建，这个单例的生命周期就是应用的生命周期</span></span><br><span class="line">    <span class="comment">// 一旦有了这个单例，就能写任意数量的非静态方法并通过Get函数来访问它们</span></span><br><span class="line">    <span class="function"><span class="type">static</span> Random&amp; <span class="title">Get</span><span class="params">()</span> <span class="comment">// 2.提供静态访问该类的方法,返回这种特定类型的引用或指针</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">// 实际上是在函数内部有个静态变量，意味着它仍存在于内存中，一旦get函数被第一次调用就完成了实例化</span></span><br><span class="line">        <span class="comment">// 在余下时间里，它只是在静态内存中被引用，与之前一致</span></span><br><span class="line">        <span class="type">static</span> Random s_instance; <span class="comment">// 不放在成员变量里定义及类外初始化</span></span><br><span class="line">        <span class="keyword">return</span> s_instance; <span class="comment">// 3.需要返回某种Singleton的实例，对于整个程序单例类只有一个实例</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">float</span> <span class="title">OFloat</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> m_RandomGenerator; &#125;</span><br><span class="line">    <span class="comment">// 方法3-2：</span></span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">float</span> <span class="title">Float</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="built_in">Get</span>().<span class="built_in">IFloat</span>(); &#125; <span class="comment">// or Get().m_RandomGenerator</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 方法3-1：</span></span><br><span class="line">    <span class="function"><span class="type">float</span> <span class="title">IFloat</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> m_RandomGenerator; &#125; <span class="comment">// 因为不是静态函数所以可以访问所有成员，而不需要通过实例来访问</span></span><br><span class="line">    <span class="built_in">Random</span>() &#123;&#125; <span class="comment">// 1.如果有公共的构造函数就会允许被实例化，不能在外部被实例化</span></span><br><span class="line">    <span class="type">float</span> m_RandomGenerator = <span class="number">0.5f</span>;</span><br><span class="line">    <span class="comment">// static Random s_Instance; // 4.传统方法是在私有成员里创建单例类的静态实例</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Random Random::s_Instance; 这里的可以移至函数体内</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//方法1：</span></span><br><span class="line">    <span class="type">float</span> number = Random::<span class="built_in">Get</span>().<span class="built_in">OFloat</span>();</span><br><span class="line">    <span class="comment">// 方法2：auto&amp; random = Random::Get();</span></span><br><span class="line">    <span class="comment">//       float number = random.Float();</span></span><br><span class="line">    <span class="comment">// 方法3</span></span><br><span class="line">    <span class="comment">// float number = Random::Float();</span></span><br><span class="line">    std::cout &lt;&lt; number &lt;&lt; std::endl;</span><br><span class="line">    std::cin.<span class="built_in">get</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>32.<strong>移动语义</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 类Entity含有一个成员Name为String类型，如果要用常量字符串来初始化这个类，就会先调用String的构造函数，再调用String的拷贝构造函数（经Entity构造函数里面调用），然后再调用String的析构函数，但是使用move操作就可以让中间的一次拷贝变成move，就可以少一次new</span></span><br><span class="line"><span class="comment">// 在实例化entity的时候，如果传入的是字符串常量（右值），则会调用拷贝的右值版本，避免了一次new，如果传入的是String（左值），则仍然会进行一次左值拷贝</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">String</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">String</span>() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">String</span>(<span class="type">const</span> <span class="type">char</span>* string)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Created\n&quot;</span>);</span><br><span class="line">        m_Size = <span class="built_in">strlen</span>(string);</span><br><span class="line">        m_Data = <span class="keyword">new</span> <span class="type">char</span>[m_Size];</span><br><span class="line">        <span class="built_in">memcpy</span>(m_Data, string, m_Size);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">String</span>(<span class="type">const</span> String&amp; other)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Copied\n&quot;</span>);</span><br><span class="line">        m_Size = other.m_Size;</span><br><span class="line">        m_Data = <span class="keyword">new</span> <span class="type">char</span>[m_Size]; <span class="comment">// 分配一个新的数据缓冲区，然后逐个复制所有的数据，将整个数据块复制到这个新的数据块中</span></span><br><span class="line">        <span class="built_in">memcpy</span>(m_Data, other.m_Data, m_Size);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">String</span>(String&amp;&amp; other) <span class="keyword">noexcept</span>  <span class="comment">// 不应该抛出异常，通过制定这个构造函数，希望除去复制</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Moved\n&quot;</span>);</span><br><span class="line">        m_Size = other.m_Size;</span><br><span class="line">        m_Data = other.m_Data; <span class="comment">// 简单地将指针赋值，指向m_Data,other.m_Data就是原来的字符串缓冲区的指针</span></span><br><span class="line">        <span class="comment">// 旧的字符串基本为空，当旧实例被销毁时，delete实际上会删除nullptr,删除nullptr相当于啥也没干</span></span><br><span class="line">        <span class="comment">// 实际上只是接管了那个旧的字符串，而不是通过复制所有的数据和分配新的内存来进行深拷贝</span></span><br><span class="line">        <span class="comment">// 实际上是浅拷贝，只是重新连接了指针</span></span><br><span class="line">        other.m_Size = <span class="number">0</span>;</span><br><span class="line">        other.m_Data = <span class="literal">nullptr</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ~<span class="built_in">String</span>() </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Destroyed\n&quot;</span>);</span><br><span class="line">        <span class="keyword">delete</span> m_Data;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">Print</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; m_Size; i++)</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;%c&quot;</span>, m_Data[i]);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">char</span>* m_Data;</span><br><span class="line">    <span class="type">uint32_t</span> m_Size;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Entity</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Entity</span>(<span class="type">const</span> String&amp; name)</span><br><span class="line">        : <span class="built_in">m_Name</span>(name) &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">Entity</span>(String&amp;&amp; name) <span class="comment">// 添加一个新的构造函数，接收一个临时参数</span></span><br><span class="line">        <span class="comment">// : m_Name(name) &#123;&#125; 仍然出现copy</span></span><br><span class="line">        <span class="comment">// : m_Name((String&amp;&amp;)name) &#123;&#125; // 显式地转化为一个临时对象,只分配了一次内存，将字符串移动至Entity类中，没有copy出现了move</span></span><br><span class="line">        : <span class="built_in">m_Name</span>(std::<span class="built_in">move</span>(name)) &#123;&#125; <span class="comment">// 实践中不会像上一行那样去写，但本质是一样的</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">PrintName</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        m_Name.<span class="built_in">Print</span>();</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    String m_Name;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// Entity entity(String(&quot;Kwx&quot;)); String(&quot;Kwx&quot;) | 实例以值传递的方式传递给函数参数时，会调用拷贝构造函数</span></span><br><span class="line">    <span class="function">Entity <span class="title">entity</span><span class="params">(<span class="string">&quot;Kwx&quot;</span>)</span></span>; <span class="comment">// 隐式构造函数 </span></span><br><span class="line">    entity.<span class="built_in">PrintName</span>(); <span class="comment">// 产生了copy意味着数据被复制，复制一个字符串需要在堆上分配内存，需要调用new char</span></span><br><span class="line">    std::cin.<span class="built_in">get</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>33.<strong>赋值运算符</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">String</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">String</span>() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">String</span>(<span class="type">const</span> <span class="type">char</span>* string)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Created\n&quot;</span>);</span><br><span class="line">        m_Size = <span class="built_in">strlen</span>(string);</span><br><span class="line">        m_Data = <span class="keyword">new</span> <span class="type">char</span>[m_Size];</span><br><span class="line">        <span class="built_in">memcpy</span>(m_Data, string, m_Size);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">String</span>(<span class="type">const</span> String&amp; other)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Copied\n&quot;</span>);</span><br><span class="line">        m_Size = other.m_Size;</span><br><span class="line">        m_Data = <span class="keyword">new</span> <span class="type">char</span>[m_Size];</span><br><span class="line">        <span class="built_in">memcpy</span>(m_Data, other.m_Data, m_Size);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">String</span>(String&amp;&amp; other) <span class="keyword">noexcept</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Moved\n&quot;</span>);</span><br><span class="line">        m_Size = other.m_Size;</span><br><span class="line">        m_Data = other.m_Data;</span><br><span class="line">        other.m_Size = <span class="number">0</span>; <span class="comment">// 移动后原位置肯定为空了</span></span><br><span class="line">        other.m_Data = <span class="literal">nullptr</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 实际上没有像在移动构造函数中那样创建新对象，而是把另一个对象移动到自身这个当前对象中，所以需要覆盖当前对象</span></span><br><span class="line">    <span class="comment">// 因为当前对象可能已经分配了一些内存，如果设置m_Data等于另一个指针就会造成内存泄漏，因为没有办法删除旧的数据</span></span><br><span class="line">    <span class="comment">// 所以 1.首先删除当前数据，因为我们要把另一个对象移到自己这里 2.重新赋值所有变量,然后确保other对象处于正确状态</span></span><br><span class="line">    <span class="comment">// 通常在赋值操作符中还需要确保当前对象不等于另一个对象</span></span><br><span class="line">    String&amp; <span class="keyword">operator</span>=(String&amp;&amp; other) <span class="keyword">noexcept</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Moved!\n&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span> != &amp;other)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">delete</span>[] m_Data;</span><br><span class="line">            m_Size = other.m_Size;</span><br><span class="line">            m_Data = other.m_Data;</span><br><span class="line">            other.m_Size = <span class="number">0</span>;</span><br><span class="line">            other.m_Data = <span class="literal">nullptr</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ~<span class="built_in">String</span>() </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Destroyed\n&quot;</span>);</span><br><span class="line">        <span class="keyword">delete</span> m_Data;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">Print</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; m_Size; i++)</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;%c&quot;</span>, m_Data[i]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">char</span>* m_Data;</span><br><span class="line">    <span class="type">uint32_t</span> m_Size;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Entity</span> <span class="comment">// Entity是一个额外的间接层</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Entity</span>(<span class="type">const</span> String&amp; name)</span><br><span class="line">        : <span class="built_in">m_Name</span>(name) &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">Entity</span>(String&amp;&amp; name)</span><br><span class="line">        : <span class="built_in">m_Name</span>(std::<span class="built_in">move</span>(name)) &#123;&#125; <span class="comment">// std::move把一个字符串转化为临时变量</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">PrintName</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        m_Name.<span class="built_in">Print</span>();</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    String m_Name;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function">Entity <span class="title">entity</span><span class="params">(<span class="string">&quot;Kwx&quot;</span>)</span></span>; <span class="comment">// 赋值操作符只是在做一个隐式转换并调用这个特定的字符串构造函数</span></span><br><span class="line">    entity.<span class="built_in">PrintName</span>();</span><br><span class="line"></span><br><span class="line">    String string = <span class="string">&quot;Hi&quot;</span>;</span><br><span class="line">    <span class="comment">// String dest = string; // 字符串复制到新变量，怎么把它移动到新变量呢？</span></span><br><span class="line">    <span class="comment">// String dest((String&amp;&amp;)string); // 并不优雅且也不支持所有类型例如auto</span></span><br><span class="line">    <span class="function">String <span class="title">dest1</span><span class="params">(std::move(string))</span></span>; <span class="comment">// 也可以 String dest = std::move(string)</span></span><br><span class="line">    <span class="comment">// 思路：1.肯定要先把它变成一个临时值 2.那就需要让它使用这个move构造函数，因为那块代码是从other窃取了资源</span></span><br><span class="line">    <span class="comment">// 3.从一种类型转换到另一种类型cast 4.使用一个更灵活的函数在编译时自动找出输入的类型</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 赋值操作符：仅当把一个变量赋值给一个已有的变量时才会被调用</span></span><br><span class="line">    String apple = <span class="string">&quot;Apple&quot;</span>;</span><br><span class="line">    String dest2;</span><br><span class="line">    <span class="comment">// String dest3 = std::move(apple); 这里并没有调用赋值操作符，只是构造了一个新字符串,这里是移动构造函数</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Apple: &quot;</span>);</span><br><span class="line">    apple.<span class="built_in">Print</span>();</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;dest: &quot;</span>);</span><br><span class="line">    dest2.<span class="built_in">Print</span>();</span><br><span class="line">    <span class="comment">// dest = apple; // should cause error</span></span><br><span class="line">    <span class="comment">// dest2 = std::move(apple); // 转移了整个字符数组的所有权没做任何复制、任何分配或接触分配之类的事</span></span><br><span class="line">    dest2.<span class="keyword">operator</span>=(std::<span class="built_in">move</span>(apple)); <span class="comment">// 这是赋值运算符</span></span><br><span class="line">    <span class="comment">// 赋值操作符与使用构造函数的区别：使用运算符相当于 .operator=...,并像调用函数一样调用它</span></span><br><span class="line">    <span class="comment">// 开偷！</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Apple: &quot;</span>);</span><br><span class="line">    apple.<span class="built_in">Print</span>();</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;dest: &quot;</span>);</span><br><span class="line">    dest2.<span class="built_in">Print</span>();</span><br><span class="line"></span><br><span class="line">    std::cin.<span class="built_in">get</span>(); <span class="comment">// apple的析构函数什么都没做，因为它试图删除一个数组而这个数组已被设为空指针</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// c++三法则：如果需要析构函数，则一定需要拷贝构造函数和新移动语义</span></span><br></pre></td></tr></table></figure>

<h4 id="3-C-Primer"><a href="#3-C-Primer" class="headerlink" title="3.C++ Primer"></a>3.C++ Primer</h4><p>字符串字面值的类型实际上就是由常量字符构成的数组</p>
<p>对象是指一块具有某种类型的内存</p>
<p>初始化变量时，初始值会被拷贝到新建的对象中；定义引用时，程序将引用与它的初始值绑定在一起，并非将初始值拷贝给引用</p>
<p>引用并非对象，所以不能定义引用的引用，也不能定义指向引用的指针</p>
<p>指针存放某个对象的地址</p>
<p>对指针的引用进行赋值，也就等价于让指针指向新值</p>
<p>引用绑定到常量上形成常量引用，常量引用不能修改其绑定的对象</p>
<p>非常量引用的初始值必须是左值，不能是表达式</p>
<p>允许常量引用绑定非常量的对象、字面值甚至表达式</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> i = <span class="number">7</span>;</span><br><span class="line"><span class="type">int</span>&amp; a = i;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span>&amp; b = i; <span class="comment">// b也绑定i，但不允许通过b来修改i的值</span></span><br><span class="line">a = <span class="number">0</span>; <span class="comment">// 非常量可以改</span></span><br><span class="line">b = <span class="number">0</span>; <span class="comment">// Error 常量不可改,但是可以通过 i = 1</span></span><br></pre></td></tr></table></figure>

<p>普通指针不能指向常量对象</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span>* <span class="type">const</span> 常量指针 顶层(右-&gt;左) 可以指向非常量</span><br><span class="line"><span class="type">const</span> <span class="type">int</span>* 指向常量的指针，因为不能改*p 底层</span><br></pre></td></tr></table></figure>

<p>顶层const表示指针本身是个常量，底层表示指针所指的对象是一个常量</p>
<p>拷贝时，顶层const不会产生阻碍，拷入拷出的对象必须具有相同的底层const资格</p>
<p>关于顶层与底层：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">int</span> <span class="comment">// 顶层</span></span><br><span class="line"><span class="type">const</span> <span class="type">int</span>* <span class="comment">// 底层</span></span><br><span class="line"><span class="type">int</span>* <span class="type">const</span> <span class="comment">// 顶层</span></span><br></pre></td></tr></table></figure>

<p>auto会忽略顶层const(如果需要则必须声明)，保留底层const：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">int</span> i = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">auto</span> b = &amp;i;</span><br><span class="line">*b = <span class="number">2</span>; <span class="comment">// 不能更改，因为对常量(const)取地址为底层const: const int* </span></span><br></pre></td></tr></table></figure>

<p>区分什么是拷贝，什么是声明，带有类型的是声明，不带的是拷贝</p>
<p>是声明则比较是否常量指针&#x2F;引用，非常量不能指向&#x2F;绑定常量对象</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 不能用字面值初始化一个非常量引用</span></span><br><span class="line"><span class="keyword">auto</span>&amp; a = <span class="number">42</span>; <span class="comment">// 引用需要绑定一个对象：一块具有类型的内存</span></span><br></pre></td></tr></table></figure>

<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&amp; 取地址作用于左值，返回的指针是右值</span><br><span class="line">* 解引用 [] 下标 求值结果都为左值</span><br></pre></td></tr></table></figure>

<p>调用一个返回引用的函数得到左值，其他返回类型得到右值</p>
<p>允许将指向非常量类型的指针（引用）转换成相应的常量类型的指针（引用）</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> i;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span>* j = &amp;i;</span><br></pre></td></tr></table></figure>

<p>相反的转换并不存在，因为它试图删除底层const</p>
<p>非常量不能指向&#x2F;绑定常量对象；可以使用非常量来初始化一个底层const对象，反之不行；</p>
<p>一个普通的引用必须用同类型的对象初始化</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">reset</span><span class="params">(<span class="type">int</span>*)</span></span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">reset</span><span class="params">(<span class="type">int</span>&amp;)</span> </span></span><br><span class="line"><span class="function"><span class="type">int</span> i </span>= <span class="number">0</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span>&amp; ci = i;</span><br><span class="line"><span class="built_in">reset</span>(&amp;ci) <span class="comment">// Error int* _ = &amp;ci is wrong</span></span><br><span class="line"><span class="built_in">reset</span>(ci) <span class="comment">// Error int&amp; _ = ci is wrong </span></span><br><span class="line"><span class="built_in">reset</span>(<span class="number">42</span>) <span class="comment">// Error 不能把普通引用绑定于字面值</span></span><br></pre></td></tr></table></figure>

<p>当初始化变量 以及 以值传递的方式传递或返回一个对象时，会发生拷贝</p>
<p>构造函数不能声明为const</p>
<p>友元允许其他类或函数访问它的非公有成员</p>
<p>this是一个常量指针，不允许改变其保存的地址（顶层const）</p>
<p>拷贝构造函数的参数必须是引用，否则需要拷贝实参，为了拷贝实参又需要调用拷贝构造，陷入循环</p>
<p>重载运算符本质上是函数，也有其返回类型与参数列表。如果一个运算符是成员函数，其左侧运算对象就绑定到隐式的this参数</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Foo</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	Fool&amp; <span class="keyword">operator</span>=(<span class="type">const</span> Foo&amp;) <span class="comment">// 拷贝赋值运算符接受一个与其所在类相同类型的参数:</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>需要析构函数的类也需要拷贝与赋值操作</p>
<p>需要拷贝操作的类也需要赋值操作，反之亦然</p>
<p>右值引用：只能被绑定到一个将要被销毁的对象</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> i = <span class="number">42</span>;</span><br><span class="line"><span class="type">int</span>&amp;&amp; r1 = i; <span class="comment">// Error: 不能将一个右值引用绑定到一个左值上</span></span><br><span class="line"><span class="type">const</span> <span class="type">int</span>&amp; r2 = i * <span class="number">42</span>; <span class="comment">// Right.</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;utility&gt;</span></span></span><br><span class="line"><span class="type">int</span>&amp;&amp; r3 = std::<span class="built_in">move</span>(r1) <span class="comment">// Right.调用move就意味着承诺，除了将其赋值或销毁外不将它用于额外用途</span></span><br></pre></td></tr></table></figure>

<p>子类不能访问父类的private，但能通过父类的protected、private方法间接访问父类的private</p>
<p>子类通过public继承不会改变父类的数据属性；protected继承private是private，其余都是protected；private继承全是private</p>
<p>父类的原属性并没改变，降级的是子类在父类的个别成员属性</p>
<h2 id="2023"><a href="#2023" class="headerlink" title="2023"></a>2023</h2><h4 id="1-Cpp-1"><a href="#1-Cpp-1" class="headerlink" title="1.Cpp"></a>1.Cpp</h4><p>std::move &amp;&amp; std::forward：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/384316039">https://zhuanlan.zhihu.com/p/384316039</a></p>
<p>具名的右值引用是一个左值</p>
<p>std::forward ，可以保持原始参数的类型，将实参从右值引用的左值，变成了本身就是右值引用</p>
<p>decltype：<a target="_blank" rel="noopener" href="http://c.biancheng.net/view/7151.html">http://c.biancheng.net/view/7151.html</a></p>
<p>restrict: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/349726808">https://zhuanlan.zhihu.com/p/349726808</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/04/05/HPC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/04/05/HPC/" class="post-title-link" itemprop="url">HPC</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-04-05 12:46:44" itemprop="dateCreated datePublished" datetime="2023-04-05T12:46:44+08:00">2023-04-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-02-06 20:21:39" itemprop="dateModified" datetime="2024-02-06T20:21:39+08:00">2024-02-06</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p> [2022](# 2022)</p>
<p>– [1.Vim](# 1.Vim)</p>
<p>– [2.HPC](# 2.HPC)</p>
<p>[2023](# 2023)</p>
<p>– [1.CMake](# 1.CMake)</p>
<p>– [2.HPC Xiaopeng](# 2.HPC Xiaopeng)</p>
<p>  – [01.CMake](# 01.CMake)</p>
<p>  – [02.RAII &amp; 智能指针](# 02.RAII &amp; 智能指针)</p>
<p>  – [03.模板元编程与函数式](# 03.模板元编程与函数式)</p>
<p>  – [04.编译器优化与SIMD指令](# 04.编译器优化与SIMD指令)</p>
<p>  – [05.多线程](# 05.多线程)</p>
<p>  – [06.访存优化](# 06.访存优化)</p>
<p>  – [07.CUDA](# 07.CUDA)</p>
<p>  – [08.C语言指针](# 08.C语言指针)</p>
<p>– [3.线程池](# 3.线程池)</p>
<p>– [4.编译 &amp; 链接](# 4.编译 &amp; 链接)</p>
<p>– [5.CUDA](# 5.CUDA)</p>
<h2 id="2022"><a href="#2022" class="headerlink" title="2022"></a>2022</h2><h4 id="1-Vim"><a href="#1-Vim" class="headerlink" title="1.Vim"></a>1.Vim</h4><p>w右跳到下一个单词开头 W还能无视一些符号(破折号)  b 向左    e跳转到下一个单词的末尾</p>
<p>:w test.txt   :wqa  qa退出所有窗口   ZZ 退出 ZQ不保存退出</p>
<p>0 $ 行首行尾 ^非空格行首  3$ 下3行的行尾     3- 上3行 + 下 跳到行首</p>
<p>v(visualize) bve选中单词   u撤销</p>
<p>x删除 d在normal模式下还会继续等待输入   D &#x3D; d$ 直接删至行尾 </p>
<p>cw直接删掉并立即进入插入模式 cw&#x3D;dwi c3w cW</p>
<p>g跳转到第一行 G跳转到最后一行 66G(行尾)66gg(行首)</p>
<p>&#x2F;kwx向下查找 n跳转到下一个  N往上     ？向上找 n上N下    单词# 向上找 *向下找</p>
<p>选中当前单词bve viw    c修改   ciw b 修改a&#x3D;x为b&#x3D;x</p>
<p>f b 查找第一个b ；跳转下一个     cf&#x3D; cfb 当前到&#x3D;(b)全部重命名 包含&#x3D;     ct&#x3D; 不包含&#x3D;</p>
<p>I# 在^处变为注释    I当前行开头插入 A末尾      i向前插入 a向后插入 insert append</p>
<p>录制宏：q u xj q 录入u寄存器 5@u反复调用 j向下</p>
<p>:norm 0x 0行首 即删除行首注释    :norm I重新注释 </p>
<p>ctrl+u &#x2F; d   上下翻页   ctrl+y &#x2F; e 上下单行</p>
<p>:s&#x2F;debian&#x2F;ubuntu&#x2F;g多次文本替换    全局替换：ggVG全部选中  或将标记符换成% </p>
<p>o向下新起一行插入 O向上    5o world自动创建5行world</p>
<p>D&#x3D;d$ 删除该行后续内容 C&#x3D;c$额外进入insert</p>
<p>vi&lt;  va&lt; 选中&lt;&gt;内&#x2F;包含&lt;&gt;的内容  “同理</p>
<p>ciw修改当前word caw会连同当前空格一并修改</p>
<p>%可以在两头的{}互换   &lt;&lt;减小缩进 &gt;&gt;增大   &#x3D;&#x3D;自动调整缩进</p>
<p>vi {选中花括号内 a含{}    {上一段落  }下   ()在多个函数之间跳转</p>
<p>ggvG :s&#x2F;\s*$&#x2F;&#x2F; 去除末尾不该有的空格</p>
<p>v选择 V选择整行 y复制  yyp 向后复制1行 yyP向前</p>
<p>dd删除一整行  ddp互换两行   xp交换两个字符的位置</p>
<p>5s修改当前5个字符    r仅修改当前字符</p>
<p>:sh g++ tset.cpp &amp;&amp; .&#x2F;a.out   exit &#x2F; ctrl+d         :nnoremap &lt;F8&gt; : sh &lt;CR&gt;</p>
<p>%可以直接替换当前的文件名   :nnoremap &lt;F5&gt; :wa&lt;CR&gt;::!g++ test.cpp -o a.out &amp;&amp; .&#x2F;a.out&lt;CR&gt;</p>
<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">run: hello</span></span><br><span class="line">	./hello</span><br><span class="line"><span class="section">hello: hello.cpp</span></span><br><span class="line">	g++ hello.cpp -o hello</span><br></pre></td></tr></table></figure>

<p>:make    :cw直接进入调错窗口   </p>
<p>ctrl+i  ctrl+o 历史页面跳转   gf向内跳转</p>
<p>:ls查看缓冲区    :b1跳转到1号缓冲</p>
<h4 id="2-HPC"><a href="#2-HPC" class="headerlink" title="2.HPC"></a>2.HPC</h4><p>1.1.1 Protobuffer语法释义：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/419954657">https://zhuanlan.zhihu.com/p/419954657</a></p>
<p>1.1.2 编解码：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/420385869">https://zhuanlan.zhihu.com/p/420385869</a></p>
<p>1.1.3 flatbuffer初次使用：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/423382566">https://zhuanlan.zhihu.com/p/423382566</a></p>
<p>cmake -G “Unix Makefiles” -DCMAKE_BUILD_TYPE&#x3D;Release</p>
<p>生成flatc，得到net_generated.h </p>
<p>1.1.4 寻址：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/423382972">https://zhuanlan.zhihu.com/p/423382972</a></p>
<p>1.3.1 图优化：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/358469896">https://zhuanlan.zhihu.com/p/358469896</a></p>
<p>arm-neon(single instruction, multiple data)单指令多数据协处理器</p>
<p>寄存器：32$\times$64-bit D 可组成16$\times$128-bit Q</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/358603760">arm neon指北进阶</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/388683540">ARM汇编入门指南1 “Hello World”</a></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">.text</span><br><span class="line">    .file   <span class="string">&quot;main.c&quot;</span></span><br><span class="line">    .globl  main                            <span class="comment">// -- Begin function main</span></span><br><span class="line">    .p2align    <span class="number">2</span></span><br><span class="line">    .type   main,@function</span><br><span class="line">main:                                   <span class="comment">// @main</span></span><br><span class="line"><span class="comment">// %bb.0:</span></span><br><span class="line">    sub sp, sp, #<span class="number">32</span>                     <span class="comment">// =32   申请32bytes的栈空间</span></span><br><span class="line">    stp x29, x30, [sp, #<span class="number">16</span>]             <span class="comment">// 16-byte Folded Spill  将 FP(x29), LR(x30) 保存在栈上</span></span><br><span class="line">    add x29, sp, #<span class="number">16</span>                    <span class="comment">// =16   缩小栈大小16bytes </span></span><br><span class="line">    mov w8, wzr                         <span class="comment">// 将 zero寄存器的值0 移动到 w8 寄存器</span></span><br><span class="line">    stur    wzr, [x29, #<span class="number">-4</span>]             <span class="comment">// 将[x29,#-4]地址的内存重置为0</span></span><br><span class="line">    adrp    x0, .L.str                  <span class="comment">// 将字符串所在的页的基地址加载到x0</span></span><br><span class="line">    add x0, x0, :lo12:.L.str            <span class="comment">// 计算字符串的偏移地址，保存到x0</span></span><br><span class="line">    str w8, [sp, #<span class="number">8</span>]                    <span class="comment">// 4-byte Folded Spill,w8的值保存到[sp,#8]的内存地址上</span></span><br><span class="line">    bl  <span class="built_in">printf</span></span><br><span class="line">    ldr w8, [sp, #<span class="number">8</span>]                    <span class="comment">// 4-byte Folded Reload，加载数值到寄存器</span></span><br><span class="line">    mov w0, w8</span><br><span class="line">    ldp x29, x30, [sp, #<span class="number">16</span>]             <span class="comment">// 16-byte Folded Reload，还原之前保存在栈内存上的FP，LR值到x2fp,lr</span></span><br><span class="line">    add sp, sp, #<span class="number">32</span>                     <span class="comment">// =32</span></span><br><span class="line">    ret</span><br><span class="line">.Lfunc_end0:</span><br><span class="line">    .size   main, .Lfunc_end0-main</span><br><span class="line">                                        <span class="comment">// -- End function</span></span><br><span class="line">    .type   .L.str,@object                  <span class="comment">// @.str</span></span><br><span class="line">    .section    .rodata.str1<span class="number">.1</span>,<span class="string">&quot;aMS&quot;</span>,@progbits,<span class="number">1</span></span><br><span class="line">.L.str:</span><br><span class="line">    .asciz  <span class="string">&quot;Hello World!\n&quot;</span></span><br><span class="line">    .size   .L.str, <span class="number">14</span></span><br><span class="line"></span><br><span class="line">    .ident  <span class="string">&quot;Android (7155654, based on r399163b1) clang version 11.0.5 (https://android.googlesource.com/toolchain/llvm-project 87f1315dfbea7c137aa2e6d362dbb457e388158d)&quot;</span></span><br><span class="line">    .section    <span class="string">&quot;.note.GNU-stack&quot;</span>,<span class="string">&quot;&quot;</span>,@progbits</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/393077446">ARM汇编入门指南2</a></p>
<p>栈上实例化对象：</p>
<p>在函数一开始的位置使用sub申请一块新的栈空间，使用STP将x29(sp)和x30(lr)寄存器的值备份到栈内存；函数结束的时候使用ldp将栈上备份的值还原到sp与lr</p>
<p>2.1.1 ARM汇编基础: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/524208867">https://zhuanlan.zhihu.com/p/524208867</a></p>
<p>2.2.1 Neon 初步使用：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/524229060">https://zhuanlan.zhihu.com/p/524229060</a></p>
<p>2.2.2 Neon加速卷积推理： <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/524335501">https://zhuanlan.zhihu.com/p/524335501</a></p>
<p>img2col原理：<a target="_blank" rel="noopener" href="https://blog.csdn.net/Mrhiuser/article/details/52672824">https://blog.csdn.net/Mrhiuser/article/details/52672824</a></p>
<p>4.2.1 Winograd卷积：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/524344248">https://zhuanlan.zhihu.com/p/524344248</a></p>
<p>注意看公式(6)及思路3</p>
<p>4.2.2 ncnn实现winograd: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/524355496">https://zhuanlan.zhihu.com/p/524355496</a></p>
<p><strong>kernel_transform</strong></p>
<p>step2 reshape 单个的flatten然后拼接</p>
<p>step3 reorder：改变了内存排布</p>
<p>**input_transform **</p>
<p>step1：重叠部分铺开</p>
<p>step2：每个tile的同一位置的元素连成”tiles”块</p>
<p>step3：细看第一张图即可理解，mod8，mod4</p>
<p>4.3 C4排布加速卷积实现：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/524423507">https://zhuanlan.zhihu.com/p/524423507</a></p>
<p>nc4hw4：正视图的h及w，侧面就是c，有多少个积木块就是b</p>
<h2 id="2023"><a href="#2023" class="headerlink" title="2023"></a>2023</h2><h4 id="1-CMake"><a href="#1-CMake" class="headerlink" title="1.CMake"></a>1.CMake</h4><p><a target="_blank" rel="noopener" href="https://www.bookstack.cn/read/CMake-Cookbook/README.md">https://www.bookstack.cn/read/CMake-Cookbook/README.md</a></p>
<p>在开发过程碰到需要在上级目录中构建，而源代码又分别写在下级目录的情况，同时又要根据不同的情况选择性地添加不同的源代码进行编译，所以考虑将需要编译的源代码放到一个 cmake 列表中。但是 set() 对应生成的变量都是局部变量（即不同的目录下不共用），于是使用 set_property() 命令。</p>
<p>undefined reference to “main”：-nostartfiles</p>
<p>undefined symbol：<a target="_blank" rel="noopener" href="https://blog.csdn.net/buknow/article/details/96130049">https://blog.csdn.net/buknow/article/details/96130049</a></p>
<p>PUBLIC: 在public后面的库会被Link到你的target中，并且里面的符号也会被导出，提供给第三方使用<br>PRIVATE: 在private后面的库仅被link到你的target中，并且终结掉，第三方不能感知你调了啥库INTERFACE: 在interface后面引入的库不会被链接到你的target中，只会导出符号<br><a target="_blank" rel="noopener" href="https://blog.csdn.net/znsoft/article/details/119035578">https://blog.csdn.net/znsoft/article/details/119035578</a> </p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建库 --&gt; 生成可执行文件 --&gt; 链接</span></span><br><span class="line"><span class="keyword">add_library</span>(<span class="keyword">message</span></span><br><span class="line">  STATIC</span><br><span class="line">    <span class="keyword">Message</span>.hpp</span><br><span class="line">    <span class="keyword">Message</span>.cpp</span><br><span class="line">  )</span><br><span class="line"><span class="keyword">add_executable</span>(hello-world hello-world.cpp)</span><br><span class="line"><span class="keyword">target_link_libraries</span>(hello-world <span class="keyword">message</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 寻找 python 解释器，这是一个REQUIRED依赖</span></span><br><span class="line"><span class="keyword">find_package</span>(PythonInterp REQUIRED)</span><br><span class="line"><span class="comment"># Python 头文件和库的模块，称为FindPythonLibs.cmake</span></span><br><span class="line"><span class="keyword">find_package</span>(PythonLibs <span class="variable">$&#123;PYTHON_VERSION_MAJOR&#125;</span>.<span class="variable">$&#123;PYTHON_VERSION_MINOR&#125;</span> EXACT REQUIRED)</span><br><span class="line"><span class="comment"># 执行 python 命令</span></span><br><span class="line"><span class="keyword">execute_process</span>(</span><br><span class="line">  <span class="keyword">COMMAND</span></span><br><span class="line">      <span class="variable">$&#123;PYTHON_EXECUTABLE&#125;</span> <span class="string">&quot;-c&quot;</span> <span class="string">&quot;print(&#x27;Hello, world!&#x27;)&quot;</span></span><br><span class="line">  RESULT_VARIABLE _status</span><br><span class="line">  OUTPUT_VARIABLE _helftflo_world</span><br><span class="line">  ERROR_QUIET</span><br><span class="line">  OUTPUT_STRIP_TRAILING_WHITESPACE</span><br><span class="line">  )</span><br><span class="line">  </span><br><span class="line"><span class="comment"># PYTHONINTERP_FOUND：是否找到解释器</span></span><br><span class="line"><span class="comment"># PYTHON_EXECUTABLE：Python解释器到可执行文件的路径</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 软件包没有安装在标准位置时，CMake无法正确定位它们,可使用CLI的-D参数告诉CMake查看特定的位置</span></span><br><span class="line">$ cmake -D PYTHON_EXECUTABLE=/custom/location/python ..</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可执行文件包含Python.h头文件，因此这个目标的include目录必须包含Python的include目录</span></span><br><span class="line"><span class="keyword">target_include_directories</span>(hello-embedded-python</span><br><span class="line">  PRIVATE</span><br><span class="line">      <span class="variable">$&#123;PYTHON_INCLUDE_DIRS&#125;</span></span><br><span class="line">    )</span><br><span class="line"><span class="comment"># 将可执行文件链接到 Python 库</span></span><br><span class="line"><span class="keyword">target_link_libraries</span>(hello-embedded-python</span><br><span class="line">  PRIVATE</span><br><span class="line">      <span class="variable">$&#123;PYTHON_LIBRARIES&#125;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检测 Eigen 库</span></span><br><span class="line">https://www.bookstack.cn/read/CMake-Cookbook/content-chapter3-<span class="number">3.7</span>-chinese.md</span><br></pre></td></tr></table></figure>

<p>其他常用操作：</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br></pre></td><td class="code"><pre><span class="line">$ cmake --build . -- VERBOSE=<span class="number">1</span>  &lt;==&gt; make 但是能跨平台 不然其他生成器如 Ninja 可能就不奏效了</span><br><span class="line">$ cmake -D CMAKE_CXX_COMPILER=clang++ ..</span><br><span class="line">$ cmake --system-information information.txt</span><br><span class="line">$ cmake -D CMAKE_CXX_FLAGS=<span class="string">&quot;-fno-exceptions -fno-rtti&quot;</span> .. <span class="comment"># 编译项目时，禁用异常和运行时类型标识(RTTI)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">option</span>(USE_LIBRARY <span class="string">&quot;Compile sources into a library&quot;</span> <span class="keyword">OFF</span>) </span><br><span class="line"></span><br><span class="line"><span class="keyword">include</span>(CMakeDependentOption)</span><br><span class="line"><span class="comment"># 相当于 if M_S_L==off: U_L=on</span></span><br><span class="line">cmake_dependent_option(</span><br><span class="line">    MAKE_STATIC_LIBRARY <span class="string">&quot;Compile sources into a static library&quot;</span> <span class="keyword">OFF</span></span><br><span class="line">    <span class="string">&quot;USE_LIBRARY&quot;</span> <span class="keyword">ON</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 缓存变量，可通过缓存编辑 默认的构建类型</span></span><br><span class="line"><span class="keyword">if</span>(<span class="keyword">NOT</span> CMAKE_BUILD_TYPE)</span><br><span class="line">    <span class="keyword">set</span>(CMAKE_BUILD_TYPE Release CACHE <span class="keyword">STRING</span> <span class="string">&quot;Build type&quot;</span> FORCE)</span><br><span class="line"><span class="keyword">endif</span>()</span><br><span class="line"><span class="keyword">message</span>(STATUS <span class="string">&quot;Build type: $&#123;CMAKE_BUILD_TYPE&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印编译器标志</span></span><br><span class="line"><span class="keyword">message</span>(<span class="string">&quot;C++ compiler flags: $&#123;CMAKE_CXX_FLAGS&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置编译选项 可以是链接库也可以是可执行文件</span></span><br><span class="line"><span class="keyword">target_compile_options</span>(geometry</span><br><span class="line">  PRIVATE</span><br><span class="line">    <span class="variable">$&#123;flags&#125;</span></span><br><span class="line">  ) </span><br><span class="line"><span class="comment"># PRIVATE，编译选项会应用于给定的目标，不会传递给与目标相关的目标</span></span><br><span class="line"><span class="comment"># INTERFACE，只应用于指定目标，并传递给与目标相关的目标</span></span><br><span class="line"><span class="comment"># PUBLIC，应用于指定目标和使用它的目标</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设定语言标准</span></span><br><span class="line"><span class="keyword">set_target_properties</span>(animals</span><br><span class="line">  PROPERTIES</span><br><span class="line">    CXX_STANDARD <span class="number">14</span></span><br><span class="line">    CXX_EXTENSIONS <span class="keyword">OFF</span>  <span class="comment"># 只启用ISO C++标准的编译器标志，而不使用特定编译器的扩展</span></span><br><span class="line">    CXX_STANDARD_REQUIRED <span class="keyword">ON</span>  <span class="comment"># 如果off 就先从 c++20 17往下找</span></span><br><span class="line">    POSITION_INDEPENDENT_CODE <span class="number">1</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 控制流</span></span><br><span class="line"><span class="keyword">list</span>(</span><br><span class="line">  APPEND sources_with_lower_optimization</span><br><span class="line">    geometry_circle.cpp</span><br><span class="line">    geometry_rhombus.cpp</span><br><span class="line">  )</span><br><span class="line"><span class="keyword">message</span>(STATUS <span class="string">&quot;Setting source properties using IN LISTS syntax:&quot;</span>)</span><br><span class="line"><span class="keyword">foreach</span>(_source IN LISTS sources_with_lower_optimization)</span><br><span class="line">  <span class="keyword">set_source_files_properties</span>(<span class="variable">$&#123;_source&#125;</span> PROPERTIES COMPILE_FLAGS -O2)</span><br><span class="line">  <span class="keyword">message</span>(STATUS <span class="string">&quot;Appending -O2 flag for $&#123;_source&#125;&quot;</span>)</span><br><span class="line">  <span class="keyword">get_source_file_property</span>(_flags <span class="variable">$&#123;_source&#125;</span> COMPILE_FLAGS)</span><br><span class="line">  <span class="keyword">message</span>(STATUS <span class="string">&quot;Source $&#123;_source&#125; has the following extra COMPILE_FLAGS: $&#123;_flags&#125;&quot;</span>)</span><br><span class="line"><span class="keyword">endforeach</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(CMAKE_SYSTEM_NAME <span class="keyword">STREQUAL</span> <span class="string">&quot;Linux&quot;</span>)</span><br><span class="line">  <span class="keyword">target_compile_definitions</span>(hello-world PUBLIC <span class="string">&quot;IS_LINUX&quot;</span>)</span><br><span class="line">elif()</span><br><span class="line"><span class="keyword">else</span>()</span><br><span class="line"><span class="keyword">endif</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(CMAKE_CXX_COMPILER_ID <span class="keyword">MATCHES</span> Intel)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(CMAKE_SIZEOF_VOID_P <span class="keyword">EQUAL</span> <span class="number">8</span>)</span><br><span class="line">  <span class="keyword">target_compile_definitions</span>(arch-dependent PUBLIC <span class="string">&quot;IS_64_BIT_ARCH&quot;</span>)</span><br><span class="line"><span class="keyword">elseif</span>(CMAKE_HOST_SYSTEM_PROCESSOR <span class="keyword">MATCHES</span> <span class="string">&quot;x86_64&quot;</span>)</span><br><span class="line">  <span class="keyword">message</span>(STATUS <span class="string">&quot;x86_64 architecture detected&quot;</span>)</span><br><span class="line">  </span><br><span class="line"><span class="comment"># cmake_host_system_information 查询运行CMake的主机系统的系统信息</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 寻找CheckCXXCompilerFlag.cmake标准模块文件</span></span><br><span class="line"><span class="keyword">include</span>(CheckCXXCompilerFlag)</span><br><span class="line"><span class="comment"># 检查 -march=native编译器标志是否工作</span></span><br><span class="line">check_cxx_compiler_flag(<span class="string">&quot;-march=native&quot;</span> _march_native_works)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印模块</span></span><br><span class="line"><span class="keyword">include</span>(CMakePrintHelpers)</span><br><span class="line">cmake_print_variables(_status _hello_world)</span><br><span class="line"></span><br><span class="line"><span class="comment"># pkg-config检测外部库</span></span><br><span class="line"><span class="keyword">find_package</span>(PkgConfig REQUIRED QUIET)  <span class="comment"># 传递QUIET参数，只有在找不到 pkg-config时，CMake才会报错</span></span><br><span class="line">pkg_search_module(</span><br><span class="line">  ZeroMQ</span><br><span class="line">  REQUIRED</span><br><span class="line">      libzeromq libzmq lib0mq</span><br><span class="line">  IMPORTED_TARGET</span><br><span class="line">  )</span><br><span class="line"><span class="keyword">if</span>(<span class="keyword">TARGET</span> PkgConfig::ZeroMQ)</span><br><span class="line">    <span class="keyword">message</span>(STATUS <span class="string">&quot;Found ZeroMQ&quot;</span>)</span><br><span class="line"><span class="keyword">endif</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 单元测试</span></span><br><span class="line"><span class="keyword">find_package</span>(PythonInterp REQUIRED)</span><br><span class="line"><span class="keyword">find_program</span>(BASH_EXECUTABLE NAMES bash REQUIRED)</span><br><span class="line"></span><br><span class="line"><span class="keyword">enable_testing</span>()  <span class="comment"># 测试这个目录和所有子文件夹</span></span><br><span class="line"><span class="keyword">add_test</span>(  <span class="comment"># 设置测试名称和运行指令</span></span><br><span class="line">  NAME cpp_test</span><br><span class="line">  <span class="keyword">COMMAND</span> $&lt;TARGET_FILE:cpp_test&gt;  <span class="comment"># 生成器表达式，是在生成构建系统生成时的表达式</span></span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 动态分析检测内存泄露</span></span><br><span class="line"><span class="keyword">find_program</span>(MEMORYCHECK_COMMAND NAMES valgrind)</span><br><span class="line"><span class="keyword">set</span>(MEMORYCHECK_COMMAND_OPTIONS <span class="string">&quot;--trace-children=yes --leak-check=full&quot;</span>)</span><br><span class="line">$ ctest -T memcheck --parallel <span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 文件操作</span></span><br><span class="line"><span class="keyword">add_custom_target</span>(unpack-eigen  <span class="comment"># 构建没有输出的命令</span></span><br><span class="line">  ALL  <span class="comment"># 目标始终被执行</span></span><br><span class="line">  <span class="keyword">COMMAND</span></span><br><span class="line">      <span class="variable">$&#123;CMAKE_COMMAND&#125;</span> -E tar xzf <span class="variable">$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;</span>/eigen-eigen-<span class="number">5</span>a0156e40feb.tar.gz</span><br><span class="line">  <span class="keyword">COMMAND</span></span><br><span class="line">      <span class="variable">$&#123;CMAKE_COMMAND&#125;</span> -E rename eigen-eigen-<span class="number">5</span>a0156e40feb eigen-<span class="number">3.3</span>.<span class="number">4</span></span><br><span class="line">  WORKING_DIRECTORY</span><br><span class="line">      <span class="variable">$&#123;CMAKE_CURRENT_BINARY_DIR&#125;</span></span><br><span class="line">  COMMENT</span><br><span class="line">      <span class="string">&quot;Unpacking Eigen3 in $&#123;CMAKE_CURRENT_BINARY_DIR&#125;/eigen-3.3.4&quot;</span></span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 探究编译器是否支持某种特性</span></span><br><span class="line"><span class="keyword">try_compile</span>(</span><br><span class="line">  omp_taskloop_test_1</span><br><span class="line">      <span class="variable">$&#123;CMAKE_CURRENT_BINARY_DIR&#125;</span>/omp_try_compile  <span class="comment"># 用于保存编译成功与否的状态</span></span><br><span class="line">  SOURCES</span><br><span class="line">      <span class="variable">$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;</span>/taskloop.cpp</span><br><span class="line">  <span class="keyword">LINK_LIBRARIES</span></span><br><span class="line">      OpenMP::OpenMP_CXX</span><br><span class="line">  )</span><br><span class="line"><span class="keyword">message</span>(STATUS <span class="string">&quot;Result of try_compile: $&#123;omp_taskloop_test_1&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">include</span>(CheckCXXSourceCompiles)  <span class="comment"># 使用check_cxx_source_compiles函数，需要包含CheckCXXSourceCompiles.cmake模块文件</span></span><br><span class="line"><span class="keyword">file</span>(READ <span class="variable">$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;</span>/taskloop.cpp _snippet)  <span class="comment"># 复制源文件的内容，file(READ ...)命令读取内容到一个变量中，试图编译和连接这个变量</span></span><br><span class="line"><span class="keyword">set</span>(CMAKE_REQUIRED_LIBRARIES OpenMP::OpenMP_CXX)  <span class="comment"># 对于下一步正确调用编译器是必需的,使用导入的OpenMP::OpenMP_CXX目标，它还将设置正确的编译器标志和包含目录:</span></span><br><span class="line">check_cxx_source_compiles(<span class="string">&quot;$&#123;_snippet&#125;&quot;</span> omp_taskloop_test_2)</span><br><span class="line"><span class="keyword">unset</span>(CMAKE_REQUIRED_LIBRARIES)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 探究编译器标志</span></span><br><span class="line"><span class="keyword">list</span>(APPEND CXX_BASIC_FLAGS <span class="string">&quot;-g3&quot;</span> <span class="string">&quot;-O1&quot;</span>)  <span class="comment"># 声明列表CXX_BASIC_FLAGS，其中包含构建项目时始终使用的编译器标志-g3和-O1:</span></span><br><span class="line"><span class="keyword">include</span>(CheckCXXCompilerFlag)</span><br><span class="line">check_cxx_compiler_flag(<span class="variable">$&#123;ASAN_FLAGS&#125;</span> asan_works)  <span class="comment"># 调用check_cxx_compiler_flag来确保编译器理解ASAN_FLAGS变量中的标志</span></span><br><span class="line"><span class="keyword">unset</span>(CMAKE_REQUIRED_FLAGS)</span><br><span class="line"><span class="keyword">if</span>(asan_works)  <span class="comment"># 如果编译器理解这些选项，将变量转化为一个列表，分号替换空格</span></span><br><span class="line">    <span class="keyword">string</span>(REPLACE <span class="string">&quot; &quot;</span> <span class="string">&quot;;&quot;</span> _asan_flags <span class="variable">$&#123;ASAN_FLAGS&#125;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 探究可执行命令</span></span><br><span class="line"><span class="keyword">include</span>(CheckCSourceRuns)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将cmake子目录添加到CMake模块搜索的路径列表中,告诉cmake去哪里查找宏</span></span><br><span class="line"><span class="keyword">list</span>(APPEND CMAKE_MODULE_PATH <span class="string">&quot;$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;/cmake&quot;</span>)</span><br><span class="line"><span class="keyword">include</span>(colors)</span><br><span class="line">显式</span><br><span class="line"><span class="keyword">include</span>(cmake/colors.cmake)</span><br></pre></td></tr></table></figure>

<p>Setuptools：</p>
<p>–package_dir 告诉setuptools哪些目录下的文件被映射到哪个源码包</p>
<p>package_dir &#x3D; {‘’: ‘lib’}，表示“root package”中的模块都在lib 目录中</p>
<h4 id="2-HPC-Xiaopeng"><a href="#2-HPC-Xiaopeng" class="headerlink" title="2.HPC Xiaopeng"></a>2.HPC Xiaopeng</h4><p><a target="_blank" rel="noopener" href="https://github.com/parallel101/course">https://github.com/parallel101/course</a></p>
<h5 id="01-CMake"><a href="#01-CMake" class="headerlink" title="01.CMake"></a>01.CMake</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cmake -Bbuild --dry-run</span><br><span class="line">-DCMAKE_CXX_COMPILER=g++ -DCMAKE_CXX_STANDARD=17 -C build # change 目录</span><br></pre></td></tr></table></figure>

<p>“”优先搜索当前目录，&lt;&gt;可以用””代替，反之不然，所以&lt;&gt;是为了避免当前目录下的错误文件被引入</p>
<p>为了避免引用subdirectory中头文件时#include “”相对路径的改写，可使用target_include_directories；甚至可直接使用&lt;&gt;，因为该方法会被视为与系统路径等价</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 子模块的头文件处理</span></span><br><span class="line"><span class="keyword">add_executable</span>(a.out main.cpp)</span><br><span class="line"><span class="keyword">target_link_libraries</span>(a.out PUBLIC hellolib)</span><br><span class="line">target_include_libraries(a.out PUBLIC hellolib)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可进一步做如下处理：定义hellolib的头文件搜索路径，引用PUBLIC的可执行文件时，CMake会自动添加这个路径</span></span><br><span class="line"><span class="keyword">add_library</span>(hellolib STATIC hello.cpp)</span><br><span class="line"><span class="keyword">target_include_directories</span>(hellolib PUBLIC .)</span><br><span class="line"></span><br><span class="line"><span class="comment">#CMake引用系统中预安装的第三方库</span></span><br><span class="line"><span class="keyword">find_package</span>(XX REQUIRED)</span><br></pre></td></tr></table></figure>

<h5 id="02-RAII-智能指针"><a href="#02-RAII-智能指针" class="headerlink" title="02.RAII &amp; 智能指针"></a>02.RAII &amp; 智能指针</h5><h5 id="Resource-Acquisition-Is-Initialization"><a href="#Resource-Acquisition-Is-Initialization" class="headerlink" title="Resource Acquisition Is Initialization"></a>Resource Acquisition Is Initialization</h5><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> sum = std::<span class="built_in">reduce</span>(v.<span class="built_in">begin</span>(), v.<span class="built_in">end</span>(), <span class="number">0</span>, std::plus&#123;&#125;)</span><br><span class="line">    </span><br><span class="line"><span class="meta"># c++ 20 引入区间</span></span><br><span class="line">std::vector v = &#123;<span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">-1</span>, <span class="number">-2</span>&#125;;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> &amp;&amp;vi: v</span><br><span class="line">     | std::views::<span class="built_in">filter</span>([] (<span class="keyword">auto</span> &amp;&amp;x) &#123; <span class="keyword">return</span> x &gt;= <span class="number">0</span>; &#125;)</span><br><span class="line">     | std::views::<span class="built_in">transform</span>([] (<span class="keyword">auto</span> &amp;&amp;x) &#123; <span class="keyword">return</span> <span class="built_in">sqrtf</span>(x); &#125;)</span><br><span class="line">    ) &#123;</span><br><span class="line">    std::cout &lt;&lt; vi &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;fstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdexcept&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">test</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">std::ofstream <span class="title">fout</span><span class="params">(<span class="string">&quot;a.txt&quot;</span>)</span></span>;</span><br><span class="line">    fout &lt;&lt; <span class="string">&quot;有一种病\n&quot;</span>;</span><br><span class="line">    <span class="keyword">throw</span> std::<span class="built_in">runtime_error</span>(<span class="string">&quot;中道崩殂&quot;</span>);</span><br><span class="line">    fout &lt;&lt; <span class="string">&quot;叫 JavaBean\n&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="built_in">test</span>();</span><br><span class="line">    &#125; <span class="built_in">catch</span> (std::exception <span class="type">const</span> &amp;e) &#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;捕获异常：&quot;</span> &lt;&lt; e.<span class="built_in">what</span>() &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<img src="/home/kwx/blog/source/_posts/assets/image-20230319164406951.png" alt="image-20230319164406951" style="zoom:67%;" />

<p>std::to_string(80)<br>explicit 需要显式，不能用&#x3D;做隐式构造<br>使用static_cast<int>(3.14f) 而非 int(3.14f)<br>使用reinterpret_cast&lt;void *&gt;(0xb800)而非(void *)0xb8000<br>后者是：如果硬要让int与指针有一定关联，不让编译器去做安全检查</p>
<p>通过指定struct为函数返回值类型，return 初始化列表可以解决函数多返回值<br>std::tuple前后顺序没有名字<br>C++中所有对象都是深拷贝，只有shared&#x2F;weak&#x2F;默认是浅拷贝，unique是禁止拷贝</p>
<p>一些规则：<a target="_blank" rel="noopener" href="https://github.com/isocpp/CppCoreGuidelines">https://github.com/isocpp/CppCoreGuidelines</a></p>
<p>默认的编译器生成的拷贝构造是指针的浅拷贝，所以&#x3D;delete，避免双重free</p>
<p>浅拷贝那个只是复制地址，没有分配内存</p>
<p>vector的resize其实就是种原子操作，让两个操作封装成一个</p>
<p>三五法则：（可以将拷贝构造函数声明为 explicit）</p>
<p>如果一个类定义了析构函数，必须同时定义或删除拷贝构造函数和拷贝赋值函数，否则出错。</p>
<p>如果一个类定义了拷贝构造函数，必须同时定义或删除拷贝赋值函数，否则出错，删除可导致低效。</p>
<p>如果一个类定义了移动构造函数，必须同时定义或删除移动赋值函数，否则出错，删除可导致低效。</p>
<p>如果一个类定义了拷贝构造或拷贝赋值函数，必须最好同时定义移动构造或移动赋值函数，否则低效。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">int x = 1 # 拷贝构造</span><br><span class="line">x = 2 # 拷贝赋值</span><br><span class="line">拷贝赋值（先销毁现有的1再重新构造2） ≈ 析构 + 拷贝构造（直接再未初始化的内存上构造2）</span><br><span class="line">移动构造 ≈ 拷贝构造 + 析构 + 默认构造</span><br><span class="line">内存的销毁重新分配可以通过 realloc，就地利用当前现有的m_data，避免重新分配</span><br></pre></td></tr></table></figure>

<img src="/home/kwx/blog/source/_posts/assets/image-20230319180514192.png" alt="image-20230319180514192" style="zoom:67%;" />

<img src="/home/kwx/blog/source/_posts/assets/image-20230319180743499.png" alt="image-20230319180743499" style="zoom:67%;" />

<p>时间复杂度：copy: O(n)  move&#x2F;swap: O(1)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">std::move(t)  (T &amp;&amp;)t</span><br><span class="line">std::as_const(t)  (T const &amp;)t</span><br><span class="line">v2= &#123;&#125; 调用默认构造函数与移动赋值函数</span><br></pre></td></tr></table></figure>

<p>如果有移动赋值函数，可以删除拷贝赋值函数：因为没有了拷贝赋值，v2&#x3D;v1会被编译器解读为v2&#x3D;List(v1)，相当于就地构造的临时对象，从而变成了移动语义</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230319183605608.png" alt="image-20230319183605608" style="zoom:67%;" />

<p>new C 随机初始化，new C( ) 零初始化</p>
<p>p &#x3D; nullptr 等价于 p.reset()</p>
<p>unique_ptr 函数传参：如果func实际并不需要夺走资源的占有权，只是调用了指针的某个成员函数，并没有接管对象生命周期的大权，直接用p.get( )获取<strong>原始指针</strong>；如果需要接管，则使用std::move(p)，这时候p,get( )是null，因为移动会清除原有对象（防止重复释放）</p>
<p>shared_ptr：p.use_count( )  </p>
<p>解决循环引用：weak_ptr，p.expired( )判断弱引用是否失效，p.lock( )生成强引用shared_ptr</p>
<p>智能指针作为类的成员变量时，整个类也就变成了浅拷贝，或者unique_ptr禁止拷贝</p>
<p>unique_ptr：该对象仅仅属于我</p>
<p>原始指针：该对象不属于我，但它释放前我必然被释放</p>
<p>shared_ptr：该对象由多个对象共享时，或该对象仅属于我，但有使用weak_ptr的需要</p>
<p>weak_ptr：对象不属于我，且它释放后我仍可能不被释放</p>
<p>管理资源（资源往往不能被复制）的类，删除拷贝，使用智能指针进行管理</p>
<p>const引用可以避免不必要的拷贝（实际传递的是一个指针），如果函数参数传递的是值，可能也会触发拷贝</p>
<p>基础类型（比如 int，float）或 原始指针（比如 int *，Object *）按值传递：void doSomethingWith(Object *ptr);</p>
<p>（指针64位，float32位）</p>
<p>数据容器类型（比如 vector，string）或 自定义的可拷贝的类 按常引用传递：int sumArray(std::vector<int> const &amp;arr);</p>
<p>如果是智能指针 且需要生命周期控制权，按值传递：void addObject(std::shared_ptr<Object> obj);</p>
<p>如果是智能指针 但不需要生命周期，则通过 .get() 获取原始指针后，按值传递：void modifyObject(Object *obj)</p>
<h5 id="03-模板元编程与函数式"><a href="#03-模板元编程与函数式" class="headerlink" title="03.模板元编程与函数式"></a>03.模板元编程与函数式</h5><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span> = <span class="type">int</span>&gt;</span><br></pre></td></tr></table></figure>

<p>模板参数可以作为编译器常量</p>
<p>模板内部实现不加static或者inline的话，不会内联，会生成弱符号，就是编译器会对相同的多个弱符号里取其一</p>
<p>constexpr保证是编译期求完值的，等号右边必须是编译期常量表达式(如 std::min)，而非运行时常量</p>
<p>模板的惰性：延迟编译</p>
<p>分离模板的定义：需要在看得到模板内部函数定义的cpp里增加模板的显式声明</p>
<p>auto根据等号右边的值自动推导，且不能用于类成员</p>
<p>函数没有return语句时，auto自动推断为void</p>
<p>如果声明和实现分离了，那就不能声明为auto</p>
<p>引用的本质无非是指针，试图修改一个引用时，实际就是修改了原来的对象</p>
<p>函数中的static只有在进入了函数才会做初始化而非一加载程序就初始化</p>
<p>右值int &amp;&amp;能退化为 const &amp;，但不能退化为int &amp;</p>
<p>decltype(变量名&#x2F;表达式) 获取变量定义时&#x2F;表达式的类型</p>
<p>区分：int * const |  const int * | int const *</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; std::is_same_v&lt;<span class="type">int</span> <span class="type">const</span>, <span class="type">const</span> <span class="type">int</span>&gt; &lt;&lt; <span class="string">&quot;\n&quot;</span></span><br><span class="line">std::cout &lt;&lt; std::is_same_v&lt;std::<span class="type">remove_const_t</span>&lt;<span class="type">int</span> <span class="type">const</span>&gt;, <span class="type">int</span>&gt; &lt;&lt; <span class="string">&quot;\n&quot;</span></span><br><span class="line">std::cout &lt;&lt; std::is_same_v&lt;std::<span class="type">decay_t</span>&lt;<span class="type">int</span> <span class="type">const</span>&gt;, <span class="type">int</span>&gt; &lt;&lt; <span class="string">&quot;\n&quot;</span>  # 退化<span class="type">const</span>，&amp;,<span class="type">int</span>[] 退化为<span class="type">int</span> *</span><br></pre></td></tr></table></figure>

<p>sfinae：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/100554291">https://zhuanlan.zhihu.com/p/100554291</a></p>
<p>type_trait：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/gtarcoder/p/4807670.html">https://www.cnblogs.com/gtarcoder/p/4807670.html</a></p>
<p>万能推导：</p>
<p>decltype(auto) p &#x3D; func( )会自动推导为func( )的返回类型，与decltype(func( )) p &#x3D; func( )等价，在代理模式中用于完美转发函数返回值：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">decltype</span>(<span class="keyword">auto</span>) <span class="title">at</span><span class="params">(<span class="type">size_t</span> i)</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> m_internal_class.<span class="built_in">at</span>(i);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>typedef int (*PFunc) (int) 等价于 using PFunc &#x3D; int(*) (int)</p>
<p>用 decltype(T1{} * T2{}) 算出 T1 和 T2 类型相加以后的结果，并做为返回的 vector 容器中的数据类型</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># before</span></span><br><span class="line"><span class="keyword">typename</span> std::decay&lt;<span class="type">int</span>&gt;::type</span><br><span class="line">std::same&lt;<span class="type">int</span>, <span class="type">int</span>&gt;::value</span><br><span class="line"></span><br><span class="line"><span class="meta"># now</span></span><br><span class="line">std::<span class="type">decay_t</span>&lt;<span class="type">int</span>&gt;</span><br><span class="line">std::is_same_v&lt;<span class="type">int</span>, <span class="type">int</span>&gt;</span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">using</span> <span class="type">decay_t</span> = <span class="keyword">typename</span> std::decay&lt;<span class="type">int</span>&gt;::type</span><br></pre></td></tr></table></figure>

<p>函数作为参数也就是传入了函数的起始地址</p>
<p>函数可以引用定义位置所有的变量的特性在函数式编程中叫做闭包</p>
<p>[&amp;]传入的是可写入的变量，是可变引用</p>
<p>lambda表达式：传递const引用以避免拷贝开销，此外最好把模板参数的Func声明为Func const &amp;以避免不必要的拷贝</p>
<p>lambda表达式的返回值永远是匿名的，所以要用auto来推导</p>
<p>需要注意：lambda对象的生命周期不超过它捕获的所有引用的寿命</p>
<p>lambda表达式避免使用模板参数可以用std::function（把所有( )的函数变成虚函数），它的开销与虚函数一致，因其实现需要用到虚函数，std::function&lt;int&lt;float, char *&gt;&gt;</p>
<p>未知类型 std::any，代替 C 的 void*   ;   某种类型 std::optional，代替 C 的类型指针</p>
<p>回调函数 std::function，代替 C 的函数指针  ;  某些类型 std::variant，代替 union</p>
<p>可以将lambda表达式的参数声明为auto，基本和template<class T>等价</p>
<p>auto const &amp; 等价于 T const &amp;</p>
<p>带auto的lambda表达式，和模板函数一样，同样会有惰性、多次编译的特性</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230319230943640.png" alt="image-20230319230943640" style="zoom:67%;" />

<p>化简auto：</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230319231432165.png" alt="image-20230319231432165" style="zoom:67%;" />

<p>结构化绑定还可以应用于任意类</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">A</span> &#123;</span><br><span class="line">	<span class="type">int</span> x;</span><br><span class="line">	<span class="type">float</span> y;</span><br><span class="line">&#125;;</span><br><span class="line">A a = &#123;<span class="number">1</span>, <span class="number">1.1</span>&#125;;</span><br><span class="line"><span class="keyword">auto</span> [x, y] = a;</span><br></pre></td></tr></table></figure>

<p>返回bool的std::tuple可以用std::optional替代：</p>
<p>value_or( )指定缺失值：printf(“成功 ! “, ret.value_or( 1.0f ))， ret.value( )会检测是否为空</p>
<p>有值时可以用*ret，optional里的类型是结构体的话，也可以用ret-&gt;xxx访问结构体的属性</p>
<p>if (opt) 等价于 if (ret.has_value( ))</p>
<p>std::optional是更安全的指针，std::variant就是更安全的Union：std::variant&lt;int, float&gt; v &#x3D; 3</p>
<p>判断当前是那个类型：std::holds_alternative<int>(v) or v.index( ) &#x3D;&#x3D; 0</p>
<p>判断是否是指针：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; std::is_pointer_v&lt;std::<span class="type">nullptr_t</span>&gt; &lt;&lt; <span class="string">&quot;\n&quot;</span>  # False</span><br></pre></td></tr></table></figure>

<p>std::visit会自动用相应的类型调用 lambda，lambda 中往往是个重载函数</p>
<p>std::visit、std::variant 的这种模式称为静态多态，和虚函数、抽象类的动态多态相对</p>
<p>静态多态的优点是：性能开销小，存储大小固定。缺点是：类型固定，不能运行时扩充</p>
<h5 id="04-编译器优化与SIMD指令"><a href="#04-编译器优化与SIMD指令" class="headerlink" title="04.编译器优化与SIMD指令"></a>04.编译器优化与SIMD指令</h5><p>编译器就是从源代码生成汇编语言</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230320224540396.png" alt="image-20230320224540396" style="zoom:67%;" />

<p>RIP是当前执行的代码地址</p>
<p>MMX YMM XMM都是用于存储浮点数的寄存器</p>
<p>SSE Media Registers：128位宽 &#x3D; 4个float &#x2F; 2个double</p>
<p>32位eax与64位rax：共用前32位，即eax与rax的低32位是共用的</p>
<p>同理，eax与ax，ax&#x3D;ah + al</p>
<p>AVX用的ZMM， AVX512 YMM (256位) ，SSE用的XMM (128位)</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230320225552955.png" alt="image-20230320225552955" style="zoom:8-%;" />

<p>gcc -fomit-frame-pointer -fverbose-asm -S main.cpp  &#x2F;tmp&#x2F;main.S</p>
<p>movl %edi, -4(%rsp) 相当于 *(rsp - 4) &#x3D; edi</p>
<p>函数前6个参数，分别通过edi, esi, edx, ecx, r8d, r9d传入</p>
<p>imul 第一个参数edi 第二个参数esi  返回值eax  32位—-&gt; 64位 rdi rsi imulq</p>
<p>lea 用于加载表达式地址，而非把表达式的值给取出来，即 leal (%rdi, %rsi) , %eax  &lt;&#x3D;&gt;  eax &#x3D; &amp;*(rdi + rsi) </p>
<p>lea 可以执行任意一次函数 leal(%rdi, %rsi, 8)  rdi + rsi * 8</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">func</span><span class="params">(<span class="type">int</span>* a, <span class="type">int</span> b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a[b];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">movslq %esi, %rsi  指针是<span class="number">64</span>位的，<span class="type">int</span>是<span class="number">32</span>位的，所以要先把<span class="type">int</span>转化为<span class="number">64</span>位，esi -&gt; <span class="function">rsi</span></span><br><span class="line"><span class="function"><span class="title">movl</span> <span class="params">(%rdi, %rsi, <span class="number">4</span>)</span>, %eax  <span class="meta"># int大小是4，所以偏移量也要乘以4才能访问到正确的地址</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"># 可以改进为：</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">func</span><span class="params">(<span class="type">int</span>* a, std::<span class="type">size_t</span> b)</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">return</span> a[b];</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta"># std::size_t在64位系统上相当于uint64_t,32位就是uint32_t，从而不需要movslq，而且也能处理数组大超出INT_MAX的情况，推荐始终用size_t表示数组大小和索引</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">float</span> <span class="title">func</span><span class="params">(<span class="type">float</span> a, <span class="type">float</span> b)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a + b;</span><br><span class="line">&#125;</span><br><span class="line">addss %xmm1, %xmm0  只对最低位进行加法</span><br><span class="line">ss矢量化失败，ps成功</span><br><span class="line">addss 一个<span class="type">float</span>加法，addsd 一个<span class="type">double</span>，addps 四个<span class="type">float</span> addpd，两个<span class="type">double</span></span><br></pre></td></tr></table></figure>

<img src="/home/kwx/blog/source/_posts/assets/image-20230320232629595.png" alt="image-20230320232629595" style="zoom:67%;" />

<p>存储在堆上妨碍优化：vector, map, set, string, function, any, smart pointers</p>
<p>栈上利于优化：array, bitset, pair, tuple, optional, variant</p>
<p>存储在栈上无法动态扩充大小</p>
<p>最简单的判断方法：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">size_of</span>(vector&lt;array&gt;)  <span class="number">24</span> 存的只是一个指针以及vector大小</span><br><span class="line"><span class="built_in">size_of</span>(array&lt;<span class="type">float</span>, <span class="number">32</span>&gt;)  =  <span class="number">32</span> * <span class="number">4</span></span><br></pre></td></tr></table></figure>

<p>constexpr强迫编译器进行常量折叠，在编译期求值，不过constexpr无法用于非constexpr的容器，例如vector, map, set, string等</p>
<p>外部函数：同一个文件内只有声明没有实现</p>
<p>调用外部函数：call指令   编译器优化：call变jmp</p>
<p>call _Z5otheri@PLT  @PLT(procedure linkage table)函数链接表</p>
<p>链接器会查找其他.o文件中是否定义了这个符号，如果定义了就把@PLT替换为它的地址</p>
<p>局部可见函数 static：编译器不生成other函数直接进行inline了</p>
<p><a target="_blank" rel="noopener" href="https://godbolt.org/">https://godbolt.org/</a></p>
<p>指针别名：__restrict关键字向编译器保证指针之间不会发生重叠</p>
<p>所有非const指针都声明__restrict</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">void func(int *__restrict a, int *__restrict b, int *__restrict c) &#123;</span><br><span class="line">    *c = *a;</span><br><span class="line">    *c = *b;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>禁止优化：volatile，适用于benchmark测速对比，可以用于非指针</p>
<p>volatile在*前，restrict在*后</p>
<p>两个int32可以合并为1个int64，4个int32可以合并为一个__m128</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">(<span class="type">int</span>* a)</span></span>&#123;</span><br><span class="line">    a[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">    a[<span class="number">1</span>] = <span class="number">1</span>;</span><br><span class="line">    a[<span class="number">2</span>] = <span class="number">2</span>;</span><br><span class="line">    a[<span class="number">3</span>] = <span class="number">3</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<img src="/home/kwx/blog/source/_posts/assets/image-20230320235203319.png" alt="image-20230320235203319" style="zoom:67%;" />

<p>movups：move unaligned packed single，u代表(%rdi)的地址不一定对齐到16字节</p>
<p>moveaps：aligned</p>
<p>8个int32合并为一个__m256，但是编译器不能保证所有64位电脑都支持ymm只能保证都支持xmm</p>
<p>所以还需：gcc -march&#x3D;native -O3</p>
<p>paddd:：4个int的加法</p>
<p>movdqa：加载4个int</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">(<span class="type">int</span>* a)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1024</span>; i++) &#123;</span><br><span class="line">        a[i] = i;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<img src="/home/kwx/blog/source/_posts/assets/image-20230320235917427.png" alt="image-20230320235917427" style="zoom:80%;" />

<img src="/home/kwx/blog/source/_posts/assets/image-20230320235936972.png" alt="image-20230320235936972" style="zoom:67%;" />

<p>边界特判法：对边界做特殊处理，大部分矢量化  cmpl</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">(<span class="type">int</span> *a, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">	n = n / <span class="number">4</span> * <span class="number">4</span>;  # 编译器会发现 n % <span class="number">4</span> = <span class="number">0</span> 从而不会生成边界特判的分支</span><br><span class="line">	<span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">		a[i] = i; </span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>假定指针是16字节对齐的：assume_aligned，movups -&gt; movaps</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">(<span class="type">int</span> *a, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">	n = n / <span class="number">4</span> * <span class="number">4</span>;</span><br><span class="line">	a = (<span class="type">int</span> *)__builtin_assume_aligned(a, <span class="number">16</span>);</span><br><span class="line">	<span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">		a[i] = i; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>循环中的矢量化：小心指针别名，OpenMP强制矢量化 </p>
<p># pragma omp simd   gcc -fopenmp -O3</p>
<p># pragma GCC ivdep 忽略矢量依赖关系</p>
<p>循环中的if语句挪到外部，避免在for循环体里调用外部函数，一道同一个文件或者放在头文件并声明为static函数</p>
<p># pragma GCC unroll 4   循环展开 i++ 变成 i +&#x3D; 4</p>
<p>结构体大小不是2的整数幂往往会导致SIMD优化失败</p>
<p>在struct后加上alignas(要对齐的字节数)即可实现同样效果</p>
<p>结构体的内存布局：</p>
<p>AOS（Array of Struct）：xyzxyzxyz 必须对齐到2的整数幂才高效</p>
<p>SOA：xxxyyyzzz 分离存储多个属性，可能无法保证多个数组大小一致，但通常更高效</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230321001621586.png" alt="image-20230321001621586" style="zoom:67%;" />

<img src="/home/kwx/blog/source/_posts/assets/image-20230321001633243.png" alt="image-20230321001633243" style="zoom:67%;" />

<p>AOSOA：</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230321001651512.png" alt="image-20230321001651512" style="zoom:67%;" />

<p>std::vector也有指针别名问题，用#pragma omp simd，__restrict无用</p>
<p>std::vector也能使用SOA，但要保证三个vector是同样大小</p>
<p>-ffast-math  数学函数加std前缀 std::abs  std::sqrt</p>
<p>嵌套循环：直接累加也有指针别名问题</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230321002249095.png" alt="image-20230321002249095" style="zoom:67%;" />

<p>方案1：先读到局部变量，累加完毕后再写入</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230321002257029.png" alt="image-20230321002257029" style="zoom:67%;" />

<p>方案2：先累加到初始为0的局部变量，再累加到c，精度更高(1000 + 0.001)</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230321002350406.png" alt="image-20230321002350406" style="zoom:67%;" />

<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span>(CMAKE_BUILD_TYPE Release)  <span class="comment"># 开启-O3</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">find_package</span>(OpenMP REQUIRED)</span><br><span class="line"><span class="keyword">target_link_libraries</span>(<span class="keyword">target</span> PUBLIC OpenMP::OpenMP_CXX)</span><br><span class="line"></span><br><span class="line"><span class="keyword">target_compile_options</span>(<span class="keyword">target</span> PUBLIC -fast-<span class="keyword">math</span> -march=native)</span><br></pre></td></tr></table></figure>

<h5 id="05-多线程"><a href="#05-多线程" class="headerlink" title="05.多线程"></a>05.多线程</h5><p>时间点：std::chrono::steady_clock::time_point</p>
<p>时间段：std::chrono::milliseconds&#x2F;seconds&#x2F;minutes</p>
<p>duration_cast 可以在任意的 duration 类型之间转换<br>duration&lt;T, R&gt; 表示用 T 类型表示，且时间单位是 R<br>R 省略不写就是秒，std::milli 就是毫秒，std::micro 就是微秒<br>seconds 是 duration<int64_t> 的类型别名，milliseconds 是 duration&lt;int64_t, std::milli&gt; 的类型别名<br>这里我们创建了 double_ms 作为 duration&lt;double, std::milli&gt; 的别名</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> t0 = std::chrono::steady_clock::<span class="built_in">now</span>();    <span class="comment">// 获取当前时间点</span></span><br><span class="line"><span class="keyword">auto</span> t1 = t0 + std::chrono::<span class="built_in">seconds</span>(<span class="number">30</span>);       <span class="comment">// 当前时间点的30秒后</span></span><br><span class="line"><span class="keyword">auto</span> dt = t1 - t0;                        <span class="comment">// 获取两个时间点的差（时间段）</span></span><br><span class="line"><span class="keyword">using</span> double_ms = std::chrono::duration&lt;<span class="type">double</span>, std::milli&gt;</span><br><span class="line"><span class="type">int64_t</span> sec = std::chrono::<span class="built_in">duration_cast</span>&lt;chrono::seconds&gt;(dt).<span class="built_in">count</span>();  <span class="comment">// 时间差的秒数</span></span><br><span class="line"><span class="type">double</span> ms = std::chrono::<span class="built_in">duration_cast</span>&lt;double_ms&gt;(dt),<span class="built_in">count</span>();</span><br></pre></td></tr></table></figure>

<p>std::this_thread::sleep_for(std::chrono::milliseconds(400))</p>
<p>std::this_thread::sleep_until(std::chrono::steady_clock::now() + std::chrono::milliseconds(400))</p>
<p>std::thread的实现依赖于pthread，需要：</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">find_package</span>(Threads REQUIRED)</span><br><span class="line"><span class="keyword">target_link_libraries</span>(cpptest PUBLIC Threads::Threads)</span><br></pre></td></tr></table></figure>

<p>主线程等待子线程结束再退出：t.join( )</p>
<p>std::thread自定义了析构函数，删除了拷贝构造&#x2F;赋值函数，但提供了移动构造&#x2F;赋值函数，其析构函数会销毁线程，可以用detach( )分离，也就意味着线程的生命周期不再由当前std::thread对象管理，而是在线程退出后自动销毁自己。</p>
<p>析构函数不再销毁线程的另一种：移动到全局线程池</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230321205208662.png" alt="image-20230321205208662" style="zoom:80%;" />

<p>std::async接受一个带返回值的lambda，自身返回一个std::future对象，async调用以后实际是没有在执行的，在后台被挂起悄悄运行</p>
<p>调用future的get( )，如果此时async里的任务没有完成会等待至完成并获取其返回值</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230321221431911.png" alt="image-20230321221431911" style="zoom:80%;" />

<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">std::future&lt;<span class="type">int</span>&gt; res = std::<span class="built_in">async</span>([&amp;] &#123;<span class="keyword">return</span> <span class="built_in">download</span>(<span class="string">&quot;hello.zip&quot;</span>)&#125; );</span><br><span class="line"><span class="meta"># res.wait();  也可以等待线程执行完</span></span><br><span class="line"><span class="meta"># ret.wait_for(std::chrono::milliseconds(1000)); 返回 std::future_status::timeout/ready</span></span><br><span class="line"><span class="type">int</span> ret = res.<span class="built_in">get</span>();</span><br><span class="line">std::<span class="built_in">async</span>(std::launch::deferred, [&amp;] &#123;...&#125;)  <span class="comment">// defer不会创建一个线程来执行而是推迟到future的get()被调用时，该特性可以用于惰性求值</span></span><br></pre></td></tr></table></figure>

<p>手动创建线程：std::promise（std::promise是async的底层实现），在线程返回时用set_value( )设置返回值，</p>
<p>在主线程里，用get_future( )获取其std::future对象，进一步get( )可以等待并获取线程返回值</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230321211011571.png" alt="image-20230321211011571" style="zoom:80%;" />

<p>需要拷贝可以用shared_future</p>
<p>调用std::mutex的lock( )时，会检测mutex是否已经上锁；如果没有锁定就会上锁，如果锁定了就陷入等待直到mutex被另一个线程解锁后才再次上锁</p>
<p>而调用unlock( )则会进行解锁操作</p>
<p>std::lock_guard : RAII</p>
<p>std::unique_lock：希望在析构前提前unlock。额外存储一个flag来表示是否已经被释放，没有则调用unlock( )，否则不调用；</p>
<p>可以直接调用unlock( )来提前解锁，即便忘了也没关系因为退出作用域的时候它还会自动检查下要不要解锁</p>
<p>指定std::defer_lock，unique_lock就不会在构造函数中调用mtx.lock( )，需要之后再手动上锁，好处依然是忘了unlock也能自动unlock</p>
<p>也可以使用无阻塞的try_lock( )，在上锁失败时不会陷入等待，而是直接返回False，成功返回True  try_lock_for&#x2F;until</p>
<p>unique_lock用std::try_to_lock作为参数，相比无参数会在构造函数时调用try_lock而非lock，之后可以用owns_lock( )判断是否上锁成功</p>
<p>unique_lock&#x2F;lock_guard用std::adopt_lock作为参数，如果当前已经上锁，但想在析构时解锁</p>
<p>std::mutex与unique_lock具有同样的接口：鸭子类型</p>
<p>死锁：执行lock( )失败陷入相互等待</p>
<p>永远不要同时持有两个锁 &#x2F; 保证双方上锁顺序一致 &#x2F; std::lock同时对多个上锁</p>
<p>std::scoped_lock：std::lock的RAII，可以同时对多个mutex上锁</p>
<p>std::recursive_mutex自动判断同一个线程lock( )了多次同一个锁，会让计数器+1，但是会带来性能下降</p>
<p>多线程同时访问经典案例：</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230321223707485.png" alt="image-20230321223707485" style="zoom:80%;" />

<p>封装线程安全的vector：</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230321223934630.png" alt="image-20230321223934630" style="zoom:80%;" />

<p>出错：因为size( )是const函数，而mutex::lock( )是非const的</p>
<p>逻辑上const而部分成员非const：mutable</p>
<p>size( )在逻辑上是const的，为了让this为const时仅仅给m_mtx开后门，可修改为mutable …从而 所有成员里只有它不是const的</p>
<p>读写锁允许：n读取0写入； 1写入0读取； 0读取0写入</p>
<p>std::shared_mutex 上锁时指定读&#x2F;写需求，负责调度的读写锁会为你判断要不要等待</p>
<p>push_back需要修改数据，使用lock&#x2F;unlock</p>
<p>size( )读取数据，可以共享</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230321224423718.png" alt="image-20230321224423718" style="zoom:80%;" />

<p>std::shared_lock：RAII lock_shared</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230321224633978.png" alt="image-20230321224633978" style="zoom:80%;" />

<p>只需要一次性上锁 + RAII：访问者模式</p>
<p>合并多次上锁，不然每次循环上锁解锁十分低效，同时还能分离存储与访问</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230321224919043.png" alt="image-20230321224919043" style="zoom:80%;" />

<img src="/home/kwx/blog/source/_posts/assets/image-20230321224941891.png" alt="image-20230321224941891" style="zoom:80%;" />

<p>条件变量：等待被唤醒，等待某一条件成真</p>
<p>cv.wait(lck)将让当前线程陷入等待，在其他线程中调用notify_one( )会唤醒那个陷入等待的线程</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230321225250428.png" alt="image-20230321225250428" style="zoom:80%;" />

<p>cv.wait(lck, lambda) lambda表达式返回值为True时才会真正唤醒否则继续等待</p>
<p>notify_all( )唤醒全部等待中的线程</p>
<p>t1被notify_all唤醒后，t2不会同时在执行，只有等t1解锁后，才会轮到t2</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230321225905234.png" alt="image-20230321225905234" style="zoom:80%;" />

<p>这就是为什么wait( )需要一个unique_lock，因为要保证多个线程被唤醒时只有一个能够被启动，如果不需要，在wait( )返回后调用lck.unlock( )即可</p>
<p>生产者-消费者模式：</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230321230045299.png" alt="image-20230321230045299" style="zoom:100%;" />

<p>将队列封装成类：</p>
<p><img src="/home/kwx/blog/source/_posts/assets/image-20230321230131855.png" alt="image-20230321230131855"></p>
<p><img src="/home/kwx/blog/source/_posts/assets/image-20230321230139392.png" alt="image-20230321230139392"></p>
<p>std::condition_variable仅支持std::unique_lock<a href="std::mutex">std::mutex</a>作为wait的参数，其他类型的锁得用std::condition_variable_any</p>
<p>原子操作：</p>
<img src="/home/kwx/blog/source/_posts/assets/截图 2023-03-21 23-11-54.png" alt="截图 2023-03-21 23-11-54" style="zoom:67%;" />

<p>可以用mutex上锁，在counter +&#x3D; 1加入lock&#x2F;unlock，但mutex太过重量级，会让线程挂起从而需要通过系统调用进入内核层调度到其他线程执行，有很大的开销，但此处只是小小地修改下int</p>
<p>atomic：有专门的硬件指令加持 lock xadd %eax, (%rdx)</p>
<p>对 atomic的 +&#x3D; 等操作会被编译器转换成专门的指令，CPU 识别到该指令时，会锁住内存总线，放弃乱序执行等优化策略（将该指令视为一个同步点，强制同步掉之前所有的内存操作），从而向你保证该操作是原子的（取其不可分割之意），不会加法加到一半另一个线程插一脚进来</p>
<p>对于程序员，只需把 int 改成 atomic<int> 即可，也不必像 mutex 那样需要手动上锁解锁，因此用起来也更直观</p>
<p>即更改为 std::atomic<int> counter &#x3D; 0 ； +&#x3D;  ++ &amp;&#x3D; |&#x3D; ^&#x3D; 都有原子性(按位与，按位或，按位异或)</p>
<p>conuter.fetch_add(1)  &lt;&#x3D;&gt; counter +&#x3D; 1； store( ) &lt;&#x3D;&gt; &#x3D;；  load( ) 用于读取其中的int值</p>
<p>fetch_add会返回其旧值，int pld &#x3D; atm.fetch_add(val) 除了会导致atm的值增加val外，还会返回atm增加前的值存储到 old</p>
<p>这可以让它并行地往一个列表里追加数据，追加写入的索引就是fetch_add返回的旧值</p>
<p>exchange：读取的同时写入， exchange(val)会把val写入原子变量同时返回其旧值</p>
<p>compare_exchange_strong(old, val)：读取原子变量的值，比较是否与old相等，相等则把val写入原子变量，不相等则把原子变量的值写入旧值old</p>
<p>此处old传递的是一个引用，因此可以修改它的值</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230321232506012.png" alt="image-20230321232506012" style="zoom:80%;" />

<p>compare_exchange_strong的逻辑最为复杂，简称CAS(compare and swap)</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230321232908158.png" alt="image-20230321232908158" style="zoom:80%;" />

<h5 id="06-访存优化"><a href="#06-访存优化" class="headerlink" title="06.访存优化"></a>06.访存优化</h5><p>对于float：</p>
<p>1次减法 ≈ 1次加法      1次乘法 ≈ 1次加法      1次除法 ≥ 2次加法      </p>
<p>1次读写 ≈ 32次加法（矢量化成功 SSE）≈ 4次加法（矢量化失败）</p>
<p>如果循环体内是 a[i] &#x3D; func(a[i])，那么 func 里要包含16次加法，才能和内存的延迟相抵消</p>
<p>如果是 a[i] &#x3D; func(a[i], b[i])，那就是2次读1次写，总共其实是2次访存，那就要32次加法</p>
<p>如果有8个核心，则需要16*8&#x3D;128次加法，才能避免内存瓶颈，否则加速比会达不到16</p>
<p>当然，如果你是AVX  (256位)，则需要32次加法，AVX512，则需要64次加法！</p>
<p>用了 SIMD 发现没效果，可能是因为代码内存瓶颈而非计算瓶颈。也就是 func 里的运算非常简单，没有64次加法那么多，但是内存读写却实实在在。导致CPU大部分时间浪费在等内存延迟，这时候浮点计算得再快也没有用。</p>
<p>memory-bound：对 fill 这种纯粹只有访存的循环体，并行没有加速效果</p>
<p>cpu-bound：sin这种内部需要泰勒展开来计算，每次迭代计算量很大的循环体，并行才有较好的加速效果</p>
<p>下图是 int 的 add mul，float 的乘加一个速</p>
<p>L1&#x2F;2&#x2F;3 read 和 Main RAM read 的时间指的是读一个缓存行（64字节）所花费的时间 </p>
<p>从主内存读取一次float花费 125 &#x2F; 64 * 4 ≈ 8 个 cycle</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230322210653200.png" alt="image-20230322210653200" style="zoom:67%;" />

<p>要想利用全部CPU核心，避免mem-bound，需要func里有足够的计算量</p>
<p>当核心数量越多，CPU计算能力越强，相对之下来不及从内存读写数据，从而越容易mem-bound</p>
<p>sudo dmidecode -t memory 理论极限带宽 &#x3D; 频率 * 宽度 * 数量 &#x3D; 2667 * 8 * 2 &#x3D; 42467MB&#x2F;s （2块内存，数据宽度64位 8 字节）</p>
<p>计算实际带宽：搬运多少MB的数据 &#x2F; 耗时（理论也是MB）</p>
<p>查看高速缓存大小：lscpu</p>
<p>指令在执行的时候会读写大量数据，不希望在访问数据的时候把指令踢出缓存，否则缓存会重新加载就很慢，所以L1分为数据缓存与指令缓存</p>
<p>其中数据缓存有 32 KB，6 个物理核心每个都有一个，总共 192 KB，指令缓存也是 192 KB</p>
<p>二级缓存有 256 KB，6 个物理核心每个都有一个，总共 1.5 MB，三级缓存由各个物理核心共享，总共 12 MB</p>
<p>要避免memory-bound，数据量尽量足够小，如果能装的进缓存就高效了</p>
<p>读取缓存的工作机制：</p>
<p>CPU读取一个地址时，缓存去查找和该地址匹配的条目，找到就返回缓存数据，L3都找不到就向主内存发送请求，等读取到该地址的数据就创建一个新条目</p>
<p>x86中每个条目存储64字节数据，又称缓存行(cacheline)，当访问0x0048<del>0x0050 4 个字节时，实际会导致40</del>80的64个字节的数据被整个读取到缓存中</p>
<p>因此要把数据结构的起始地址和大小对齐到 64 字节，不要浪费缓存行的存储空间</p>
<p>缓存中存储的数据结构：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">CacheEntry</span> &#123;   </span><br><span class="line">    <span class="type">bool</span> valid;   </span><br><span class="line">    <span class="type">uint64_t</span> address;   </span><br><span class="line">    <span class="type">char</span> data[<span class="number">64</span>];</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">CacheEntry cache[<span class="number">512</span>];</span><br></pre></td></tr></table></figure>

<p>写入缓存的工作机制：</p>
<p>当CPU写入一个地址时，缓存会查找和该地址匹配的条目，找到就修改缓存中该地址的数据，找不到则创建一个新条目来存储CPU写的数据，并标记为脏（dirty）</p>
<p>脏数据表明还没有被写入到内存当中</p>
<p>当读和写创建的新条目过多，缓存快要塞不下时，它会把最不常用的那个条目移除，这个现象称为失效（invalid）</p>
<p>如果是读的时候创建的，那可以安全删除；如果是被标记为脏的，则说明是当时打算写入的数据，不一定已经写完，就需要向主内存发送写入请求，等它写入成功才能安全移除这个条目</p>
<p>如有多级缓存，则一级缓存失效后会丢给二级缓存。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">CacheEntry</span> &#123;</span><br><span class="line">   <span class="type">bool</span> valid, dirty;</span><br><span class="line">   <span class="type">uint64_t</span> address;</span><br><span class="line">   <span class="type">char</span> data[<span class="number">64</span>];</span><br><span class="line">&#125;;</span><br><span class="line">CacheEntry cache[<span class="number">512</span>];</span><br></pre></td></tr></table></figure>

<p>因为CPU和内存之间隔着缓存，而缓存和内存之间传输数据的最小单位是缓存行（64字节）</p>
<p>16个float是64字节，所以小于64字节的跨步访问，都会导致数据全部被读取出来；而超过64字节的跨步，中间的缓存行没有被读取，从而变快</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230322223656390.png" alt="image-20230322223656390" style="zoom: 67%;" />

<img src="/home/kwx/blog/source/_posts/assets/image-20230322223824279.png" alt="image-20230322223824279" style="zoom:67%;" />

<p>如果内部SOA太小，内部循环只有16次(1024 -&gt; 16)连续的读取，16次结束后就会跳跃一段，然后继续连续的读取。这会导致CPU预取机制失效，无法预测下一次要读哪里，等发现跳跃时已经来不及了，从而计算的延迟无法隐藏</p>
<p>如果每个属性都要访问到，AOS较好：这是因为使用SOA会让CPU不得不同时维护很多条预取赛道（mc_x, mc_y, mc_z），当赛道多了以后每一条赛道的长度就变短了，从而能够周转的余地时间比较少，不利于延迟隐藏。而如果把这三条赛道合并成一条（mc），这样同样的经费（缓存容量）能铺出的赛道（预取）就更长，从而CPU有更长的周转时间来隐藏他内部计算的延迟</p>
<p>页对齐：4KB </p>
<p>操作系统管理内存是用分页（page），程序的内存是一页一页贴在地址空间中的，有些地方可能不可访问，或者还没有分配，则把这个页设为不可用状态，访问它就会出错，进入内核模式</p>
<p>因此硬件出于安全，预取不能跨越页边界，否则可能会触发不必要的 page fault</p>
<p>因为本来就不能跨页顺序预取，所以被我们切断掉也无所谓，所以我们选用页的大小</p>
<p>另外，可以用 _mm_alloc 申请起始地址对齐到页边界的一段内存，真正做到每个块内部不出现跨页现象</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230322224711139.png" alt="image-20230322224711139" style="zoom: 80%;" />

<p>对于不得不随机访问很小一块的情况，还可以通过 _mm_prefetch 指令手动预取一个缓存行</p>
<p>这里第一个参数是要预取的地址（最好对齐到缓存行），第二个参数 _MM_HINT_T0 代表预取数据到一级缓存，_MM_HINT_NTA 则是预取到非临时缓冲结构中，可以最小化对缓存的污染，但是必须很快被用上</p>
<p>延迟隐藏：CPU的预取机制能够在等待a[i+1]的内存数据抵达时，默默地做着a[i]的计算，从而只要计算的延迟小于内存的延迟，延迟就被隐藏起来了，而不必等内存抵达了再算。这就是为什么有些运算量不足32次的程序还是会无法达到mem-bound，手动预取以后才能达到，就是因为硬件预取预测失败，导致不得不等内存抵达了才能算，导致延迟隐藏失败。</p>
<p>成功：</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230322230149362.png" alt="image-20230322230149362" style="zoom:50%;" />

<p>写入的粒度太小会造成不必要的读取：这是因为缓存和内存通信的最小单位是缓存行：64字节</p>
<p>当CPU试图写入4字节时，因为剩下的60字节没有改变，缓存不知道CPU接下来会不会用到那60字节，因此只好从内存读取完整的64字节，修改其中的4字节为CPU给的数据，之后再择机写回。这就导致了虽然没有用到读取数据，但实际上缓存还是从内存读取了，从而浪费了2倍带宽。</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230322231005167.png" alt="image-20230322231005167" style="zoom:50%;" />

<p>可以用 _mm_stream_si32 指令<strong>代替直接赋值的写入</strong>，它能够绕开缓存，将一个4字节的写入操作，挂起到临时队列，等凑满64字节后，直接写入内存，从而完全避免读的带宽，可惜它只支持int做参数，要用float还得转换一下指针类型，bitcast一下参数</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230322231058509.png" alt="image-20230322231058509" style="zoom:67%;" />

<p>因为 _mm_stream_si32 会绕开缓存，直接把数据写到内存，之后读取的话，反而需要等待 stream 写回执行完成，然后重新读取到缓存，反而更低效</p>
<p>因此仅当：该数组只有写入，之前完全没有读取过 &amp; 之后没有再读取该数组的地方 才应该用 stream 指令</p>
<p>4倍矢量化版本：_mm_stream_ps，第二参数是一个__m128 类型，可以配合其他手写的 SIMD 指令使用。不过，_mm_stream_ps 写入的地址必须对齐到 16 字节，否则会产生段错误等异常</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230322231303874.png" alt="image-20230322231303874" style="zoom:67%;" />

<p>stream 系列指令写入的地址，必须是连续的，中间不能有跨步，否则无法合并写入，会产生有中间数据读的带宽</p>
<p>写入1比写入0更慢：写入0被编译器自动优化成了memset，而memset内部利用了stream指令得以更快写入</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230322231451419.png" alt="image-20230322231451419" style="zoom:67%;" />

<p>因此可以用stream指令写入1：</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230322231431208.png" alt="image-20230322231431208" style="zoom:67%;" />

<p>_mm 系列指令出自 &lt;xmmintrin.h&gt; 头文件</p>
<p><a target="_blank" rel="noopener" href="https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html">https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html</a></p>
<p>循环合并：雅克比迭代</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230322232339235.png" alt="image-20230322232339235"  />

<img src="/home/kwx/blog/source/_posts/assets/image-20230322232346033.png" alt="image-20230322232346033"  />

<img src="/home/kwx/blog/source/_posts/assets/image-20230322232353986.png" alt="image-20230322232353986"  />

<img src="/home/kwx/blog/source/_posts/assets/image-20230322232446140.png" alt="image-20230322232446140"  />

<p>调用malloc时，os并不会实际分配那一块内存，而是将那块内存标记为不可用</p>
<p>当用户试图访问（写入）这一片内存时，硬件就会触发所谓的缺页中断（page fault），进入操作系统内核，内核会查找当前进程的 malloc 历史记录</p>
<p>如果发现用户写入的地址是他曾经 malloc 过的地址区间，则执行实际的内存分配，并标记该段内存为“可用”，下次访问就不会再缺页中断了；而如果写入地址根本不是 malloc 过的地址，就抛出段错误</p>
<p>初始化数组时，内存被写入，所以操作系统这时候才开始实际分配内存</p>
<p>不初始化的 malloc，第一次往里面赋值时，此时操作系统还没有给这个数组分配内存，所以会触发缺页中断，进入内核给数组分配内存，是内核执行内存分配的这个动作，花费了额外的时间</p>
<p>而第二次因为内存已经被分配上了，所以再次访问也不会触发缺页中断，所以看起来比第一次快很多</p>
<p>当一个尚且处于“不可用”的 malloc 过的区间被访问，os不是把整个区间全部分配完毕，而是只把当前写入地址所在的页面（4KB 大小）给分配上,也就是说用户访问 a[0] 以后只分配了 4KB 的内存</p>
<p>等到用户访问了 a[1024]，也就是触及了下一个页面，os才会继续分配一个 4KB 的页面，这时才 8KB 被实际分配，比如分配了 16GB 内存，但是只访问了它的前 4KB，这样只有一个页被分配，所以非常快</p>
<p>标准库的new和malloc保证16字节对齐</p>
<p>x86 特有的 _mm_malloc(n, aalign) 可以分配对齐到任意 a 字节的内存，需要通过 _mm_free 来释放</p>
<p>临时创建的数组手动池化：声明为static thread_local</p>
<p>手动扁平化：$a_{m\times n}$ &#x3D;&#x3D;&gt; a[i * m + j]  列主序  [i + j * n] 行主序</p>
<p>简单来说，哪个索引连续，就是什么主序</p>
<p>高维数组扁平化：$a_{nz\times ny\times nx}$   a[z][y][x] &#x3D; a[(z * ny + y) * nx + x]  (倒过来看)</p>
<p>什么序的数组，就用什么序遍历</p>
<p>插桩：指在结构网格中，从一个点往周围固定范围读取值，并根据一定权重累加，然后修改自身的值</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230323231203722.png" alt="image-20230323231203722" style="zoom:67%;" />

<img src="/home/kwx/blog/source/_posts/assets/image-20230323231216378.png" alt="image-20230323231216378" style="zoom: 80%;" />

<img src="/home/kwx/blog/source/_posts/assets/image-20230323233738141.png" alt="image-20230323233738141" style="zoom:80%;" />

<p>由于 Y 方向插桩的内存读取模式，有 nblur 次跳跃，每次跳跃的距离是 nx(x &lt; nx)，从而缓存容量需要有 nx*nblur 那么大才能利用全部的缓存</p>
<p>因此可以用循环分块（loop tiling），将外部两层循环变为 blockSize 为跨步的，而内部则在区间 [xBase, xBase + blockSize) 上循环</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230323234653212.png" alt="image-20230323234653212" style="zoom:80%;" />

<img src="/home/kwx/blog/source/_posts/assets/image-20230323235039890.png" alt="image-20230323235039890" style="zoom:67%;" />

<img src="/home/kwx/blog/source/_posts/assets/image-20230323235215662.png" alt="image-20230323235215662" style="zoom:67%;" />

<img src="/home/kwx/blog/source/_posts/assets/image-20230323235225740.png" alt="image-20230323235225740" style="zoom:67%;" />

<img src="/home/kwx/blog/source/_posts/assets/image-20230323235303120.png" alt="image-20230323235303120" style="zoom:80%;" />

<p>使用预取和直写后都变得更加慢了：</p>
<p>写入了b污染了L1，预取效果不好；</p>
<p>直写的时间点过于分散了，中间夹杂着加法的运算导致写入挂起队列指令太长，CPU放弃了合并的直写</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230323235320926.png" alt="image-20230323235320926" style="zoom: 80%;" />

<img src="/home/kwx/blog/source/_posts/assets/image-20230323235404008.png" alt="image-20230323235404008" style="zoom:80%;" />

<p>把 res 变成数组暂时存一下，最后再一次性用 stream 写入，stream 需要时空上集中一起效果才比较好</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230323235510274.png" alt="image-20230323235510274" style="zoom:80%;" />

<p>把一次写入4字节的 _mm_stream_si32 换成了一次写入16字节的 _mm_stream_ps</p>
<p>把 res 换成了 __m128 的数组，并用 _mm 系列指令读取 a 和计算加法</p>
<p>但是注意到这里 res[offset] 的访问，一次只有其中一个被用上，不能很好的利用寄存器资源</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230323235651792.png" alt="image-20230323235651792" style="zoom:80%;" />

<p>为了充分填满寄存器，把 t 循环和 offset 循环交换一下，把 offset 换到内层循环去，这样至少能让四个寄存器同时在进行加法运算</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230323235853023.png" alt="image-20230323235853023" style="zoom:80%;" />

<p>注意到 offset 循环只有 4 的大小，所以加一下 unroll 指令让编译器自动循环展开吧</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230323235944737.png" alt="image-20230323235944737" style="zoom:80%;" />

<p>m128 一次处理四个float，改成 m256 一次处理八个float</p>
<p>不过因为res有四个寄存器，4*4*8&#x3D;128字节，所以 _mm_prefetch 需要预取两个缓存行才行</p>
<p>这里 blockSize 和 32 似乎一样了，所以 xBase 也可以直接去掉了</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230324000225465.png" alt="image-20230324000225465" style="zoom:80%;" />

<p>预取的地址太靠近了，可能还是会让CPU陷入等待，无法隐藏计算的延迟。再稍微往前调一点点试试看。提前量不能太多，否则需要很大的缓存大小，否则到时候读的太多又得赶到二级缓存；也不能太少，否则等计算到那里的时候数据来不及取出，导致延迟无法隐藏</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230324000235957.png" alt="image-20230324000235957" style="zoom:80%;" />

<p>矩阵转置：</p>
<p>循环是 YX 序的，虽然 b(x, y) 也是 YX 序的没问题，但是 a(y, x) 相当于一个 XY 序的二维数组，从而在内存看来访存是跳跃的，违背了空间局域性</p>
<p>因为每次跳跃了 nx，所以只要缓存容量小于 nx 就无法命中</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230324213348371.png" alt="image-20230324213348371" style="zoom:80%;" />

<p>优化：循环分块  YXyx序</p>
<p>只需块的大小 blockSize^2 小于缓存容量，即可保证全部命中</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230324213435510.png" alt="image-20230324213435510" style="zoom:80%;" />

<p>莫顿码：<a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1461134">https://cloud.tencent.com/developer/article/1461134</a></p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230324213710043.png" alt="image-20230324213710043" style="zoom:67%;" />

<p><img src="/home/kwx/blog/source/_posts/assets/image-20230324214025070.png" alt="image-20230324214025070"></p>
<p>循环莫顿序：按照Z字型曲线遍历，有效利用多级缓存</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230324214124487.png" alt="image-20230324214124487" style="zoom:80%;" />

<p>按照Z曲线遍历，首先只需要一个一维循环，其循环变量就是莫顿码，区间范围则是 [0, nx*ny&#x2F;blockSize^2)</p>
<p>然后，通过莫顿解码，获取 X，Y 分量，这样就是Z字型曲线遍历的了，可以打印 xBase, yBase 出来看一看</p>
<p>缺点：nx和ny必须是二的幂次方，否则需要一些特殊判断防止越界。</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230324214256714.png" alt="image-20230324214256714" style="zoom:85%;" />

<p>矩阵乘法：</p>
<p>a(i, j)始终在一个地址不动 对于缓存是好 对于cpu是坏事 因为这就意味着串行着在同一个变量上做加法</p>
<p>而串行着做加法，cpu是无法做指令级并行的，相当于一直串行着做标量处理</p>
<p>b(i, j)每次跳跃 n 间隔的访问（对缓存不友好），c(t, j) 连续的顺序访问（好）</p>
<p>因为存在不连续的 b 和一直不动的 a，导致矢量化失败，一次只能处理一个标量，CPU也无法启动指令级并行（ILP）</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230324221307074.png" alt="image-20230324221307074" style="zoom:80%;" />

<p>寄存器分块：特点是跨越t循环，跨越到里面来的</p>
<p>之前的a在大小为n的t循环中都是同一个地址，这是没法使用指令集并行的，对cpu来说就是reduction，也就是不断往同一个地址累加，没法并行</p>
<p>寄存器分块后，从0到32不再是同一个地址</p>
<p>分析访存规律：a(i, j) 连续 32 次顺序访问（好），b(i, t) 连续 32 次顺序访问（好），c(t, j) 32 次在一个地址不动（一般）</p>
<p>这样就消除不连续的访问了，从而内部的 i 循环可以顺利矢量化，且多个循环体之间没有依赖关系，CPU得以启动指令级并行，缓存预取也能正常工作</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230324224306879.png" alt="image-20230324224306879" style="zoom:80%;" />

<p>小内核卷积：寄存器分块，跳跃了l和k</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230324232152974.png" alt="image-20230324232152974" style="zoom:80%;" />

<img src="/home/kwx/blog/source/_posts/assets/image-20230324232201109.png" alt="image-20230324232201109" style="zoom:80%;" />

<p>最内层unroll：</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230324232223332.png" alt="image-20230324232223332" style="zoom:80%;" />

<p>伪共享：</p>
<p>如果多个核心同时访问的地址非常接近，这时候会变得很慢！这是因为 CPU 之间通信的最小单位也是 缓存行（64 字节），如果两个核心访问到了的同一缓存行，假设一个核心修改了该缓存行的前32字节，另一个修改了后32字节，同时写回的话，结果要么是只有前32字节，要么是只有后32字节，而不能两个都正确写入。所以CPU为了安全起见，同时只能允许一个核心写入同一地址的缓存行。从而导致读写这个变量的速度受限于三级缓存的速度，而不是一级缓存的速度。</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230325210317136.png" alt="image-20230325210317136" style="zoom:80%;" />

<p>消除错误共享只需要把每个核心写入的地址尽可能分散开。比如这里我们把每个核心访问的地方跨越了 16KB，这样CPU就知道每个核心之间不会发生冲突，从而可以放心地放在一级缓存里，不用担心会不会和其他核心共用了一个缓存行了。</p>
<p>错误共享只会发生在写入的情况，如果多个核心同时读取两个很靠近的变量，是不会产生冲突的，也没有性能损失</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230325210505407.png" alt="image-20230325210505407" style="zoom:80%;" />

<h5 id="07-CUDA"><a href="#07-CUDA" class="headerlink" title="07.CUDA"></a>07.CUDA</h5><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> (CMAKE_BUILD_TYPE Release)</span><br><span class="line"><span class="keyword">project</span>(hellocuda LANGUAGES CXX CUDA)</span><br><span class="line"><span class="keyword">add_executable</span>(main main.cu)</span><br></pre></td></tr></table></figure>

<p>兼容C++17</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sctdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__device__ <span class="type">void</span> <span class="title">say_hello</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello, world!\n&quot;</span>);</span><br><span class="line">&#125;  </span><br><span class="line"><span class="comment">// device是GPU内部的调用，不能直接从main调用，而是必须从另一个global或device调用，因此也不需要三个尖括号，可以有返回值</span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">say_hello</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;();  # 调用时，要使用三重尖括号</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();  # 让CPU陷入等待，等GPU完成队列的所有任务后返回</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 即host可以调global，global可以调device，device可以调device</span></span><br><span class="line"><span class="comment">// __device__将函数定义在GPU上，__host__将函数定义在CPU上 __host__可以省略，默认就是host，包括main函数</span></span><br><span class="line"><span class="comment">// __host__ __device__连用，同时定义在CPU和GPU上</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">constexpr</span> <span class="type">const</span> <span class="type">char</span>* <span class="title">cuthead</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* p)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> p + <span class="number">1</span>;</span><br><span class="line">&#125; </span><br><span class="line"><span class="comment">// constexpr通常都是一些可以内联的函数，数学计算之类，想让constexpr修饰的函数自动变成__host__ __device__</span></span><br><span class="line"><span class="comment">// 当然constexpr里没法调用printf，也不能用_syncthreads之类的GPU特有的函数，因此也不能完全替代 __host__ 和 __device__</span></span><br><span class="line"><span class="comment">// 用CMake的生成器表达式来实现只对.cu文件开启此选项，不然给到GCC就出错了</span></span><br><span class="line"><span class="built_in">target_compile_options</span>(main PUBLIC $&lt;$&lt;COMPILE_LANGUAGE:CUDA&gt;:--expt-relaxed-<span class="keyword">constexpr</span>&gt;)</span><br><span class="line">    </span><br><span class="line"><span class="comment">// CUDA编译器具有多段编译的特点，第一次提取出host送给GCC生成CPU部分的指令码，第二次提取出global和device交给NVCC生成GPU部分的指令码</span></span><br><span class="line"><span class="comment">// 最后寻找三重尖括号的位置，把CPU编译好的那一份给link到GPU指令码的那一份</span></span><br><span class="line"><span class="comment">// 编译期指定的版本 &lt;= 运行时显卡的版本</span></span><br><span class="line"><span class="built_in">set</span>(CMAKE_CUDA_ARCHITECTURES <span class="number">75</span>)  <span class="comment">// 会自动转换成 --gpu-code 等编译 flag，20系是75</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">// &lt;&lt;&lt;block数量，每个block的thread数量&gt;&gt;&gt; 也就是 &lt;&lt;&lt;gridDim, blockDim&gt;&gt;&gt;</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span> </span>&#123;  <span class="comment">// 扁平化</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> tid = blockDim.x * blockIdx.x + threadIdx.x;  <span class="comment">// 总的线程编号</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> tnum = blockDim.x * gridDim.x;  <span class="comment">// 总的线程数量</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 线程是并行的最小单位 实际上一维的 &lt;&lt;&lt;m, n&gt;&gt;&gt; 不过是 &lt;&lt;&lt;dim3(m, 1, 1), dim3(n, 1, 1)&gt;&gt;&gt; 的简写而已。</span></span><br><span class="line"><span class="comment">// Kelper开始，__global__ 里可以调用另一个 __global__，且其三重尖括号里的板块数和线程数可以动态指定，无需先传回到 CPU 再进行调用</span></span><br><span class="line"><span class="comment">// 常用于这种情况：需要从 GPU 端动态计算出 blockDim 和 gridDim，而又不希望导回数据到 CPU 导致强制同步影响性能</span></span><br><span class="line"><span class="comment">// 这种模式被称为动态并行（dynamic parallelism），同样需要开启 CUDA_SEPARABLE_COMPILATION </span></span><br><span class="line"><span class="comment">// 把一个kernel里算出来的值直接喂到另一个kernel里面，无需同步</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 全局有效</span></span><br><span class="line"><span class="built_in">set</span>(CMAKE_CUDA_SEPARABLE_COMPILATION ON)</span><br><span class="line"><span class="built_in">add_executable</span>(main main.cu)</span><br><span class="line"><span class="comment">// 只对main程序启用</span></span><br><span class="line"><span class="built_in">set_property</span>(TARGET main PROPERTY CUDA_SEPERABLE_COMPILATION ON)</span><br></pre></td></tr></table></figure>

<p>异步，所以不可能从kernel里通过返回值获取GPU数据，因为kernel返回时核函数并没有在GPU执行，所以必须是void，std::thread同理</p>
<p>CUDA的函数，如cudaDeviceSynchronize( )出错时不会直接终止程序，也不会抛出C++异常，而是返回一个错误代码</p>
<p>GPU使用独立的显存（设备内存device），不能访问CPU内存（主机内存host）堆栈上的变量 所以要使用cudaMalloc</p>
<p>CPU也访问不了GPU的内存地址，直接段错误</p>
<p>注意cudaMalloc的返回值已经用来表示错误代码，所以返回指针只能通过&amp;pret二级指针</p>
<p>也就是先分配个指针，然后取指针的指针，来分配GPU内存</p>
<p>跨GPU&#x2F;CPU拷贝：cudaMemcpy会自动同步！拷贝方向往左边，最后参数又是从左往右</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326141948993.png" alt="image-20230326141948993" style="zoom:80%;" />

<p>所以上面synchronize可以删除，GPU的性能是通过大吞吐量来掩盖延迟，如果没有塞满，就可能影响性能</p>
<p>cudaMallocManaged：统一内存地址技术（Unified Memory）</p>
<p>分配出来的地址不论在CPU&#x2F;GPU上都是一模一样的； 自动拷贝（当从CPU访问时），不需要再写memcpy，但也因此需要加上synchornize；并非完全没有开销</p>
<p>分配数组：</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326143144660.png" alt="image-20230326143144660" style="zoom:67%;" />

<p>多个线程并行赋值：刚才单线程for循环是串行的，可以用threadIdx.x作为i索引，这样就实现了每个线程给数组的一个元素赋值</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326143154834.png" alt="image-20230326143154834" style="zoom:67%;" />

<p>技巧：网格跨步循环（grid-stride loop）</p>
<p>分配太大的n给三尖括号，GPU可能会吃不消，因此可以让传入的参数大一点，小线程自动分配数组赋值</p>
<p>无论调用者指定了多少个线程（blockDim），都能自动根据给定的 n 区间循环，不会越界，也不会漏掉几个元素</p>
<p>这样一个 for 循环非常符合 CPU 上常见的 parallel for 的习惯，又能自动匹配不同的 blockDim，看起来非常方便</p>
<p><img src="/home/kwx/blog/source/_posts/assets/image-20230326143421665.png" alt="image-20230326143421665"></p>
<p>向上取整：int nblocks &#x3D; (n + nthreads - 1) &#x2F; nthreads 解决边角料</p>
<p>但因为向上取整会多出一些线程，所以要在kernel内判断当前i是否超过了n（实际应为&gt;&#x3D;n），超过就要提前退出，防止越界</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326154256521.png" alt="image-20230326154256521" style="zoom:80%;" />

<p>边角料的另一种处理方法，网格跨步循环：thread + block ，利用扁平化的线程数量和线程编号实现动态大小</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326154944378.png" alt="image-20230326154944378" style="zoom:80%;" />

<p>指定32block，每个block线程数128，跨步的大小就是网格的大小</p>
<p>就是每个数组元素都是跨步赋值的，抵达数组长度就结束了</p>
<p>无论调用者指定每个板块多少线程（blockDim），总共多少板块（gridDim）。都能自动根据给定的 n 区间循环，不会越界，也不会漏掉几个元素</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">std::vector&lt;T, std::allocator T&gt;  <span class="comment">// 负责在CPU上分配和释放内存，初始化T对象等等，也就是调用了malloc跟free</span></span><br><span class="line"><span class="function">T* <span class="title">allocate</span><span class="params">(<span class="type">size_t</span> n)</span>  <span class="comment">// 分配长度为n类型为T的数组，返回其起始地址</span></span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">deallocate</span><span class="params">(T *p, <span class="type">size_t</span> n)</span> <span class="comment">// 释放长度为n，起始地址为p，类型为T的数组</span></span></span><br></pre></td></tr></table></figure>

<p>魔改抽象的std::allocator接口重用vector：</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326161859095.png" alt="image-20230326161859095" style="zoom:80%;" />

<p>std::is_pod_v：判断T是不是C语言类型(int, float以及这些基础类型组成的结构体)</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326162214004.png" alt="image-20230326162214004" style="zoom:80%;" />

<p>避免初始化为0：因为vector在初始化的时候(or resize)会调用所有元素的无参构造函数，对int来说就是零初始化，然而这个初始化是在CPU上做的，所以要禁用它</p>
<p>可以通过给 allocator 添加 construct 成员函数，来魔改 vector 对元素的构造</p>
<p>默认情况下他可以有任意多个参数，而如果没有参数则说明是无参构造函数，因此只需要判断是不是有参数，然后是不是传统的 C 语言类型（plain-old-data），如果是，则跳过其无参构造，从而避免在 CPU 上低效的零初始化</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326162400034.png" alt="image-20230326162400034" style="zoom:80%;" />

<p>核函数可以是一个模板函数：arr.data( )返回数组中第一个元素的指针</p>
<p>T是自动推导的，而n是从尖括号里指定的</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326162435456.png" alt="image-20230326162435456" style="zoom:80%;" />

<p>核函数可以接受函子(functor)，实现函数式编程</p>
<p>定义了个MyFunctor，里面有个device的operator( )成员函数，即为函子(仿函数)，也就是具有operator( )的任何东西，可以通过对象将其调用</p>
<p>这里的 Func 不可以是 Func const &amp;，那样会变成一个指向 CPU 内存地址的指针，从而出错， CPU 向 GPU 的传参必须按值传</p>
<p>做参数的这个函数必须是一个有着成员函数 operator( ) 类型，即 functor 类，而不能是独立的函数，否则报错，这个函数必须标记为 __device__，即 GPU 上的函数，否则会变成 CPU 上的函数</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326163101537.png" alt="image-20230326163101537" style="zoom:80%;" />

<p>函子可以是lambda表达式：</p>
<p>可以直接写 lambda 表达式，不过必须在 [] 后，() 前，插入 <strong>device</strong> 修饰符，而且需要开启 –extended-lambda 开关，device就是在GPU上调用</p>
<p>为了只对 .cu 文件开启这个开关，可以用 CMake 的生成器表达式，限制 flag 只对 CUDA 源码生效，这样混合其他 .cpp 文件时也不会发生 gcc 报错的情况</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326163304628.png" alt="image-20230326163304628" style="zoom:80%;" />

<p><img src="/home/kwx/blog/source/_posts/assets/image-20230326163314267.png" alt="image-20230326163314267"></p>
<p>捕获外部变量：</p>
<p>虽然arr数组是分配在GPU上的，但是arr的指针本身是分配在cpu main函数的栈上的</p>
<p>捕获的是指向array的指针的指针，捕获的是一个指向CPU指针的指针，从而这里去访问array会先访问到array在CPU栈上的内存，然后访问到它指向GPU的内存，而栈上的内存GPU是访问不到的</p>
<p>如果试图用 [&amp;] 捕获变量是会出错的，毕竟这时候捕获到的是堆栈（CPU内存）上的变量 arr 本身，而不是 arr 所指向的内存地址（GPU内存）</p>
<p>那如果按值捕获呢？绝大多数C++都是深拷贝（除了智能指针和原始指针），这样只会把vector整个拷贝到GPU上，而不是浅拷贝其起始地址指针</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326163917876.png" alt="image-20230326163917876" style="zoom:80%;" />

<p><img src="/home/kwx/blog/source/_posts/assets/image-20230326163924857.png" alt="image-20230326163924857"></p>
<p>正确的做法是先获取 arr.data() 的值到 arr_data 变量，然后用 [&#x3D;] 按值捕获 arr_data，函数体里面也通过 arr_data 来访问 arr</p>
<p>因为 data() 返回一个起始地址的原始指针，而原始指针是浅拷贝的，所以可以拷贝到 GPU 上让它访问，这样和之前作为核函数参数是一样的，相当于打包到结构体func，不过是作为 Func 结构体统一传入了（原始指针是C语言类型）</p>
<p><img src="/home/kwx/blog/source/_posts/assets/image-20230326164015600.png" alt="image-20230326164015600"></p>
<p>或者在 [] 里这样直接写自定义捕获的表达式也是可以的，这样就可以用同一变量名</p>
<p>让闭包里的arr这个变量成为指向arr的指针，从而浅拷贝，也就不需要在外面再写个arr.data( )了</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326164054190.png" alt="image-20230326164054190" style="zoom:80%;" />

<p><img src="/home/kwx/blog/source/_posts/assets/image-20230326165112033.png" alt="image-20230326165112033"></p>
<p>开启了 –use_fast_math 选项，那么所有对 sinf 的调用都会自动被替换成 __sinf</p>
<p>–ftz&#x3D;true 会把极小数(denormal)退化为0； –prec-div&#x3D;false 降低除法的精度换取速度；–prec-sqrt&#x3D;false 降低开方的精度换取速度</p>
<p>–fmad 因为非常重要，所以默认就是开启的，会自动把 a * b + c 优化成乘加(FMA)指令，开启 –use_fast_math 后会自动开启上述所有。</p>
<p>thrust库</p>
<p>数组求和结果不对：</p>
<p>因为 <strong>global</strong> 函数不能返回值，只能通过指针，因此先分配一个大小为 1 的 sum 数组，其中 sum[0] 用来返回数组的和</p>
<p>这样同步之后就可以通过 sum[0] 看到求和的结果了</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326173602922.png" alt="image-20230326173602922" style="zoom:80%;" />

<p>这是因为 GPU 上的线程是并行执行的，然而 sum[0] +&#x3D; arr[i] 这个操作，实际上被拆分成四步：</p>
<p>读取 sum[0] 到寄存器A  &#x3D;&#x3D;&gt; 读取 arr[i] 到寄存器B &#x3D;&#x3D;&gt; 让寄存器A的值加上寄存器B的值 &#x3D;&#x3D;&gt; 写回寄存器A到 sum[0]</p>
<p>假如有两个线程分别在 i&#x3D;0 和 i&#x3D;1，同时执行：</p>
<p>线程0：读取 sum[0] 到寄存器A（A&#x3D;0）线程1：读取 sum[0] 到寄存器A（A&#x3D;0）</p>
<p>线程0：读取 arr[0] 到寄存器B（B&#x3D;arr[0]）线程1：读取 arr[1] 到寄存器B（B&#x3D;arr[1]）</p>
<p>线程0：让寄存器A加上寄存器B（A&#x3D;arr[0]）线程1：让寄存器A加上寄存器B（A&#x3D;arr[1]）</p>
<p>线程0：写回寄存器A到 sum[0]（sum[0]&#x3D;arr[0]）线程1：写回寄存器A到 sum[0]（sum[0]&#x3D;arr[1]）</p>
<p>这样一来最后 sum[0] 的值是 arr[1]。而不是我们期望的 arr[0] + arr[1]，即算出来的总和变少了</p>
<p>所以需要使用原子操作来保证读取&#x2F;加法&#x2F;写会三个操作，中途不会有另一个线程来打扰</p>
<p>CUDA也提供了atomicAdd，效果和+&#x3D;一样，不过是原子的，第一个参数是个指针，指向要修改的地址；第二个参数是要增加多少</p>
<p>即：atomicAdd(dst, src) 和 *dst +&#x3D; src 差不多  它会把sum[0]给锁住</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326174207190.png" alt="image-20230326174207190" style="zoom:80%;" />

<p>atomicAdd会返回旧值：可以保存到返回值</p>
<p>old &#x3D; atomicAdd(dst, src) 其实相当于：old &#x3D; *dst; *dst +&#x3D; src;</p>
<p>利用这一点可以实现往一个全局的数组 res 里追加数据的效果，其中 sum 起到了记录当前数组大小的作用</p>
<p>因为返回的旧值就相当于在数组里“分配”到了一个位置一样，不会被别人占据</p>
<p>sum(1)是分配了初值为0的单元素数组</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326190629523.png" alt="image-20230326190629523" style="zoom:80%;" />

<p>sub，or，and，xor，max，min</p>
<p>atomicExch：原子写入并读取旧值，Exch是exchange的简写，对标的是std::atomic的exchange函数</p>
<p>old &#x3D; atomicExch(dst, src) 相当于：old &#x3D; *dst; *dst &#x3D; src</p>
<p>atomicCAS：原子地判断是否相等，相等则写入，并读取旧值</p>
<p>old &#x3D; atomicCAS(dst, cmp, src) 相当于：old &#x3D; *dst;if (old &#x3D;&#x3D; cmp)  *dst &#x3D; src</p>
<p>atomicCAS 的作用在于他可以用来实现任意 CUDA 没有提供的原子读-修改-写回指令，比如这里通过 atomicCAS 实现了整数 atomicAdd 同样的效果</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326191618099.png" alt="image-20230326191618099" style="zoom:80%;" />

<p>里面换成 expect * src，就变成了原子乘法  atomicMul，虽然 CUDA 没提供</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326191716983.png" alt="image-20230326191716983" style="zoom:80%;" />

<p>提升原子操作性能：</p>
<p>先累加到局部变量 local_sum，最后一次性累加到全局的 sum，这样每个线程就只有一次原子操作，而不是网格跨步循环的那么多次原子操作了</p>
<p>当然，还需要调小 gridDim * blockDim 使其远小于 n，这样才能够减少原子操作的次数，下图就减少了 4096&#x2F;512&#x3D;8 倍的原子操作</p>
<p>网格跨步循环执行了4096&#x2F;512&#x3D;8次，每个线程执行8次原子就低效了，因为每次跨网格嘛</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326192028395.png" alt="image-20230326192028395" style="zoom:80%;" />

<p>GPU 是由多个流式多处理器（SM）组成的，每个 SM 可以处理一个或多个板块</p>
<p>SM 又由多个流式单处理器（SP）组成，每个 SP 可以处理一个或多个线程</p>
<p>每个 SM 都有自己的一块共享内存，性质类似于 CPU 中的缓存——和主存相比很小，但是很快，用于缓冲临时数据</p>
<p>通常板块数量总是大于 SM 的数量，这时驱动就会在多个 SM 之间调度你提交的各个板块，正如操作系统在多个 CPU 核心之间调度线程那样</p>
<p>不过有一点不同，GPU 不会像 CPU 那样做时间片轮换，板块一旦被调度到了一个 SM 上，就会一直执行，直到它执行完退出，这样的好处是不存在保存和切换上下文（寄存器，共享内存等）的开销，毕竟 GPU 的数据量比较大，禁不起这样切换来切换去</p>
<p>一个 SM 可同时运行多个板块，这时多个板块共用同一块共享内存（每块分到的就少了），而板块内部的每个线程，则是被进一步调度到 SM 上的每个 SP</p>
<p>无原子解决方案：</p>
<p>先声明sum为比原数组小1024倍的数组，然后在 GPU 上启动 n &#x2F; 1024 个线程，每个负责原数组中 1024 个数的求和，然后写入到 sum 的对应元素中去</p>
<p>因为每个线程都写入了不同的地址，所以不存在任何冲突，也不需要原子操作了，每个线程访问到的是sum的不同地方</p>
<p>然后求出的大小为 n &#x2F; 1024 的数组，已经足够小了，可以直接在 CPU 上完成最终的求和</p>
<p>也就是 GPU 先把数据尺寸缩减 1024 倍到 CPU 可以接受的范围内，然后让 CPU 完成的思路</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326192816225.png" alt="image-20230326192816225" style="zoom: 80%;" />

<p>先读取到线程局部数组，然后分布缩减，让数据间没有先后依赖</p>
<p>板块内的所有数组才是并行的</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326194101544.png" alt="image-20230326194101544" style="zoom:80%;" />

<img src="/home/kwx/blog/source/_posts/assets/image-20230326200556820.png" alt="image-20230326200556820" style="zoom:80%;" />

<p>在每个if分支后加上__syncthreads( )强制同步当前板块内的所有线程，这样就能保证之前其他线程的local_sum都已经写入成功了</p>
<p>线程组32个为一束（warp）：SM 对线程的调度是按照 32 个线程为一组来调度的，0-31号线程为一组，32-63号线程为一组，以此类推</p>
<p>因此 SM 的调度无论如何都是对一整个线程组（warp）进行的，不可能出现一个组里只有单独一个线程被调走，要么 32 个线程一起调走</p>
<p>所以 j &lt; 32 之后，就不需要 __syncthreads() 了，因为此时所有访问 local_sum 的线程都在一个组里，反正都是一起调度走，不需要同步</p>
<p>把 local_sum 数组声明为 volatile 禁止编译器优化</p>
<p>GPU 线程组（warp）中 32 个线程实际是绑在一起执行的，因此如果出现分支（if）语句时，如果 32 个 cond 中有的为真有的为假，则会导致两个分支都被执行</p>
<p>为了避免会产生额外的开销，建议 GPU 上的 if 尽可能 32 个线程都处于同一个分支，要么全部真要么全部假，否则实际消耗了两倍时间</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326200647528.png" alt="image-20230326200647528" style="zoom: 67%;" />

<p>使用网格跨步一次性读取多个arr元素：</p>
<p>可见共享内存中做求和开销还是有点大，之后那么多次共享内存的访问，前面却只有一次全局内存 arr 的访问，是不是太少了</p>
<p>因此可以通过网格跨步循环增加每个线程访问 arr 的次数，从而超过共享内存部分的时间，当然也别忘了在 main 中增加 gridDim 的大小</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326201056192.png" alt="image-20230326201056192" style="zoom: 67%;" />

<img src="/home/kwx/blog/source/_posts/assets/image-20230326201049505.png" alt="image-20230326201049505" style="zoom:80%;" />

<p>通过模板函数包装一下 BLS（block-local storage）：</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326202219205.png" alt="image-20230326202219205" style="zoom:80%;" />

<img src="/home/kwx/blog/source/_posts/assets/image-20230326202224699.png" alt="image-20230326202224699"  />

<p>进一步，当数组非常大，缩减后的数组可以继续递归地用 GPU 求和</p>
<p>同样是缩并到一定小的程度开始就切断(cutoff)，开始用 CPU 串行求和</p>
<p><a target="_blank" rel="noopener" href="https://developer.download.nvidia.cn/assets/cuda/files/reduction.pdf">https://developer.download.nvidia.cn/assets/cuda/files/reduction.pdf</a></p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326202249665.png" alt="image-20230326202249665" style="zoom:80%;" />



<p>1个GPU由多个SM组成，每个SM一次可以执行32个线程，在板块中的1024个线程中反复切来切去来隐藏内存的延迟，每个线程都是有寄存器</p>
<p>对于使用寄存器较少、访存为主的核函数（例如矢量加法），使用大 blockDim 为宜；反之（例如光线追踪）使用小 blockDim，但也不宜太小</p>
<p>线程有线程局部内存，板块有共享内存，kernel有全局显存</p>
<p>矩阵转置：</p>
<p>一行一行用行主序去访问，out是行，但in是用行主序去访问列主序，CPU上是循环分块</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326202957185.png" alt="image-20230326202957185" style="zoom:80%;" />

<p>需要使用二维的 blockDim 和 gridDim，然后在核函数里分别计算 x 和 y 的扁平化线程编号就行了！它会自动变成循环分块一样的效果，有利于缓存局域性</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326203146222.png" alt="image-20230326203146222" style="zoom:80%;" />

<p>共享内存和板块的L1内存是一样快的，可以手动把内容读到缓存里做完转置再写到外面来</p>
<p>上面对 in 的读取是存在跨步的，而 GPU 喜欢连续的顺序读取，这样跨步就不高效了，但是矩阵转置，无论是 in 还是 out 必然有一个是需要跨步的，怎么办？</p>
<p>因此可以先通过把 in 分块，按块跨步地读，而块内部则仍是连续地读——从低效全局的内存读到高效的共享内存中，然后在共享内存中跨步地读，连续地写到 out 指向的低效的全局内存中，这样跨步的开销就开在高效的共享内存上，而不是低效的全局内存上，因此会变快</p>
<p>rx，ry是按块跨步；tmp的读写速度是一级缓存的速度</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326203407009.png" alt="image-20230326203407009" style="zoom:80%;" />

<p>区块：</p>
<p>GPU 的共享内存，实际上是 32 块内存条通过并联组成的（有点类似 CPU 的双通道内存条），每个 bank 都可以独立地访问，每个时钟周期都可以读取一个 int</p>
<p>然后，他们把地址空间分为 32 分，第 i 根内存条，负责 addr % 32 &#x3D;&#x3D; i 的那几个 int 的存储，这样交错存储，可以保证随机访问时，访存能够尽量分摊到 32 个区块，这样速度就提升了 32 倍</p>
<p>比如：<strong>shared</strong> int arr[1024]; 那么 arr[0] 是存储在 bank 0，arr[1] 是 bank 1……arr[32] 又是 bank 0，arr[33] 又是 bank 1</p>
<p><img src="/home/kwx/blog/source/_posts/assets/image-20230326212712522.png" alt="image-20230326212712522"></p>
<p>但这种设计有一个问题：如果多个线程同时访问到了同一个 bank 的话，就需要排队</p>
<p>假设线程0-3同时访问了 bank 0，但是同一个 bank 是需要排队，也就是串行访问的，所以线程0-3实际上没有真正并行起来，慢了4倍</p>
<p>bank 是按照 addr % 32 来划分的，也就是说 arr[0] 和 arr[32] 是同属于 bank 0 的，如果两个线程同时访问了 arr[0] 和 arr[32] 就会出现 bank conflict 导致必须排队影响性能</p>
<p>解决区块冲突：把 tmp 这个二维数组从 32x32 变成 33x32</p>
<p>通常总以为把数组大小对齐到二的幂次是好事，但对共享内存对齐地划分 bank 这种独特的特性来说，有时故意不对齐反而是好事</p>
<p>这样线程 0 访问的就是 arr[0] 位于 bank 0，线程 1 访问的就是 arr[33] 位于 bank 1，线程 2 访问的就是 arr[66] 位于 bank 2，正好变成了一个线程访问一个 bank，没有冲突，不需要排队，从而可以并行访问</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230326214452110.png" alt="image-20230326214452110" style="zoom:80%;" />

<p>13.vector</p>
<p>sizeof(vector)得到24，3个指针</p>
<p>第一个指针指向堆上的地址，这个地址是vector的起始地址，从起始地址开始才是它真正存储的元素</p>
<p>指针存在栈上，但是它指向的位置是存在堆上的，因为在栈上是无法动态扩容的</p>
<p>第二个指针指向的是它的结束位置，知道了开始与结束也就知道了它的长度</p>
<p>超出长度时[]不会报错，因为追求高效，因为它不会用if语句来检查长度</p>
<p>用at( )函数来自动检测索引是否越界，也可以像[]一样写入，因为返回的是int&amp;</p>
<p>std::execution::par来实现并行</p>
<p>vector<int> a{4}：长度为1只有一个4的数组</p>
<p>vector<int> a(4)：长度为4的全0数组 ( )才能保证调用它的显式构造函数</p>
<p>在类里的时候，就需要vector<int> a &#x3D; vector<int>(4)不能只写vector<int>(4)</p>
<p>运算符重载打印vector类型：</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230327202559855.png" alt="image-20230327202559855" style="zoom: 67%;" />

<p>clear配合resize</p>
<p>pop_back( )删除数组末尾的数，没有返回值</p>
<p>a.back( )获取最后一个元素</p>
<p>data( )获取首地址指针，等价于&amp;a[0]，下一个元素的地址只需要指针+1即可</p>
<p>p[i]相等于 *(p + i)，因此可以把data( )返回的首地址指针当一个数组来访问</p>
<p>指针没有拷贝构造，拷贝的是个引用</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vector&lt;<span class="type">int</span>&gt; a = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;;</span><br><span class="line"><span class="type">int</span>* p = a.<span class="built_in">data</span>();</span><br><span class="line">cout &lt;&lt; p[<span class="number">0</span>] &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">cout &lt;&lt; p[<span class="number">2</span>] &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br></pre></td></tr></table></figure>

<p>data( )返回的首地址指针配合size( )唯一确定一个动态数组</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vector&lt;<span class="type">int</span>&gt; a = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;;</span><br><span class="line"><span class="type">int</span>* p = a.<span class="built_in">data</span>();</span><br><span class="line"><span class="type">int</span> n = a.<span class="built_in">size</span>();</span><br><span class="line"><span class="built_in">memset</span>(p, <span class="number">-1</span>, <span class="built_in">sizeof</span>(<span class="type">int</span>) * n);  <span class="comment">// memset只认char*</span></span><br></pre></td></tr></table></figure>

<p>弱应用的生命周期必须要比主对象的短，不然会出现空悬指针</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span>* p;</span><br><span class="line">    &#123;</span><br><span class="line">        vector&lt;<span class="type">int</span>&gt; a = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;;</span><br><span class="line">        p = a.<span class="built_in">data</span>();</span><br><span class="line">        cout &lt;&lt; p[<span class="number">0</span>] &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; p[<span class="number">0</span>] &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 延续生命周期</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span>* p;</span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; holder;</span><br><span class="line">    &#123;</span><br><span class="line">        vector&lt;<span class="type">int</span>&gt; a = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;;</span><br><span class="line">        p = a.<span class="built_in">data</span>();</span><br><span class="line">        cout &lt;&lt; p[<span class="number">0</span>] &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">        holder = std::<span class="built_in">move</span>(a);</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; p[<span class="number">0</span>] &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当resize 的目标长度大于原有容量时，就需要重新分配一段更大的连续内存，并把原数组长度的部分移动过去，多出来的部分则用 0 来填充，导致元素的地址有所改变，从而之前 data 返回的指针以及所有的迭代器对象都会失效</p>
<p>push_back也一样，其就相当于resize(+1)并写入这个元素</p>
<p>resize(n)的逻辑是扩容至max(n, capacity * 2)</p>
<p>第三个指针是capacity，需要和size分离</p>
<p>capacity函数查询已经分配的内存大小，也就是实际的最大容量</p>
<p>而size( )返回的其实是已经存储了数据的数组长度</p>
<p>可以发现当resize指定的新长度超过capacity时，就会重新分配一段更大容量的内存来存储数组，只有这时才会移动元素的位置(data指针失效)</p>
<p>size总是&lt;&#x3D;容量，size内都已经过初始化，size到capacity都未经初始化</p>
<p>resize已经初始化到0，reserve只是调用了new，未经初始化</p>
<p>reserve(12)再reserve(0)是没用的，它只能扩容不能减容，所以需要shrink_to_fit，释放多余容量，但会造成一次内存的重新分配，也就是一次移动</p>
<p>shrink_to_fit为什么要分配内存？</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">p = <span class="built_in">malloc</span>(<span class="number">100</span>)</span><br><span class="line"><span class="comment">// free(p + 10) 是不行的 得如下：</span></span><br><span class="line">q = <span class="built_in">malloc</span>(<span class="number">10</span>)</span><br><span class="line"><span class="built_in">memcpy</span>(q, p)</span><br><span class="line"><span class="built_in">free</span>(p)</span><br></pre></td></tr></table></figure>

<p>clear只是大小清零，标记为0，但是capacity还在那里</p>
<p>tools：mallochook 追踪所有的内存分配和释放</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230327211959402.png" alt="image-20230327211959402" style="zoom: 67%;" />

<p>push_back 在容量不足的时候就可以一次性扩容两倍，只需重新分配 logn 次，移动元素 2n-1 次</p>
<p>所以需要配合reserve，暂时固定容量，就不会一次次扩容两倍，避免重新分配内存和移动元素，更高效</p>
<p>迭代器模式：</p>
<p>注意到 vector 和 string 的底层都是连续的稠密数组，他们都有 data() 和 size() 函数，因此可改用首地址指针和数组长度做参数：print(char const *a, size_t n)</p>
<p>这样 print 在无需知道容器具体类型的情况下，只用最简单的接口（首地址指针）就完成了遍历和打印的操作</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230327224625008.png" alt="image-20230327224625008" style="zoom:67%;" />

<p>stride跨步访问</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230327225236436.png" alt="image-20230327225236436" style="zoom: 67%;" />

<p>尾地址指针所指向的地方是无效的内存 a + a.size()，尾地址指针减1才是真正的末尾元素指针 a + a.size() - 1，因为如果用 a + a.size() - 1 也就是 &amp;a.back() 作为尾地址指针，将无法表示数组长度为 0 的情况</p>
<p>首指针、尾指针设置为模板参数：</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230327225419766.png" alt="image-20230327225419766" style="zoom:67%;" />

<p>首指针和尾指针的组合的确能胜任 vector 这种连续数组，但是对于 list 这种不连续的内存的容器就没辙了，list 没有 data() 这个成员函数，因为它根本就不连续</p>
<p>然而 list 却提供了 begin() 和 end() 函数，他们会返回两个 list<char>::iterator 对象，这是一个特殊定义过的类型，其具有 !&#x3D; 和 ++ 以及 * 这些运算符的重载，所以用起来就像普通的指针一样</p>
<p>而这些运算符重载，却会把 ++ 对应到链表的 curr &#x3D; curr-&gt;next 上，用起来就像普通的指针，但内部却通过运算符重载适配不同容器的特殊类，就是迭代器(iterator)，迭代器是 STL 中容器和算法之间的桥梁</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230327230023185.png" alt="image-20230327230023185" style="zoom:67%;" />

<img src="/home/kwx/blog/source/_posts/assets/image-20230327230137709.png" alt="image-20230327230137709" style="zoom: 67%;" />

<p>尽可能使用++p，因为p++后置自增需要先保存旧的迭代器，然后自增自己，再返回就迭代器比较低效</p>
<p>++p 会返回自增后的值 p + 1，这和 p +&#x3D; 1 完全一样，同样因为返回的是一个左值引用所以还可以继续自增比如 ++++p；p++ 会返回自增前的值 p，但是执行完以后 p 却又是 p + 1 了，非常迷惑</p>
<p>迭代器实际上还可以用 [] 运算符访问， b[i] 就和 *(b + i) 等价</p>
<p>迭代器对象和容器本身的主要区别就在于：迭代器不掌握生命周期，从而迭代器的拷贝是平凡的浅拷贝，方便传参；缺点是迭代器是一个对原容器的弱引用，如果原容器解构或发生内存重分配，迭代器就会失效</p>
<p>insert 函数的第一个参数是要插入的位置（用迭代器表示），第二个参数则是要插入的值，这个函数的复杂度是 O(n)，n 是从插入位置 pos 到数组末尾 end 的距离</p>
<p>它会插入位置后方的元素整体向后移动一格，是比较低效的，因此为了高效，我们尽量只往尾部插入元素；如果需要高效的头部插入，可以考虑用 deque 容器，它有高效的 push_front 函数替代</p>
<p>insert 在容量不足时，同样会造成重新分配以求扩容，会移动其中所有元素，这时所有之前保存的迭代器都会失效</p>
<p>a.insert(插入位置, 重复多少次, 插入的值)</p>
<p>花括号类型就是std::initializer_list<int></p>
<p>insert还可以批量插入来自另一个不同类型的容器，例如 list<int>，只要元素类型相等，且符合迭代器规范；可以自由选择对方容器的一个子区间（通过迭代器加减法）内的元素来插入，而不是死板地只能全部插入</p>
<p>template <class It> ，这里 的It 可以是其他容器的迭代器类型</p>
<p>iterator insert(const_iterator pos, It beg, It end)</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230327232326233.png" alt="image-20230327232326233" style="zoom:67%;" />

<p>除了构造函数外，assign 这个成员函数也能在后期把元素覆盖进去，和 insert 不同的是，它会把旧有的数组完全覆盖掉，变成一个新的数组</p>
<p>a.assign(beg, end) 基本和 a &#x3D; vector<int>(beg, end) 等价，唯一的区别是后者会重新分配内存，而前者会保留原来的容量不会释放掉；a.assign(n, val) 基本和 a &#x3D; vector<int>(n, val) 等价，区别同理</p>
<p>explicit显式的，就是需要圆括号</p>
<p>a.assign({x, y, …}) 和 a &#x3D; {x, y, …} 完全等价，都会保留原来的容量，和 a &#x3D; vector<int>{x, y, …} 就不等价，这个会重新分配内存</p>
<p>erase 函数可以删除指定位置的一个元素（通过迭代器指定）</p>
<p>erase 的复杂度最坏情况是删第一个元素 O(n)，删最后一个元素复杂度为 O(1)，因为 erase 会移动 pos 之后的那些元素</p>
<p>a.erase(a.begin() + 1, a.begin() + 3) 删除了 a 的第二和第三个元素，相当于del a[1:3]，注意 C++ 的 insert 和 erase 都是就地操作的</p>
<p>a.erase(a.begin() + n, a.end()) 就和 a.resize(n) 等价，前提是 n 小于 a.size()，返回删除后最后一个元素之后那个位置的迭代器</p>
<h5 id="08-C语言指针"><a href="#08-C语言指针" class="headerlink" title="08.C语言指针"></a>08.C语言指针</h5><p>计算机的位数决定了内存地址的大小，指针的本质就是内存地址，64位系统上的指针就是64位</p>
<p>sizeof(intptr_t) &#x3D; sizeof(void*) &#x3D; sizeof(uintptr_t)</p>
<p>主流操作系统上，size_t &lt;&#x3D;&#x3D;&gt; uintptr_t</p>
<p>原码、反码、补码：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/118432554">https://zhuanlan.zhihu.com/p/118432554</a></p>
<p>指数位(e)是 +127 以后表示的</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230328210013994.png" alt="image-20230328210013994" style="zoom:67%;" />

<p>大端字节序：big-endian<img src="/home/kwx/blog/source/_posts/assets/image-20230328210926860.png" alt="image-20230328210926860" style="zoom:50%;" /></p>
<p>小端：little  x86 arm</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230328211002531.png" alt="image-20230328211002531" style="zoom: 50%;" />

<p>可以通过 &amp; 运算符获取一个变量的指针（地址）</p>
<p>可以通过 * 运算符访问指针指向的变量（左值）</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230328211319834.png" alt="image-20230328211319834" style="zoom: 50%;" />

<p>可见，指针无非是一个 64 位整数，这个整数表示的是指针所指向变量在内存中的起始地址（第一个字节所在的门牌号），甚至可以把 int* 强制转换成 unsigned long 类型，来打印出这个门牌号的整数值</p>
<p>nullptr 的类型是 std::nullptr_t，它可以隐式转换为任意类型的指针</p>
<p>a[2] 就是 *(a + 2) 的简写而已</p>
<p>指针加法的特殊性：加 n 实际上是加了 n*sizeof(T)</p>
<p>使用 size_t 表示数组长度</p>
<p>malloc只分配字节，使用 malloc(n * 4) 来分配 int 数组，T *a &#x3D; (T*)malloc(n * sizeof(T))</p>
<p>C 语言特性：函数声明为 T [] 类型的参数，实际上是 T * 类型</p>
<p>如果函数参数类型形如func(int arr[])，func(int arr[6])，那么其实就等价于：func(int* arr)</p>
<p>也就是说，给函数参数传入一个数组，实际上等同于传入它的首地址指针，本质上属于按引用传递</p>
<p>字符常量其实就是对应的 ASCII 码，ASCII 字符对照表就是把字符对应到 0~127 的整数，方便用计算机存储</p>
<img src="/home/kwx/blog/source/_posts/assets/image-20230328223626237.png" alt="image-20230328223626237" style="zoom:50%;" />

<h4 id="3-线程池"><a href="#3-线程池" class="headerlink" title="3.线程池"></a>3.线程池</h4><p>简易线程池：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/356904887">https://zhuanlan.zhihu.com/p/356904887</a></p>
<p>for(;;) vs while(1)：<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_44395686/article/details/103409425">https://blog.csdn.net/weixin_44395686/article/details/103409425</a></p>
<p>notify_one&#x2F;all：<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43743711/article/details/115803461">https://blog.csdn.net/weixin_43743711/article/details/115803461</a></p>
<p>lock：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/91062516">https://zhuanlan.zhihu.com/p/91062516</a></p>
<p>Event Pool：<a target="_blank" rel="noopener" href="https://github.com/chloro-pn/event_pool">https://github.com/chloro-pn/event_pool</a></p>
<p>Hipe：<a target="_blank" rel="noopener" href="https://github.com/CodingHanYa/Hipe">https://github.com/CodingHanYa/Hipe</a></p>
<h4 id="4-编译-链接"><a href="#4-编译-链接" class="headerlink" title="4.编译 &amp; 链接"></a>4.编译 &amp; 链接</h4><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/595527528">https://zhuanlan.zhihu.com/p/595527528</a></p>
<p>VMA是进程地址空间中的一个连续虚拟内存区域，可以是代码、数据、堆或栈等。LMA代表加载内存地址，是可执行文件中一个段（section）在可执行文件被加载到内存时的实际内存地址。</p>
<p>在可执行文件被加载到内存时，操作系统将可执行文件中的各个段映射到进程的虚拟地址空间中的相应VMA中。因此，VMA和LMA之间的差异可以帮助操作系统在不同的进程之间共享相同的代码和数据，从而实现更有效的内存管理。</p>
<p>重定向是指，编译器将源代码编译成目标文件后，链接器将目标文件中的符号（如函数、变量等）与其他目标文件或库文件中的符号进行匹配，并将这些符号的引用地址重定向到它们在可执行文件或共享库中的实际地址上。</p>
<p>重定向是必要的，因为编译时源代码中的符号引用地址是未知的，需要在链接时才能确定。另外，不同的目标文件和库文件可能定义了相同名称的符号，因此需要链接器进行符号解析和匹配。</p>
<p>重定向涉及到的操作包括符号表的合并、重定向表的生成、符号地址的计算和填充等，这些都是链接器的核心功能。通过重定向，链接器可以将多个目标文件和库文件链接成一个可执行文件或共享库，从而实现代码的重用和共享。</p>
<p>偏移量是指目标文件中的代码和数据相对于该文件的起始位置的偏移量。当目标文件被加载到内存中时，操作系统需要使用该偏移量将目标文件中的符号地址映射到实际的内存地址。</p>
<p>偏移量通常在目标文件中被编码为一个相对于起始位置的固定偏移量或一个基地址，也可以是一个相对于其他符号地址的相对偏移量。在链接时，链接器会计算和记录每个符号的偏移量，然后生成重定向表，以便在目标文件被加载到内存中时能够正确地将符号地址转换为实际的内存地址。</p>
<p>符号表它用于记录程序中所有的函数、变量和其他标识符的信息，包括它们的名称、类型、大小、位置等等。</p>
<p>在编译过程中，编译器会将每个源文件中定义的符号都加入到该源文件的符号表中。在链接过程中，链接器会将所有源文件中的符号表合并成一个全局符号表，并根据符号的类型和作用域进行分类和排列。</p>
<p>符号表的主要作用是为了实现程序的符号解析。在程序执行时，当一个函数或变量被引用时，程序需要通过符号表来查找该符号的定义和位置，从而正确地完成符号的引用和调用。符号表还可以用于程序的优化和调试，例如在调试信息中，符号表可以用来标记源代码的行号、函数名等信息，方便调试器进行源代码级别的调试。</p>
<p>在符号表中，每个符号都有一个唯一的名称，通常是由源代码中的标识符经过一定规则转换而来的。同时，每个符号还有一个类型，例如函数、变量、常量，以及一个作用域，例如局部 or 全局作用域等。</p>
<p>在链接过程中，符号表也被用于实现符号的重定向和解析。当程序引用一个外部定义的符号时，链接器需要在符号表中查找该符号的定义和位置，并将引用指向正确的地址。同时，如果符号在多个源文件中被定义或引用，链接器还需要对符号进行重定向和解析，以保证符号在程序中的唯一性和正确性。</p>
<p>text段是指存储程序的指令代码的段落，通常是只读的，不能被修改。当可执行文件或共享库被加载到内存中时，操作系统将text段映射到进程的代码段中，程序的执行流程就是从该段的代码开始执行。因此，text段是程序的核心部分，包含程序的主要逻辑和算法。</p>
<p>data段是指存储程序的全局变量、静态变量和常量的段落，通常是可读写的。当可执行文件或共享库被加载到内存中时，操作系统将data段映射到进程的数据段中，程序可以读取和修改该段的变量和常量。因此，data段是程序的重要数据存储区域，包含程序的状态和运行时数据。</p>
<p>bss段（Block Started by Symbol）是一个特殊的数据段，用于存储程序中未初始化的全局变量和静态变量。在可执行文件或共享库被加载到内存中时，bss段中的数据会被初始化为0或空值。因为bss段的数据都是0或空值，所以在目标文件中并不需要为它们分配实际的存储空间，只需要记录它们的大小即可。</p>
<p>rodata段（Read-Only Data）是一个只读数据段，用于存储程序中的常量、字符串等只读数据。在可执行文件或共享库被加载到内存中时，rodata段会被映射到进程的只读数据段中，程序可以读取但不能修改其中的数据。因为rodata段的数据是只读的，所以在目标文件中也不需要为它们分配实际的存储空间，只需要记录它们的大小和内容即可。</p>
<p>debug段是用于存储调试信息的段落，包括源代码、符号表、调用栈信息等。在目标文件中，debug段的内容通常是以特定的调试格式进行存储，链接器可以根据这些格式将调试信息提取出来，并将它们与目标文件或共享库进行关联。在实际的调试过程中，调试器可以使用这些调试信息来进行源代码级别的调试、查看变量的值等操作。</p>
<p>plt段和got段：plt段（Procedure Linkage Table）和got段（Global Offset Table）是在使用共享库时才会涉及到的两个段落。plt段用于存储动态链接库中导出函数的入口地址，在可执行文件或共享库被加载到内存中时，操作系统会根据需要动态加载并解析plt段中的函数地址。got段用于存储可执行文件或共享库中对动态链接库中导入函数的引用地址，在程序运行时，操作系统会根据需要将got段中的引用地址重定向到动态链接库中对应函数的实际地址上。</p>
<h4 id="5-CUDA"><a href="#5-CUDA" class="headerlink" title="5.CUDA"></a>5.CUDA</h4><p>ncu参数: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/666242337">https://zhuanlan.zhihu.com/p/666242337</a></p>
<p>google test: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/664667816">https://zhuanlan.zhihu.com/p/664667816</a></p>
<p>算术强度: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/664670489">https://zhuanlan.zhihu.com/p/664670489</a></p>
<p>CUDA 计算 内存 调度 模型: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/664662628">https://zhuanlan.zhihu.com/p/664662628</a></p>
<p>加速数据传输: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/188246455">https://zhuanlan.zhihu.com/p/188246455</a></p>
<p>GPU学习路线: <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/617724036/answer/3180044878">https://www.zhihu.com/question/617724036/answer/3180044878</a></p>
<p>Code：<a target="_blank" rel="noopener" href="https://github.com/godweiyang/NN-CUDA-Example">https://github.com/godweiyang/NN-CUDA-Example</a></p>
<p>CUDA算子教程及运行时间分析：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/358220419">https://zhuanlan.zhihu.com/p/358220419</a></p>
<p>自定义CUDA算子的三种方式：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/358778742">https://zhuanlan.zhihu.com/p/358778742</a></p>
<p>自定义反向传播：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/359524837">https://zhuanlan.zhihu.com/p/359524837</a></p>
<p>简化版：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/545221832">https://zhuanlan.zhihu.com/p/545221832</a></p>
<p>.h：声明启动； .cu：实现启动，启动内含具体func 传的是数组</p>
<p>.cpp：pytorch tensor转化为数组（调用启动函数） + pybind </p>
<p>.py：调用</p>
<p>自定义autograd：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/544383900">https://zhuanlan.zhihu.com/p/544383900</a></p>
<p>显存：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/462191421">https://zhuanlan.zhihu.com/p/462191421</a></p>
<p>常用技巧：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/584501634">https://zhuanlan.zhihu.com/p/584501634</a></p>
<p>CPU&#x2F;GPU矩阵乘运算：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/573271688">https://zhuanlan.zhihu.com/p/573271688</a> 二维矩阵共享内存值得细看</p>
<p>Cx是所有线程的分组个数，Cy是分组后多余的线程数，while是为了提供跳出条件</p>
<p>主要是线程数可以不等于矩阵元素个数，因此做映射时会有多出来的</p>
<p>共享内存这块：所以每次运算将A矩阵的i行放入到共享内存中，保证第i行数据不会反复从Global中加载，从而提升运算速度，while是用来保证thread的数量与矩阵A的宽度不相等时，数据多算或少算</p>
<p>cudaError_t cudaMalloc(void** devPtr, size_t size)  </p>
<p>第一个参数传递的是存储在cpu内存中的指针变量的地址，cudaMalloc在执行完成后，向这个地址中写入了一个地址值（此地址值是GPU显存里的）。</p>
<p>cudaMalloc原型理解：<a target="_blank" rel="noopener" href="https://blog.csdn.net/bendanban/article/details/8151335">https://blog.csdn.net/bendanban/article/details/8151335</a></p>
<p>CUDA编程笔记1：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/462589739">https://zhuanlan.zhihu.com/p/462589739</a></p>
<p><strong>一个典型的CUDA程序实现流程：</strong></p>
<ol>
<li>把数据从CPU内存拷贝到GPU内存。</li>
<li>调用核函数对存储在GPU内存中的数据进行操作。</li>
<li>将数据从GPU内存传送回到CPU内存。</li>
</ol>
<p><strong>cudaMemcpy负责主机和设备之间的数据传输</strong></p>
<p><code>cudaMemcpy</code>是<strong>同步执行</strong>的，也就是CPU会等待copy，直到完成后再继续执行。 <strong>这里的同步是隐性的！</strong>并且<strong>内存拷贝将会占据大量时间</strong>，往往耗时的不是计算，而是内存拷贝</p>
<p>CPU的缓存是不可以编程直接控制的，<strong>但GPU的共享内存是可以编程直接控制</strong></p>
<p><strong>一个进程对应的多个线程</strong>。GPU进程往往由CPU创建，也就是说每个GPU进程都对应着一个CPU进程。<strong>代表就是核函数kernel，调用kernel也就是创建了一个GPU进程</strong></p>
<p><code>threadIdx</code>作用：<strong>使用线程索引建立数组索引</strong></p>
<p>代码中<strong>总共有32个线程同时并行执行，每一个线程取得数组中的一对元素进行相加</strong></p>
<p>CUDA编程笔记2：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/462944262">https://zhuanlan.zhihu.com/p/462944262</a></p>
<p>在软件层面上：</p>
<ul>
<li><p><strong>一个GPU进程或者说核函数kernel</strong>对应着<strong>一个线程网格Grid；</strong></p>
</li>
<li><p><strong>一个线程网格Grid</strong>可以被组织成<strong>多个线程块Block；</strong></p>
</li>
<li><p><strong>一个线程块Block</strong>可以被组织成<strong>多个线程thread</strong>。</p>
</li>
<li><p>一般Block中的thread数量要为wrapsize的整数倍</p>
</li>
<li><p>一般Grid中的Block数量要为GPU的SM数量的整数倍</p>
</li>
<li><p>一般在一定范围内Block的数量越多并行越多（但太多也会适得其反）</p>
</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/time.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">double</span> <span class="title">cpuSecond</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">timeval</span> tp;</span><br><span class="line">  <span class="built_in">gettimeofday</span>(&amp;tp,<span class="literal">NULL</span>);</span><br><span class="line">  <span class="keyword">return</span>((<span class="type">double</span>)tp.tv_sec+(<span class="type">double</span>)tp.tv_usec*<span class="number">1e-6</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>CUDA编程笔记3：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/462991566">https://zhuanlan.zhihu.com/p/462991566</a></p>
<p>GPU是一大堆<strong>SM（流式多处理器）</strong>组成的<strong>阵列</strong>，还包括DRAM组成的全局机载内存，Giga Thread引擎（一个全局调度器，用来分配线程块到SM上）</p>
<p>一个线程块只能分配到一个SM上，<strong>尽可能地把线程块均分到SM上</strong></p>
<p><strong>线程网格中的线程块数量应该要为显卡的SM数量的整数倍</strong></p>
<p>SM是GPU的核心，一个SM包括</p>
<ul>
<li>32个CUDA核心<strong>（SP，GPU真正的运算器）</strong></li>
<li>16个LD&#x2F;ST单元（load&#x2F;store）用来计算源地址和目的地址</li>
<li>4个SFU（Special function units）特殊计算单元，比如用来执行sin、cos等</li>
<li>两个线程束调度器（warp scheduler），每个线程调度器负责16个CUDA核心</li>
<li>一级缓存</li>
<li>共享内存</li>
</ul>
<p>每个SP包括一个浮点数计算单元和整数计算单元，在这里每个时钟周期执行一个整数或是浮点数指令</p>
<p>线程块中的线程数量是不确定的，所以不能直接以线程块为处理单位，于是引入了线程束概念：每32个（warpsize&#x3D;32）线程为一组，被称为线程束warp，<strong>有多少个线程束调度器就能同时执行多少个线程束</strong></p>
<p>线程束是<strong>并行处理的基本单元</strong>，线程束中的<strong>所有线程同时执行相同的指令！</strong></p>
<p>线程束的执行方式被称为<strong>单指令多线程</strong></p>
<ul>
<li>每个线程都有自己的指令地址计数器</li>
<li>每个线程都有自己的寄存器状态</li>
<li>每个线程可以有一个独立的执行路径（单指令多数据，那么全部执行，那么全部不执行，不支持if语句。而单指令多线程可以部分执行）</li>
</ul>
<p>一个线程块有80个线程，那么它会分为4个线程束，共计3*32&#x3D;96。<strong>多出来的16个线程不活跃的，但记住即使这些线程未被使用， 它们仍然消耗SM的资源</strong>， 如寄存器</p>
<p>由于线程束是<strong>单指令多线程</strong>的执行，所以不支持16个线程执行if语句块，另外16个线程执行else语句块。那么当发生线程束分化时，线程束中16个线程执行if，冻结另外16个线程；然后，16个线程执行else，冻结另外16个线程。if语句变成了两步走，线程束分化会导致性能明显地下降</p>
<p><strong>GPU不适合做逻辑复杂的控制密集型任务</strong>，像if、for、while语句</p>
<p>为什么需要Block：</p>
<p>通信：shared memory是块内thread通信的基本方式</p>
<p>同步：<strong>同一个线程块中每个线程都必须等待直至该线程块中所有其他线程都已经达到这个同步点</strong>。 而Block之间，除结束核函数外是无法同步的</p>
<p>可扩展性：<strong>CUDA在不同SM数量的GPU上都可以运行</strong></p>
<p>CUDA编程笔记4：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/463052196">https://zhuanlan.zhihu.com/p/463052196</a></p>
<ul>
<li>寄存器和本地内存为<strong>每一个线程私有</strong>，生命周期与线程一致，随线程释放而释放</li>
</ul>
<p>​       寄存器放不下，会放本地内存，以及编译期无法确定值的数组与占用较多内存的变量</p>
<ul>
<li>共享内存为每一个<strong>线程块</strong>中的<strong>所有线程共享</strong>，相当于L1 cache，但是L1 cache不可编程</li>
</ul>
<p>​       常用于块内线程通信，同一个block中的thread通过共享内存来通信</p>
<ul>
<li>全局内存、常量内存、纹理内存被<strong>GPU设备上的所有线程共享</strong></li>
</ul>
<p>​        每一个SM中都配备着专用的常量内存，只可读不可写；</p>
<p>​        …纹理内存是针对2D空间局部性的优化策略</p>
<p>​        cudaMalloc分配的就是全局内存，<code>__device__</code>修饰全局变量</p>
<p>​        cache缓存不可编程，由硬件自动实现缓存机制。</p>
<p>GPU的缓存分为以下几种：</p>
<ul>
<li>L1 cache（per-SM）</li>
<li>L2 cache（per-device）</li>
<li>只读的constant cache（per-SM）</li>
<li>只读的texture cache（per-SM）</li>
</ul>
<p>每个SM都配置着L1 cache，所有SM共享一个L2 cache。二者都是用来缓存local和global memory的。</p>
<p>CPU memory的load&#x2F;store都可以被cache。但GPU上，只有load操作会被cache，store则不会。</p>
<p>每个SM都配备一个只读constant cache和texture cache来提升性能。</p>
<p>​        </p>
<p>手把手教学：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/595851188">https://zhuanlan.zhihu.com/p/595851188</a></p>
<p>cu里写启动函数(启动里完成计算)，以及sum的实现；</p>
<p>cpp写四部分：一个是必要的check宏定义，一个是启动函数的声明，一个是与python的接口（传入pytorch的Tensor做启动），一个是pybind11</p>
<p>Code：<a target="_blank" rel="noopener" href="https://github.com/Yuppie898988/CudaDemo">https://github.com/Yuppie898988/CudaDemo</a></p>
<p>入门极简教程： <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/34587739">https://zhuanlan.zhihu.com/p/34587739</a></p>
<p>kernel是在device上线程中并行执行的函数</p>
<p>函数执行环境标识符：</p>
<p><code>__global__</code>修饰核函数，GPU上执行，CPU端调用，返回值必须是void，并且需要在调用时指定block数&amp;线程数。异步，代表函数没执行完就返回了控制权，所以测量核函数的时间需要同步操作才能获得准确的结果。</p>
<p><code>__device__</code>GPU端调用，GPU端执行，编译器内被编译为内联函数</p>
<p><code>__host__</code>主机端执行主机端调用，也就是常规的C&#x2F;C++函数</p>
<p>只有device与host能同时使用，会同时为主机端和设备端编译，使用__CUDA_ARCH__这个宏来区分</p>
<p><code>__restrict__</code>修饰符用于限定和约束指针，表明指针是访问一个数据对象的唯一且初始的方式，即告诉编译器，所有修改该指针所指向内存中内容的操作都必须通过该指针来修改，而不能通过其它途径（其它变量或指针）来修改。</p>
<p>Python &amp; CUDA &amp; C++ 混合编程：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/460991440">https://zhuanlan.zhihu.com/p/460991440</a></p>
<p>配套Code：<a target="_blank" rel="noopener" href="https://github.com/HsLOL/ExtensionOPs/tree/master/demo">https://github.com/HsLOL/ExtensionOPs/tree/master/demo</a></p>
<p>ncrelu cpp：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/350651297">https://zhuanlan.zhihu.com/p/350651297</a></p>
<p>ncrelu cuda：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/350849116">https://zhuanlan.zhihu.com/p/350849116</a>  没看懂启动函数</p>
<p>lambda：<a target="_blank" rel="noopener" href="https://blog.csdn.net/asdasdde/article/details/116268964">https://blog.csdn.net/asdasdde/article/details/116268964</a></p>
<p>mixconv：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/352451047">https://zhuanlan.zhihu.com/p/352451047</a> 没能看懂</p>
<p>Block &amp; Grid：</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/tiao_god/article/details/107181883">https://blog.csdn.net/tiao_god/article/details/107181883</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_43715171/article/details/121794135">https://blog.csdn.net/qq_43715171/article/details/121794135</a></p>
<p>图示，很清晰： <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/544864997">https://zhuanlan.zhihu.com/p/544864997</a></p>
<p>测试是否能跟上：<a target="_blank" rel="noopener" href="https://juejin.cn/post/7047666754515894286">https://juejin.cn/post/7047666754515894286</a></p>
<p><img src="/home/kwx/blog/source/_posts/assets/20180318132631477.png" alt="20180318132631477"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/04/05/Pytorch%20&%20Python/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/04/05/Pytorch%20&%20Python/" class="post-title-link" itemprop="url">Pytorch & Python</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-04-05 12:38:26" itemprop="dateCreated datePublished" datetime="2023-04-05T12:38:26+08:00">2023-04-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-02-01 23:32:58" itemprop="dateModified" datetime="2024-02-01T23:32:58+08:00">2024-02-01</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>[2022](# 2022)</p>
<p> – [1.Pytorch](# 1.Pytorch)</p>
<p> – [2.流畅的Python](# 2.流畅的python)</p>
<p> – [3.Python](# 3.Python)</p>
<p>[2023](# 2023)</p>
<p> – [1.Profiler](# 1.Profiler)</p>
<p> – <a href="#2.Pytorch">2.Pytorch</a></p>
<p> – [3.Python](# 3.Python)</p>
<p> – [4.Python扩展](# 4.Python扩展)</p>
<p>[2024](# 2024)</p>
<p> – <a href="#1.Pytorch">1.Pytorch</a></p>
<h2 id="2022"><a href="#2022" class="headerlink" title="2022"></a>2022</h2><h4 id="1-Pytorch"><a href="#1-Pytorch" class="headerlink" title="1.Pytorch"></a>1.Pytorch</h4><p>EMA： <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/479898259">https://zhuanlan.zhihu.com/p/479898259</a></p>
<p>torch.fx.wrap：<a target="_blank" rel="noopener" href="https://vimsky.com/examples/usage/python-torch.fx.wrap-pt.html">https://vimsky.com/examples/usage/python-torch.fx.wrap-pt.html</a></p>
<p>torch.finfo: <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_43844342/article/details/116209999">https://blog.csdn.net/qq_43844342/article/details/116209999</a></p>
<p>DW: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/92134485">https://zhuanlan.zhihu.com/p/92134485</a></p>
<p>Deformable conv: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/335147713">https://zhuanlan.zhihu.com/p/335147713</a> 在感受野中引入了可学习的偏移量</p>
<p>Broadcast: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/86997775">https://zhuanlan.zhihu.com/p/86997775</a></p>
<p>Index_select: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/329104226">https://zhuanlan.zhihu.com/p/329104226</a></p>
<p>bilinear中align&#x3D;True&#x2F;False: <a target="_blank" rel="noopener" href="https://blog.csdn.net/shwan_ma/article/details/108830991">https://blog.csdn.net/shwan_ma/article/details/108830991</a></p>
<p>reduction 3模式：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_33559972/article/details/104708008">https://blog.csdn.net/qq_33559972/article/details/104708008</a></p>
<p>premute：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/76583143">https://zhuanlan.zhihu.com/p/76583143</a></p>
<p>group卷积：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/113928413">https://zhuanlan.zhihu.com/p/113928413</a></p>
<p>张量乘法：<a target="_blank" rel="noopener" href="https://blog.csdn.net/hottie_xiaomiao/article/details/124262405">https://blog.csdn.net/hottie_xiaomiao/article/details/124262405</a></p>
<p>替换模型任意层：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/356273702">https://zhuanlan.zhihu.com/p/356273702</a></p>
<p>scatter：<a target="_blank" rel="noopener" href="https://blog.csdn.net/u010630669/article/details/105425572/">https://blog.csdn.net/u010630669/article/details/105425572/</a>  第一个1意味着每行有1个</p>
<p>DDP：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/393648544">https://zhuanlan.zhihu.com/p/393648544</a>     </p>
<p>​            <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/453798093">https://zhuanlan.zhihu.com/p/453798093</a></p>
<p>hook：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/152314451">https://zhuanlan.zhihu.com/p/152314451</a></p>
<p>np.percentage：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/159158966">https://zhuanlan.zhihu.com/p/159158966</a></p>
<p>np.count_nonzero： <a target="_blank" rel="noopener" href="https://www.cjavapy.com/article/1081/">https://www.cjavapy.com/article/1081/</a></p>
<p>np.where：<a target="_blank" rel="noopener" href="https://blog.csdn.net/island1995/article/details/90200151">https://blog.csdn.net/island1995/article/details/90200151</a></p>
<p>断点续训+cudnn：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/133250753">https://zhuanlan.zhihu.com/p/133250753</a></p>
<p>flops：<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/65305385/answer/1699436281">https://www.zhihu.com/question/65305385/answer/1699436281</a></p>
<p>print对齐：<a target="_blank" rel="noopener" href="https://www.geeksforgeeks.org/string-alignment-in-python-f-string/">https://www.geeksforgeeks.org/string-alignment-in-python-f-string/</a></p>
<p>cudnn.benchmark：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/73711222">https://zhuanlan.zhihu.com/p/73711222</a></p>
<p>gather： <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/110289027">https://zhuanlan.zhihu.com/p/110289027</a></p>
<p>np.take_long_axis &#x3D; torch.gather</p>
<p>np.argpartition, np.partition：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/546886845">https://zhuanlan.zhihu.com/p/546886845</a></p>
<p>np.min vs torch.min：<a target="_blank" rel="noopener" href="https://blog.csdn.net/sinat_37145472/article/details/94753866">https://blog.csdn.net/sinat_37145472/article/details/94753866</a></p>
<p>np.transpose：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_42362891/article/details/110203398">https://blog.csdn.net/qq_42362891/article/details/110203398</a></p>
<p>np -&gt; torch.topk：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/374269641">https://zhuanlan.zhihu.com/p/374269641</a></p>
<p>numba加速：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/454057229">https://zhuanlan.zhihu.com/p/454057229</a></p>
<p>apply：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qiumokucao/article/details/121356553">https://blog.csdn.net/qiumokucao/article/details/121356553</a></p>
<h4 id="2-流畅的python"><a href="#2-流畅的python" class="headerlink" title="2.流畅的python"></a>2.流畅的python</h4><p>3.setdefault为key（可能missing）配置默认值</p>
<p>   在__getitem__(也就是[]操作)碰到找不到的键，调用__missing__</p>
<p>   不可变映射类型：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> <span class="built_in">type</span> <span class="keyword">import</span> MappingProxyType </span><br><span class="line">d = &#123;<span class="string">&#x27;1&#x27;</span>: <span class="string">&#x27;A&#x27;</span>&#125;</span><br><span class="line">e = MappingProxyType(d) <span class="comment"># 获取字典的只读实例</span></span><br></pre></td></tr></table></figure>

<p> 字典的key必须是可散列的：</p>
<p>（1）支持hash()函数，并且通过__hash__方法得到的散列值是不变的</p>
<p>（2）支持通过__eq__方法检测相等性</p>
<p>（3）若 a &#x3D;&#x3D; b 为真，则 hash(a) =&#x3D; hash(b) 也为真</p>
<p>4.__doc__：生成对象的帮助文本(‘’’注释’’’)</p>
<p>5.闭包：调用averager时，make_averager已经返回了，series的本地作用域也随之一去不复返了</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">make_averager</span>():</span><br><span class="line">	series = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">averager</span>(<span class="params">new_value</span>):</span><br><span class="line">		series.append(new_value)</span><br><span class="line">        total = <span class="built_in">sum</span>(series)</span><br><span class="line">        <span class="keyword">return</span> total / <span class="built_in">len</span>(series)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> averager</span><br></pre></td></tr></table></figure>

<p>series是自由变量，指未在本地作用域中绑定的变量</p>
<p>python在__code__属性中（表示编译后的函数定义体）保存局部变量和自有变量的名称</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">avg = make_averager()</span><br><span class="line">avg.__code__.co_varnames</span><br><span class="line">avg.__code__.co_freevars</span><br></pre></td></tr></table></figure>

<p>nonlocal声明</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">make_averager</span>():</span><br><span class="line">	count = <span class="number">0</span></span><br><span class="line">	total = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">averager</span>(<span class="params">new_value</span>):</span><br><span class="line">        <span class="comment"># nonlocal count, total</span></span><br><span class="line">		count += <span class="number">1</span></span><br><span class="line">		total += new_value</span><br><span class="line">        <span class="keyword">return</span> total / count</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> averager</span><br><span class="line"></span><br><span class="line">a = make_averager()(<span class="number">10</span>)  <span class="comment"># local variable error</span></span><br></pre></td></tr></table></figure>

<p>averager里给 count 赋值了，会将其变为局部变量</p>
<p>series不会报错是因为利用了列表是可变对象的事实，没有给它赋值而是调用了append方法</p>
<p>但是对数字、字符串、元组等不可变类型来说，只能读取不能更新</p>
<p>nonlocal就是把变量标记为自由变量，为nonlocal声明的变量赋予新值，闭包中保存的绑定也会更新</p>
<p>6.装饰器在被装饰的函数定义之后立即运行（通常是在导入时，即加载python模块时）</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">clock</span>(<span class="params">func</span>):</span><br><span class="line"><span class="meta">    @functools.wraps(<span class="params">func</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">clocked</span>(<span class="params">*args, **kwargs</span>):</span><br><span class="line">        t0 = time.time()</span><br><span class="line">        result = func(*args)</span><br><span class="line">        elapsed = time.time() - t0</span><br><span class="line">        name = func.__name__</span><br><span class="line">        arg_lst = []</span><br><span class="line">        <span class="keyword">if</span> args:</span><br><span class="line">            arg_lst.append(<span class="string">&#x27;,&#x27;</span>.join(<span class="built_in">repr</span>(args) <span class="keyword">for</span> arg <span class="keyword">in</span> args))</span><br><span class="line">        <span class="keyword">if</span> kwargs:</span><br><span class="line">            pairs = <span class="string">f&#x27;<span class="subst">&#123;k&#125;</span> = <span class="subst">&#123;w&#125;</span>&#x27;</span> <span class="keyword">for</span> k, w <span class="keyword">in</span> <span class="built_in">sorted</span>(kwargs.items())</span><br><span class="line">            arg_lst.append(<span class="string">&#x27;,&#x27;</span>.join(pairs))</span><br><span class="line">        arg_str = <span class="string">&#x27;,&#x27;</span>.join(arg_lst)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;elapsed&#125;</span>---<span class="subst">&#123;name&#125;</span>---<span class="subst">&#123;arg_str&#125;</span>---<span class="subst">&#123;result&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    <span class="keyword">return</span> clocked</span><br></pre></td></tr></table></figure>

<p>@functools.lru_cache() ：使用缓存实现，更快</p>
<p>参数化注册装饰器：</p>
<p>嵌套函数的外层作为装饰器工厂，接收额外参数</p>
<p>装饰器的参数一定是函数，返回值也一定是该函数，不然不满足 $dec(f()) &#x3D; f()$</p>
<p>7.tuple、list、set、dict等保存的都是对象的引用，如果引用的元素可变，即便tuple不可变，tuple内的元素依然可变</p>
<p>构造方法 or [:]做的是浅拷贝</p>
<p>仅当删除的变量保存的是对象的最后一个引用或是无法得到对象时，del命令会让对象被当做垃圾回收</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> weakref</span><br><span class="line">s1 = [<span class="number">1</span>]</span><br><span class="line">s2 = s1</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bye</span>():</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&#x27;!&#x27;</span>)</span><br><span class="line">ender = weakref.finalize(s1, bye)</span><br><span class="line"><span class="built_in">print</span>(ender.alive) <span class="comment"># T</span></span><br><span class="line"><span class="keyword">del</span> s1</span><br><span class="line"><span class="built_in">print</span>(ender.alive) <span class="comment"># T</span></span><br><span class="line">s2 = <span class="string">&#x27;spam&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(ender.alive) <span class="comment"># F</span></span><br></pre></td></tr></table></figure>

<p>当需要引用对象而不让对象的存在时间超过所需时间（常用于缓存）</p>
<p>classmethod：定义<strong>操作类，而非操作实例</strong>的方法，最常用于定义备选构造方法。因此类方法的第一个参数是类本身而非实例</p>
<p>鸭子类型 &amp; 猴子补丁：<a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1484390">https://cloud.tencent.com/developer/article/1484390</a></p>
<h4 id="3-Python"><a href="#3-Python" class="headerlink" title="3.Python"></a>3.Python</h4><p>递归导入模块 importlib：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/565665251">https://zhuanlan.zhihu.com/p/565665251</a></p>
<p>Python颜色：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37844142/article/details/108282190">https://blog.csdn.net/qq_37844142/article/details/108282190</a></p>
<p>Python魔法函数：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/344951719">https://zhuanlan.zhihu.com/p/344951719</a></p>
<p>copy &amp; deepcopy：<a target="_blank" rel="noopener" href="https://blog.csdn.net/sodalife/article/details/89461030">https://blog.csdn.net/sodalife/article/details/89461030</a></p>
<p>pickle：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/152527979">https://zhuanlan.zhihu.com/p/152527979</a></p>
<p>logging详解：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/487524917">https://zhuanlan.zhihu.com/p/487524917</a></p>
<p>typehints：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/519335398">https://zhuanlan.zhihu.com/p/519335398</a></p>
<p>@staticmethod：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/389770470">https://zhuanlan.zhihu.com/p/389770470</a></p>
<p>@property：<a target="_blank" rel="noopener" href="http://c.biancheng.net/view/4561.html">http://c.biancheng.net/view/4561.html</a></p>
<p>数据分析：</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_35757704/article/details/89280715">https://blog.csdn.net/weixin_35757704/article/details/89280715</a></p>
<p><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000015926584">https://segmentfault.com/a/1190000015926584</a></p>
<p>matplotlib使用：</p>
<p>clf：<a target="_blank" rel="noopener" href="https://blog.csdn.net/tz_zs/article/details/81393098">https://blog.csdn.net/tz_zs/article/details/81393098</a></p>
<p>画Rect：<a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/37435369/matplotlib-how-to-draw-a-rectangle-on-image">https://stackoverflow.com/questions/37435369/matplotlib-how-to-draw-a-rectangle-on-image</a></p>
<p>image[::-1]：<a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/56916638/invert-the-y-axis-of-an-image-without-flipping-the-image-upside-down">https://stackoverflow.com/questions/56916638/invert-the-y-axis-of-an-image-without-flipping-the-image-upside-down</a></p>
<p>画点：<a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/55545400/how-to-draw-a-point-in-an-image-using-given-coordinate">https://stackoverflow.com/questions/55545400/how-to-draw-a-point-in-an-image-using-given-coordinate</a></p>
<h2 id="2023"><a href="#2023" class="headerlink" title="2023"></a>2023</h2><h4 id="1-Profiler"><a href="#1-Profiler" class="headerlink" title="1.Profiler"></a>1.Profiler</h4><p>闭包计时器:</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> functools</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">recorder</span>(<span class="params">a, b, n</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">outer</span>(<span class="params">func</span>):</span><br><span class="line"><span class="meta">        @functools.wraps(<span class="params">func</span>)</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">record</span>(<span class="params">*args, **kwargs</span>):</span><br><span class="line">            a.record()</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                result = func(*args, **kwargs)</span><br><span class="line">            <span class="comment"># torch.cuda.synchronize()</span></span><br><span class="line">            b.record()</span><br><span class="line">            torch.cuda.synchronize()</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;func.__qualname__&#125;</span>&quot;</span>.replace(<span class="string">&quot;.forward&quot;</span>, <span class="string">&quot;&quot;</span>) + <span class="string">f&quot;average cost: <span class="subst">&#123;(a.elapsed_time(b) / n):<span class="number">.6</span>f&#125;</span> s&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> result</span><br><span class="line">        <span class="keyword">return</span> record</span><br><span class="line">    <span class="keyword">return</span> outer</span><br></pre></td></tr></table></figure>

<p>Profiler with Tensorboard的使用：</p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1oT4y1h73e/?spm_id_from=333.999.0.0&vd_source=8683b4f3e93da577cf9216975b225ee5">https://www.bilibili.com/video/BV1oT4y1h73e/?spm_id_from=333.999.0.0&amp;vd_source=8683b4f3e93da577cf9216975b225ee5</a></p>
<p><a target="_blank" rel="noopener" href="https://gist.github.com/mcarilli/376821aa1a7182dfcf59928a7cde3223">https://gist.github.com/mcarilli/376821aa1a7182dfcf59928a7cde3223</a></p>
<p><a target="_blank" rel="noopener" href="https://dev-discuss.pytorch.org/t/using-nsight-systems-to-profile-gpu-workload/59">https://dev-discuss.pytorch.org/t/using-nsight-systems-to-profile-gpu-workload/59</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43838785/article/details/122128452">https://blog.csdn.net/weixin_43838785/article/details/122128452</a></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nsys profile -w true -t cuda,nvtx,cudnn,cublas --capture-<span class="built_in">range</span>=cudaProfilerApi --capture-<span class="built_in">range</span>-end=stop --cudabacktrace=true -x true -o diagnose python <span class="number">0303.</span>py</span><br><span class="line">nsys stats xxx.nsys-rep</span><br><span class="line">nsys nvprof</span><br></pre></td></tr></table></figure>

<h4 id="2-Pytorch"><a href="#2-Pytorch" class="headerlink" title="2.Pytorch"></a>2.Pytorch</h4><p>dynamo 基础接口: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/620163218">https://zhuanlan.zhihu.com/p/620163218</a></p>
<p>isnan&#x2F;isinf.any()</p>
<p>debug memory leaks: <a target="_blank" rel="noopener" href="https://discuss.pytorch.org/t/how-to-debug-causes-of-gpu-memory-leaks/6741/23?page=2">https://discuss.pytorch.org/t/how-to-debug-causes-of-gpu-memory-leaks/6741/23?page=2</a></p>
<p>cuda context: <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_38973721/article/details/129400066">https://blog.csdn.net/qq_38973721/article/details/129400066</a></p>
<p>BN1d &amp; 2d: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/664143309">https://zhuanlan.zhihu.com/p/664143309</a></p>
<p>源码编译: </p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">RUN <span class="built_in">cd</span> pytorch &amp;&amp; \</span><br><span class="line">    CUDA_HOME=&quot;/usr/local/cuda&quot; \</span><br><span class="line">    CMAKE_PREFIX_PATH=&quot;$(dirname $(which conda))/../&quot; \</span><br><span class="line">    NCCL_INCLUDE_DIR=&quot;/usr/include/&quot; \</span><br><span class="line">    NCCL_LIB_DIR=&quot;/usr/lib/&quot; \</span><br><span class="line">    USE_SYSTEM_NCCL=<span class="number">1</span> \</span><br><span class="line">    USE_OPENCV=<span class="number">1</span> \</span><br><span class="line">    pip install --no-cache-<span class="built_in">dir</span> -v .</span><br></pre></td></tr></table></figure>

<p>ncclUniqueId: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/614746112">https://zhuanlan.zhihu.com/p/614746112</a></p>
<p>Undefined Symobl: pybind11::detail::type_caster&lt;at::Tensor, void&gt;::load(pybind11::handle, bool): <a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/issues/108041">https://github.com/pytorch/pytorch/issues/108041</a></p>
<p>CUDA Error: device not ready: <a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/issues/85796Error">https://github.com/pytorch/pytorch/issues/85796Error</a>: Open MPI has detected that this process has attempted to initialize MPI (via MPI_INIT or MPI_INIT_THREAD) more than once.  This is erroneous.<br>torch docker: <a target="_blank" rel="noopener" href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch/tags?quick-deploy=false">https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch/tags?quick-deploy=false</a><br>Allow previously initialized: <a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/pull/105023/files">https://github.com/pytorch/pytorch/pull/105023/files</a></p>
<p>torch显存机制分析: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/424512257">https://zhuanlan.zhihu.com/p/424512257</a></p>
<p>repeat, repeat_interleave, tile的用法: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/474153365">https://zhuanlan.zhihu.com/p/474153365</a></p>
<p>offset, stride: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/101434655">https://zhuanlan.zhihu.com/p/101434655</a></p>
<p>torch fx 调研和实践:  <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/654834182">https://zhuanlan.zhihu.com/p/654834182</a></p>
<p>2.0 Graph Capture: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/644590863">https://zhuanlan.zhihu.com/p/644590863</a></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">flag = torch.lt(x.<span class="built_in">sum</span>(), <span class="number">0</span>)</span><br><span class="line"><span class="keyword">return</span> flag * (x + <span class="number">1</span>) + (<span class="number">1</span> - flag) * (x - <span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>gather &amp; scatter_: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/187401278">https://zhuanlan.zhihu.com/p/187401278</a></p>
<p>底层代码走读：<a target="_blank" rel="noopener" href="https://www.zhihu.com/column/c_1475072340581617664">https://www.zhihu.com/column/c_1475072340581617664</a></p>
<p>clone copy detach data：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/393041305">https://zhuanlan.zhihu.com/p/393041305</a></p>
<p>pad：<a target="_blank" rel="noopener" href="https://blog.csdn.net/jorg_zhao/article/details/105295686">https://blog.csdn.net/jorg_zhao/article/details/105295686</a></p>
<p>CUDA_LAUNCH_BLOCKING&#x3D;1 pyinstrument –show-all train_CRN.py</p>
<p>Function<strong>一般只定义一个操作</strong>，因为其无法保存参数，因此适用于激活函数、pooling等操作；Module是保存了参数，因此适合于定义一层，如线性层，卷积层，也适用于定义一个网络</p>
<p>简单架构源码：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/598044604">https://zhuanlan.zhihu.com/p/598044604</a></p>
<p>动态图原理：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/598291307">https://zhuanlan.zhihu.com/p/598291307</a> 如何将文件导出成动态库libmyop.so？</p>
<p>numba自定义function：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/582978353">https://zhuanlan.zhihu.com/p/582978353</a></p>
<p>TorchDynamo初探（字节码）：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/589115427">https://zhuanlan.zhihu.com/p/589115427</a></p>
<p>嵌套list,tensor,ndarray互转：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_38703529/article/details/120216078">https://blog.csdn.net/qq_38703529/article/details/120216078</a></p>
<p>clamp梯度为0 (mask)：<a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/issues/7002">https://github.com/pytorch/pytorch/issues/7002</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/blob/53fe804322640653d2dddaed394838b868ce9a26/torch/autograd/_functions/pointwise.py#L95">https://github.com/pytorch/pytorch/blob/53fe804322640653d2dddaed394838b868ce9a26/torch/autograd/_functions/pointwise.py#L95</a></p>
<p>libtorch安装及简单使用：<a target="_blank" rel="noopener" href="http://zhaoxuhui.top/blog/2021/04/13/libtorch-installation-and-use.html">http://zhaoxuhui.top/blog/2021/04/13/libtorch-installation-and-use.html</a></p>
<p>转置卷积：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/115070523">https://zhuanlan.zhihu.com/p/115070523</a></p>
<p>DDP详细流程： <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/178402798">https://zhuanlan.zhihu.com/p/178402798</a></p>
<p>DDP各卡GPU不均匀：<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/351342218/answer/867293468">https://www.zhihu.com/question/351342218/answer/867293468</a></p>
<p>torch.utils.benchmark：<a target="_blank" rel="noopener" href="https://runebook.dev/zh/docs/pytorch/benchmark_utils">https://runebook.dev/zh/docs/pytorch/benchmark_utils</a></p>
<p>bn vs LN： <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/113233908">https://zhuanlan.zhihu.com/p/113233908</a></p>
<p>F.embedding： <a target="_blank" rel="noopener" href="https://blog.csdn.net/rouge_eradiction/article/details/124288799">https://blog.csdn.net/rouge_eradiction/article/details/124288799</a></p>
<p>bmm：<a target="_blank" rel="noopener" href="https://blog.csdn.net/foneone/article/details/103876519">https://blog.csdn.net/foneone/article/details/103876519</a></p>
<p>baddbmm： <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.baddbmm.html">https://pytorch.org/docs/stable/generated/torch.baddbmm.html</a></p>
<p>trril_： <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_38406029/article/details/122059507">https://blog.csdn.net/qq_38406029/article/details/122059507</a></p>
<p>repeat： <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_34806812/article/details/89388210">https://blog.csdn.net/qq_34806812/article/details/89388210</a></p>
<p>stack： <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/354177500">https://zhuanlan.zhihu.com/p/354177500</a></p>
<p>torch.utils.checkpoint:  <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/455541708">https://zhuanlan.zhihu.com/p/455541708</a></p>
<p>​                                          <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/checkpoint.html">https://pytorch.org/docs/stable/checkpoint.html</a></p>
<p>​                                          <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/615122110">https://zhuanlan.zhihu.com/p/615122110</a></p>
<p>apply, _apply： <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/340453841">https://zhuanlan.zhihu.com/p/340453841</a></p>
<p>einsum： <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/361209187">https://zhuanlan.zhihu.com/p/361209187</a></p>
<p>​                  <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/44954540">https://zhuanlan.zhihu.com/p/44954540</a></p>
<h4 id="3-Python-1"><a href="#3-Python-1" class="headerlink" title="3.Python"></a>3.Python</h4><p>setuptools详解: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/460233022">https://zhuanlan.zhihu.com/p/460233022</a></p>
<p>alternative 切换 python 版本: </p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/15948314">https://zhuanlan.zhihu.com/p/15948314</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_17105473/article/details/120909679">https://blog.csdn.net/qq_17105473/article/details/120909679</a></p>
<p>jupyter-remote: </p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_36603177/article/details/132117549">https://blog.csdn.net/qq_36603177/article/details/132117549</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_40641725/article/details/114636779">https://blog.csdn.net/weixin_40641725/article/details/114636779</a></p>
<p>locust: <a target="_blank" rel="noopener" href="https://github.com/InternLM/lmdeploy/issues/304">https://github.com/InternLM/lmdeploy/issues/304</a></p>
<p>fire: <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_17550379/article/details/79943740">https://blog.csdn.net/qq_17550379/article/details/79943740</a></p>
<p>time: <a target="_blank" rel="noopener" href="https://blog.csdn.net/chenxy_bwave/article/details/119458690">https://blog.csdn.net/chenxy_bwave/article/details/119458690</a></p>
<p>Uvicorn ERROR: Exception in ASGI application: 与py脚本名字xxx对齐 xxx:app</p>
<p>Nginx负载均衡: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/134220193">https://zhuanlan.zhihu.com/p/134220193</a></p>
<p>int(os.environ[‘OMPI_COMM_WORLD_SIZE’]): <a target="_blank" rel="noopener" href="https://lambdalabs.com/blog/multi-node-pytorch-distributed-training-guide">https://lambdalabs.com/blog/multi-node-pytorch-distributed-training-guide</a></p>
<p>locals() -局部变量的字典   globals() -全局变量的字典</p>
<p>mpi4py基本使用: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/441259590">https://zhuanlan.zhihu.com/p/441259590</a></p>
<p>mpi4py多进程并行: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/25332041">https://zhuanlan.zhihu.com/p/25332041</a></p>
<p>类方法，静态方法: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/28010894">https://zhuanlan.zhihu.com/p/28010894</a></p>
<p>ClientOSError: <a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/70448419/how-to-retry-async-requests-upon-clientoserror-errno-104-connection-reset-by">https://stackoverflow.com/questions/70448419/how-to-retry-async-requests-upon-clientoserror-errno-104-connection-reset-by</a></p>
<p>nohup: <a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_42840933/article/details/85780125">https://blog.csdn.net/weixin_42840933/article/details/85780125</a></p>
<p>einsum: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/361209187">https://zhuanlan.zhihu.com/p/361209187</a> 出现在右的自由索引与只出现在左的求和索引</p>
<p>打包参数 拆分参数: <a target="_blank" rel="noopener" href="https://blog.csdn.net/qdPython/article/details/118220244">https://blog.csdn.net/qdPython/article/details/118220244</a></p>
<p>函数默认参数一定要设定为不可变参数: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/34395671">https://zhuanlan.zhihu.com/p/34395671</a></p>
<p>可变对象地址不变 所以改变a b也跟着变 不可变对象改变其中之一 地址发生变化 另一个则不会变</p>
<p>可变对象: list dict set  不可变对象: tuple string int float bool</p>
<p><code>*args, **kwargs</code> 这是一个非常常见的捕获<strong>不定长位置参数</strong>与<strong>不定长关键字参数</strong>的方式</p>
<p>repr vs str: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/542320058">https://zhuanlan.zhihu.com/p/542320058</a></p>
<p>filter(function or None, iterable) # 可迭代对象(例如序列、字典等)</p>
<p>猴子补丁: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/577415129">https://zhuanlan.zhihu.com/p/577415129</a></p>
<p>__slot__: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/578699693">https://zhuanlan.zhihu.com/p/578699693</a></p>
<p>值传递与引用传递: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/578152117">https://zhuanlan.zhihu.com/p/578152117</a></p>
<p>正则表达式：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/91689180">https://zhuanlan.zhihu.com/p/91689180</a></p>
<p>new vs init：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/shenxiaolin/p/9307496.html">https://www.cnblogs.com/shenxiaolin/p/9307496.html</a></p>
<p>装饰器：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/45458873">https://zhuanlan.zhihu.com/p/45458873</a></p>
<p>functools.wraps：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/45535784">https://zhuanlan.zhihu.com/p/45535784</a></p>
<p>types：<a target="_blank" rel="noopener" href="https://docs.python.org/zh-cn/3/library/types.html">https://docs.python.org/zh-cn/3/library/types.html</a></p>
<p>惰性求值：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/420508064">https://zhuanlan.zhihu.com/p/420508064</a></p>
<p>Unittest：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/466076772">https://zhuanlan.zhihu.com/p/466076772</a></p>
<p><code>__all__</code>：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/54274339%EF%BC%8C%E5%9C%A8%E6%A8%A1%E5%9D%97%E7%BA%A7%E5%88%AB%E6%9A%B4%E9%9C%B2%E6%8E%A5%E5%8F%A3%EF%BC%8C%E7%BB%B4%E6%8A%A4%E5%8F%AF%E8%A7%81%E6%80%A7">https://zhuanlan.zhihu.com/p/54274339，在模块级别暴露接口，维护可见性</a></p>
<p>@contextlib.contextmanager：<a target="_blank" rel="noopener" href="https://blog.csdn.net/l1l1l1l/article/details/92702773">https://blog.csdn.net/l1l1l1l/article/details/92702773</a></p>
<p>traceback：<a target="_blank" rel="noopener" href="https://blog.csdn.net/yuanfate/article/details/119916008">https://blog.csdn.net/yuanfate/article/details/119916008</a></p>
<p><strong>类方法让类模板具有记忆力</strong></p>
<p>@classmethod：</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/leviopku/article/details/100745811">https://blog.csdn.net/leviopku/article/details/100745811</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/20021164/answer/132619179">https://www.zhihu.com/question/20021164/answer/132619179</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/544021480">https://zhuanlan.zhihu.com/p/544021480</a></p>
<p>Cython基本用法：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/24311879">https://zhuanlan.zhihu.com/p/24311879</a></p>
<p>setuptools：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/460233022">https://zhuanlan.zhihu.com/p/460233022</a></p>
<p>递归导入：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/565665251">https://zhuanlan.zhihu.com/p/565665251</a></p>
<p>pyplot：<a target="_blank" rel="noopener" href="https://blog.csdn.net/mighty13/article/details/116547892">https://blog.csdn.net/mighty13/article/details/116547892</a></p>
<p>抽象类：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/302275431">https://zhuanlan.zhihu.com/p/302275431</a></p>
<p>​               <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/508700685">https://zhuanlan.zhihu.com/p/508700685</a></p>
<p>mro：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/de7d38c84443">https://www.jianshu.com/p/de7d38c84443</a></p>
<p>super和父类没有实质性的关联；super(cls, inst)获得的是cls在inst的MRO列表中下一个类</p>
<p>*,**作用： <a target="_blank" rel="noopener" href="https://www.cnblogs.com/mo-nian/p/11842422.html">https://www.cnblogs.com/mo-nian/p/11842422.html</a></p>
<p>元组逗号作用：<a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_50218564/article/details/115057043">https://blog.csdn.net/m0_50218564/article/details/115057043</a></p>
<p>dataclass: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/419778289">https://zhuanlan.zhihu.com/p/419778289</a></p>
<h4 id="4-Python扩展"><a href="#4-Python扩展" class="headerlink" title="4.Python扩展"></a>4.Python扩展</h4><p>自定义算子参考：<a target="_blank" rel="noopener" href="https://github.com/Abyssaledge/TorchEx/tree/main/torchex">https://github.com/Abyssaledge/TorchEx/tree/main/torchex</a></p>
<p>Pytorch底层算子扩展总结：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/349560723">https://zhuanlan.zhihu.com/p/349560723</a></p>
<p>ncrelu：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/350651297">https://zhuanlan.zhihu.com/p/350651297</a></p>
<p>cpp_extension：<a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/advanced/cpp_extension.html">https://pytorch.org/tutorials/advanced/cpp_extension.html</a></p>
<p>pytorch自定义op：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/166501660">https://zhuanlan.zhihu.com/p/166501660</a></p>
<p>原位操作：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/81c602f6466b">https://www.jianshu.com/p/81c602f6466b</a></p>
<p>ctx.save_for_backward : 保留反向传播需要的信息</p>
<p>clone()可以返回完全相同的tensor,新的tensor开辟新的内存，tensor仍然留在计算图中</p>
<p>detach() 函数返回完全相同的tensor，新的tensor与旧的tensor共享内存，新的tensor脱离计算图(不会有梯度计算，梯度只流向原始的tensor，in-place操作会出错)；data() 是共用同一块内存，不在计算图中，但不安全，可以做in-place 操作</p>
<p>自定义PyThon&#x2F;C++(CUDA)算子方法总结：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/158643792">https://zhuanlan.zhihu.com/p/158643792</a> </p>
<p>使用python扩展pytorch：<a target="_blank" rel="noopener" href="https://pytorch.org/docs/master/notes/extending.html">https://pytorch.org/docs/master/notes/extending.html</a></p>
<p>pybind11：<a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/advanced/cpp_extension.html">https://pytorch.org/tutorials/advanced/cpp_extension.html</a></p>
<p>pybind11安装：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/80884925">https://zhuanlan.zhihu.com/p/80884925</a></p>
<p>pybind11(配合官方文档答疑)：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/192974017">https://zhuanlan.zhihu.com/p/192974017</a></p>
<p>示例：<a target="_blank" rel="noopener" href="https://github.com/CivilNet/SYSZUXav">https://github.com/CivilNet/SYSZUXav</a>  着重 Python.h说明 + 继承示例 + 函数返回值和传参时</p>
<p>候的内存处理</p>
<p>C++前端介绍：<a target="_blank" rel="noopener" href="https://pytorch.org/cppdocs/frontend.html">https://pytorch.org/cppdocs/frontend.html</a></p>
<p>安装：<a target="_blank" rel="noopener" href="https://pytorch.org/cppdocs/installing.html">https://pytorch.org/cppdocs/installing.html</a></p>
<h2 id="2024"><a href="#2024" class="headerlink" title="2024"></a>2024</h2><h4 id="1-Pytorch-1"><a href="#1-Pytorch-1" class="headerlink" title="1.Pytorch"></a>1.Pytorch</h4><p>分布式训练代码层面: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/483656352">https://zhuanlan.zhihu.com/p/483656352</a></p>
<p>TFLite只支持same valid padding: <a target="_blank" rel="noopener" href="https://blog.csdn.net/ch206265/article/details/115298414">https://blog.csdn.net/ch206265/article/details/115298414</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/06/27/assets/Confused/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/06/27/assets/Confused/" class="post-title-link" itemprop="url">Confused</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-06-27 10:57:54" itemprop="dateCreated datePublished" datetime="2022-06-27T10:57:54+08:00">2022-06-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-27 10:13:55" itemprop="dateModified" datetime="2022-11-27T10:13:55+08:00">2022-11-27</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>女生素颜能漂亮到什么程度？ - 一个勺子的回答 - 知乎 <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/305888519/answer/636137849">https://www.zhihu.com/question/305888519/answer/636137849</a></p>
<p>你认为怎样的女孩才算是“可爱？”？ - 知乎 <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/266398947/answer/307244871">https://www.zhihu.com/question/266398947/answer/307244871</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">要论一个女孩可爱的话，首先我觉得她得美好——善良，聪明，宽容，勇敢，独立自主，既能圆滑处事，又有自己锋利的原则。</span><br><span class="line">我不认为那些——整天显得很单纯，很幼稚，说话有点嗲，娇滴滴的，很会撒娇，说自己是小仙女，看起来弱弱的想让人保护却又念着“要坚强哦”实际上内心空乏脆弱——的女孩子就是可爱，反而让我觉得她们做作，虚假。</span><br><span class="line">我觉得一个真正可爱的女孩，她会低调，会不屑于博得人的目光，会深沉，会不急于表现自己，会不刻意表现自己。而她的可爱，只有能与她站在一起的人，才能看到、懂得。</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/343516892/answers/updated">有一个大学同学，每年都会准时发生日快乐，连续6年，但是除了生日快乐也没有再多闲聊。这是什么情况? - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/311405000/answers/updated">认识了6年的男孩，每一年都准时12点和我说生日快乐,然后闲聊几句就没了，他到底是什么想法? - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/311497395/answers/updated">认识6年,几乎没什么见面, 但他却每年都12点和我说生日快乐, 然后闲聊几句,我和他有没有发展的可能? - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/347423988/answers/updated">那个男孩又和我说了生日快乐，我们已经8年没见面了,他去了外国念书，这个算是爱情吗? - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/438222464/answers/updated">想问问大家，那些一直不聊天，只在生日时发生日快乐或新年时发新年快乐的朋友是怎么想的呀？ - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/38430655/answers/updated">你曾喜欢过的男生很久没联系，但他记得你生日还发来祝福，他这是什么心理？ - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/376273564/answers/updated">一个女生记得你的生日说明什么？ - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/378186135/answers/updated">有个很长时间不联系的朋友祝我生日快乐该怎么回？ - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/441238603/answers/updated">现在表白还来得及吗? - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/484871280/answers/updated?page=1">同班同学，平常没有什么交集，但是我生日那天晚上他给我发消息祝我生日快乐，是对我有意思吗? - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/395184501/answers/updated">喜欢一个人，但许久未曾联系，是自己的高中同学，该怎么做？ - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/383615012/answers/updated">一个女孩在你生日0.00整给你发生日祝福，什么意思？ - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/497828504/answers/updated">有必要为很久未联系的异性朋友送生日祝福吗? - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/507720488">异性好友每年会祝我生日快乐？ - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/507720488/answers/updated">好友每年都会会祝我生日快乐？ - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/530896617/answers/updated">一个女孩在你生日0.00整给你发生日祝福,什么意思？ - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/496929585/answers/updated">请问一个男生很多年了都会记得我的生日，这代表了什么呢? - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/311497395/answers/updated">认识6年,几乎没什么见面, 但他却每年都12点和我说生日快乐, 然后闲聊几句,我和他有没有发展的可能?</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/06/27/CV/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/06/27/CV/" class="post-title-link" itemprop="url">CV</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-06-27 10:30:42" itemprop="dateCreated datePublished" datetime="2022-06-27T10:30:42+08:00">2022-06-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-02-06 12:52:45" itemprop="dateModified" datetime="2024-02-06T12:52:45+08:00">2024-02-06</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><a target="_blank" rel="noopener" href="https://paperswithcode.com/sota/object-detection-on-coco?p=swin-transformer-v2-scaling-up-capacity-and">https://paperswithcode.com/sota/object-detection-on-coco?p=swin-transformer-v2-scaling-up-capacity-and</a></p>
<p>Attention: <a target="_blank" rel="noopener" href="https://github.com/xmu-xiaoma666/External-Attention-pytorch">https://github.com/xmu-xiaoma666/External-Attention-pytorch</a></p>
<p>Transformer问题汇总：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/266695736">https://zhuanlan.zhihu.com/p/266695736</a></p>
<p>CV：<a target="_blank" rel="noopener" href="https://github.com/WZMIAOMIAO/deep-learning-for-image-processing">https://github.com/WZMIAOMIAO/deep-learning-for-image-processing</a></p>
<h5 id="图像分类："><a href="#图像分类：" class="headerlink" title="图像分类："></a>图像分类：</h5><h5 id="kaggle-的-木薯叶分类-不同疾病下叶子的特征（ViT夺冠）"><a href="#kaggle-的-木薯叶分类-不同疾病下叶子的特征（ViT夺冠）" class="headerlink" title="kaggle 的 木薯叶分类   不同疾病下叶子的特征（ViT夺冠）"></a>kaggle 的 木薯叶分类   不同疾病下叶子的特征（ViT夺冠）</h5><p>1.model: 分类网络 efficientb0 b1  倍率代表卷积核个数 输入分辨率</p>
<p>   <strong>resnet</strong> 残差模块 梯度消失梯度爆炸 退化问题 </p>
<p>   残差结构 shortcut：$1\times 1$卷积降维,$3\times3$卷积, $1\times1$升维</p>
<p>   <strong>resnext</strong> 组卷积(对输入的fm，卷积核的channel进行分组，降低参数) </p>
<p>   <strong>mobilenet</strong> 利用 DW+PW 将分组卷积应用到极致，即网络的分组数与网络的channel数量相等，使网络的计算量减到最低，channel之间的交互由 point-wise                        </p>
<p>​                        conv,即使用1x1的卷积进行channel之间的融合来进行补充。</p>
<p>   <strong>V2</strong> 倒残差结构 $Relu6(x)&#x3D;min(max(0,x),6)$ ReLU丢失低微特征信息</p>
<p>   <strong>V3</strong> SE模块（squeeze &amp; excitation）</p>
<p>   <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_42617455/article/details/108165206">SE模块详解_Mounsey的博客-CSDN博客_se模块</a></p>
<p>   S : fm上执行GAP（替代MLP 每个channel输出一个 all像素点的平均值）,fm被压缩为$1\times1\times C$ 的向量</p>
<p>   E：两个FC（1&#x2F;4），两个激活函数，bottleneck结构；训练fm中每个channel的权重，</p>
<p>​         加权后的fm作为下一层网络的input</p>
<p>​         hard-s: $x\frac{ReLU6(x+3)}{6}$  NAS搜参</p>
<p>   <strong>shufflenet</strong> 针对组卷积缺乏通道间的信息传递</p>
<p>   <strong>V2</strong> 4准则</p>
<p>   <strong>efficientnet</strong> 权衡分辨率 宽高 SE 改用Swish Sigmoid&#x3D;$x\sigma(x)$ </p>
<p>  训练尺寸大时速度慢 DWC逐元素慢 同等放大是次优的</p>
<p>   <strong>V2</strong> Fused-MBConv ：融合了DW卷积，SE模块，dropout</p>
<p>  <strong>Swin Transformer</strong>：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37541097/article/details/121119988">https://blog.csdn.net/qq_37541097/article/details/121119988</a></p>
<p>  Patch Merging，W-MSA，SW-MSA，相对位置偏移</p>
<p>  <strong>ConvNeXt</strong>：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37541097/article/details/122556545">https://blog.csdn.net/qq_37541097/article/details/122556545</a></p>
<p>2.图像增强：</p>
<p>   <strong>albumentations</strong> ：基于OpenCV的快速训练数据增强库 可以使用 one of 组合 随机选择</p>
<p>   <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/107399127/">albumentations 数据增强工具的使用 - 知乎 (zhihu.com)</a></p>
<p>   其他增强：mixup cutmix cutout fmix snapmix</p>
<p>   <a target="_blank" rel="noopener" href="https://blog.csdn.net/sinat_36618660/article/details/101633504">数据增强之mixup算法详解_sinat_36618660的博客-CSDN博客_mixup</a></p>
<p>  <a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_38715903/article/details/103999227">【论文阅读笔记】CutMix：数据增强_花噜噜酱的博客-CSDN博客_cutmix</a></p>
<p>   对裁剪区域的边界框采样，作为对AB两张图裁剪区域的标定：</p>
<p>   采样公式：$r_x\sim U(0,W),r_w&#x3D;W\sqrt{1-\lambda}$  ，裁剪区域面积作为权重</p>
<p>   <a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_42990464/article/details/105933992">数据增强之FMix_海里的羊的博客-CSDN博客</a></p>
<p>   <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/89ce7fdb9e12">图像的傅里叶变换 - 简书 (jianshu.com)</a></p>
<p>   <strong>Fmix</strong>: 利用掩膜来定义图像哪部分需要被考虑，对傅里叶空间采样的低频图像进行阈值处理从而去除噪声边界点，<br>              因此能从图像中剪切出任意形状的部分，将其粘贴到相关图像上</p>
<p>   <a target="_blank" rel="noopener" href="https://blog.csdn.net/kuweicai/article/details/111877458">数据增强（Data Augmentation）系列： SnapMix 原理及应用_生命在于折腾！-CSDN博客</a></p>
<p>   生成 label 的时候，直接在原图中以被 cut 掉的面积作为权重不合理 计算每个 pixel 对标签的贡献度</p>
<p>   首先计算输入图像的 CAM（Class Activation Mapping），归一化得到 SPM进行标签融合</p>
<p>   $CAM(I_i)&#x3D;\phi(\sum_{l&#x3D;0}^dw_{y_i}^lF_l(I_i))$ 输入图片 上采样(分类权重$\times$fm)</p>
<p>3.优化器：adam + sgd 组合  &#x2F;  5折交叉验证 sgd </p>
<p>   学习率：带重启的余弦退火 公式: $\eta_t&#x3D;\eta_{min}+\frac{1}{2}(1+\cos(\frac{T_{cur}}{T_i}\pi))$ 前几个epoch大学习率</p>
<p>   ReduceLROnPlateau在发现loss不再降低或者acc不再提高之后，降低学习率</p>
<p>4.<strong>Focal loss</strong>：降低易分样本的权重，提高难分样本的权重 也能解决目标检测中样本不均衡</p>
<p>   <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/113716961">Focal loss及多分类任务实现 - 知乎 (zhihu.com)</a></p>
<p>   $FL(p_t)&#x3D;-\alpha(1-p_t)^{\gamma}\log(p_t)$ 概率较大的样本 趋近于0 $\alpha$提高误分类样本的权重</p>
<p>   **label smoothing **：提高模型泛化能力；降低迭代次数  onehot的微调</p>
<p>   <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/302843504">Label Smoothing分析 - 知乎 (zhihu.com)</a></p>
<p>5.Grad-CAM：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37541097/article/details/123089851">https://blog.csdn.net/qq_37541097/article/details/123089851</a></p>
<h5 id="目标检测："><a href="#目标检测：" class="headerlink" title="目标检测："></a>目标检测：</h5><p><strong>1.RCNN</strong>(CNN攻克目标检测的开山之作)</p>
<p>   selective search算法生成1-2k个候选区域，</p>
<p>   <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/27467369">目标检测（1）-Selective Search - 知乎 (zhihu.com)</a></p>
<p>   将图像分割成很多很多的小块  合并规则如下：</p>
<p>   颜色、纹理相近；合并后总面积最小；合并后的与其所属gt边界框boundng box公共面积大的</p>
<p>   依次对区域用CNN做特征提取经过各个类别的SVM，来判别是否属于该类</p>
<p>   <strong>NMS非极大值抑制</strong>：detection输出个数未知$\rightarrow$提高召回率</p>
<p>   一看就懂：<a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_37605642/article/details/98358864">https://blog.csdn.net/m0_37605642/article/details/98358864</a></p>
<p>   召回率：指模型找到所有某类目标的能力（所有标注的真实边界框有多少被预测出来了）</p>
<p>   $Recall&#x3D;\frac{TP}{TP+FN}$</p>
<p>   <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/78504109">非极大值抑制Non-Maximum Suppression（NMS）一文搞定理论+多平台实现 - 知乎 (zhihu.com)</a></p>
<p>   寻找得分最高的目标，计算与其他目标的iou，删除所有iou大于给定阈值的目标</p>
<p>   回归器修正候选框位置：最小二乘法 线性回归  得到bounding box</p>
<p>   不足：RoI获取慢；特征提取慢</p>
<p><strong>2.Fast RCNN</strong>（解决特征提取慢）</p>
<p>   图像输入网络得到fm，将ss生成的候选框投影到fm上 得到相应的特征矩阵</p>
<p>   通过ROI pooling 矩阵缩放到7$\times$7，展平后送入fc预测</p>
<p>   <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/73138740">ROI Pooling和ROI Align - 知乎 (zhihu.com)</a></p>
<p>   优点：一次性计算全图特征，不限制输入尺寸</p>
<p>   正负样本：1张图 采64个region 16个采自IoU&gt;0.5,&lt;0.1标记为负样本</p>
<p>   边界框回归器 输出N+1个类别 4个回归参数$d_x,d_y,d_w,d_h$ </p>
<p>   分类损失+回归损失 $smooth_{L_1}(x)&#x3D;0.5x^2, |x|-0.5$</p>
<p><strong>3.Faster RCNN</strong></p>
<p>   图像输入CNN网络得到fm</p>
<p>   <strong>RPN</strong>生成候选框region proposals，softmax判断属于正负样本，再利用bounding box regression修正  </p>
<p>   anchors获得精确的proposals</p>
<p>   ROI 收集输入的fm和proposals 提取proposal fm ，送入fc分类</p>
<p>   利用 proposal fm 计算 proposal类别，再次bbr得到最终定位</p>
<p>   Fast-RCNN</p>
<p>   <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/59186710">Faster RCNN之RPN理解 - 知乎 (zhihu.com)</a></p>
<p>   <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/49897496">学一百遍都不算多的 Faster-RCNN - 知乎 (zhihu.com)</a></p>
<p>   <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/31426458"> 一文读懂Faster RCNN - 知乎 (zhihu.com)</a>(<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/49897496">https://zhuanlan.zhihu.com/p/49897496</a>)</p>
<p>   RPN来 proposal ROI  原论文3尺度3比例 每个位置在原图对应9个anchor（候选窗口）</p>
<p>   在一个滑动窗口上生成不同大小和长宽比例的anchor box，取定IoU的阈值来标定这些ab的正负。与gt有</p>
<p>   最大IoU的或者&gt;0.7的为正。</p>
<p>   于是传入RPN网络的样本数据被整理为anchor box 坐标 和 每个anchor box是否有物体（二分类标签）</p>
<p>   RPN网络将每个样本映射为一个概率值和四个坐标值，概率值表示anchor box有物体的概率，坐标值用</p>
<p>   于回归定义物体的位置。最后将二分类和坐标回归的损失统一起来，作为RPN网络的目标训练。</p>
<p>   由RPN得到Region Proposal在根据概率值筛选后经过类似的标记过程，被传入Fast RCNN子网络，进行</p>
<p>   多分类和坐标回归，同样用多任务损失将二者的损失联合训练。</p>
<p><strong>4.YOLO</strong></p>
<p>   <a target="_blank" rel="noopener" href="https://blog.csdn.net/litt1e/article/details/88907542">一文看懂YOLO v3_litt1e的博客-CSDN博客_yolov3</a></p>
<p>   <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/74540100">【论文解读】Yolo三部曲解读——Yolov2 - 知乎 (zhihu.com)</a></p>
<p>   <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/76802514">【论文解读】Yolo三部曲解读——Yolov3 - 知乎 (zhihu.com)</a></p>
<p>   <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/94799295">IoU、GIoU、DIoU、CIoU损失函数的那点事儿 - 知乎 (zhihu.com)</a></p>
<p>   Yolov5: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/183838757">https://zhuanlan.zhihu.com/p/183838757</a></p>
<p>   改进实践：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/509295685">https://zhuanlan.zhihu.com/p/509295685</a></p>
<p><strong>5.FCOS</strong>：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37541097/article/details/124844726?spm=1001.2014.3001.5502">https://blog.csdn.net/qq_37541097/article/details/124844726?spm=1001.2014.3001.5502</a></p>
<p><strong>6.注释</strong></p>
<p>   anchor box其实就是从训练集的所有ground truth box中统计(使用k-means)出来的在训练集中最经常出现的几个box形状和尺寸</p>
<p>   anchor指人为初始给的先验框，一般在二阶段检测器的RPN阶段或者在一阶段检测器中设置</p>
<p>   proposal指的是二阶段方法中RPN的输出框，也就是对anchor第一次做回归得到的结果</p>
<p>   ROI指RPN阶段输出的proposal经过排序取topk，然后做nms取一定数量的框，用于第二阶段的再次精</p>
<p>   修；在RCNN ，Fast RCNN方法中指通过选择性搜索生成的框</p>
<p>   bounding box指proposal经过再次精修后的预测框</p>
<p><strong>7.其他补充：</strong></p>
<p>边界框概率分布：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/151398233">https://zhuanlan.zhihu.com/p/151398233</a></p>
<p>IOU收罗：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/151914931">https://zhuanlan.zhihu.com/p/151914931</a></p>
<p>Neck选择：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/342011052">https://zhuanlan.zhihu.com/p/342011052</a></p>
<p>NMS汇总: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/157900024">https://zhuanlan.zhihu.com/p/157900024</a></p>
<p>目标检测backbone，neck，head：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/93451942">https://zhuanlan.zhihu.com/p/93451942</a></p>
<p>MAP特别清楚：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/3dfb43aaa14c">https://www.jianshu.com/p/3dfb43aaa14c</a></p>
<p>目标检测中的mAP: </p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/53405779/answer/429585383">https://www.zhihu.com/question/53405779/answer/429585383</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/53405779/answer/506000532">https://www.zhihu.com/question/53405779/answer/506000532</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/53405779/answer/2481182203">https://www.zhihu.com/question/53405779/answer/2481182203</a></p>
<p>FN：False Negative,被判定为负样本，但事实上是正样本<br>FP：False Positive,被判定为正样本，但事实上是负样本<br>TN：True Negative,被判定为负样本，事实上也是负样本<br>TP：True Positive,被判定为正样本，事实上也正样本</p>
<h5 id="语义分割："><a href="#语义分割：" class="headerlink" title="语义分割："></a>语义分割：</h5><p>转置卷积：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37541097/article/details/120709865">https://blog.csdn.net/qq_37541097/article/details/120709865</a></p>
<p>膨胀卷积：<a target="_blank" rel="noopener" href="https://blog.csdn.net/tracelessle/article/details/106114975">https://blog.csdn.net/tracelessle/article/details/106114975</a></p>
<p>DeepLabV2：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37541097/article/details/121752679">https://blog.csdn.net/qq_37541097/article/details/121752679</a> (ASPP)</p>
<p>DeepLabV3：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37541097/article/details/121797301">https://blog.csdn.net/qq_37541097/article/details/121797301</a></p>
<h5 id="实例分割："><a href="#实例分割：" class="headerlink" title="实例分割："></a>实例分割：</h5><p>分离对象的前景与背景</p>
<p><strong>1.Mask-RCNN：</strong></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37541097/article/details/123754766">https://blog.csdn.net/qq_37541097/article/details/123754766</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/407831250">https://zhuanlan.zhihu.com/p/407831250</a></p>
<p>RoIAlign替代RoIPool</p>
<p>mask：像素是否是目标的一部分</p>
<p>FCN从每一个ROI中预测出一个m*m大小的mask，这使得mask分支中的每个层能够明确的保持m×m空间布局;预测K个输出意在允许每个类都生成独立的掩膜，避免类间竞争，这样做解耦了掩膜和种类预测。</p>
<p>对于每一个ROI，mask分支有Km*m维度的输出，其对K个大小为m*m的mask进行编码，每一个mask有K个类别，即K个分辨率为m*m的二值的掩膜</p>
<p>FCN卷积化：是指图像语义分割的输出是个分割结果图，是二维数据</p>
<p>FPN: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/397293649">https://zhuanlan.zhihu.com/p/397293649</a></p>
<p>综述：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/412675982">https://zhuanlan.zhihu.com/p/412675982</a></p>
<p><strong>2.Yolact：</strong></p>
<p>每个anchor产生4+c+k个系数</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/137915508">https://zhuanlan.zhihu.com/p/137915508</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/wh8514/article/details/105520870/">https://blog.csdn.net/wh8514/article/details/105520870/</a> 注意原图的mask不是固定的138*138</p>
<p> <a target="_blank" rel="noopener" href="https://blog.csdn.net/sinat_37532065/article/details/89415374">https://blog.csdn.net/sinat_37532065/article/details/89415374</a></p>
<p>YOLACT wiz TensorRT: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/339079249">https://zhuanlan.zhihu.com/p/339079249</a></p>
<p><strong>3.SOLO：</strong></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/148056969">https://zhuanlan.zhihu.com/p/148056969</a></p>
<p>以具有挑战性的MS COCO数据集为例：</p>
<p>验证子集中总共有36780个对象，其中98.3％的对象对的中心距离大于30个像素。至于其余的1.7％的对象对，其中40.5％的大小比率大于1.5倍。在这里，我们不考虑像X形两个物体这样的少数情况。总之，<strong>在大多数情况下，图像中的两个实例要么具有不同的中心位置，要么具有不同的对象大小</strong>。这一发现使我们怀疑是否可以通过中心位置和对象大小直接区分实例？</p>
<p>类比FCN每个输出通道负责一个语义类别（包括背景），语义分割旨在区分不同的语义类别；</p>
<p>SOLO的每个输出通道负责一个中心位置类别，并且相应的通道图应预测属于该类别的对象的实例蒙版。因此，结构几何信息自然以高度乘宽度的尺寸保存在空间矩阵中。</p>
<p>通过将每个像素分类到其实例类别中，等效于使用回归从每个像素预测对象中心</p>
<p>对于每个网格，我们的SOLO都会预测 C 维输出以指示语义类别概率，其中C是类别数。这些概率取决于网格单元。如果将输入图像划分为 S×S 网格，则输出空间将为 S×S×C 。</p>
<p>此设计基于以下假设： S×S 网格的每个单元必须属于一个单独的实例，因此仅属于一个语义类别。在推理期间， C 维输出指示每个对象实例的类概率。</p>
<p>如果对象的中心落入网格单元，则该网格单元负责1）预测语义类别以及2）分割该对象实例。</p>
<p><strong>4.SOLOv2</strong>: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/120263670">https://zhuanlan.zhihu.com/p/120263670</a>   &lt;-  Matrix nms</p>
<p>SoftNMS：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/165048317">https://zhuanlan.zhihu.com/p/165048317</a></p>
<p>转NCNN：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/400734462">https://zhuanlan.zhihu.com/p/400734462</a></p>
<p>​                   <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/361900997">https://zhuanlan.zhihu.com/p/361900997</a></p>
<p><strong>关键点检测：</strong></p>
<p>HRNet：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37541097/article/details/124346626">https://blog.csdn.net/qq_37541097/article/details/124346626</a></p>
<h3 id="Deploy"><a href="#Deploy" class="headerlink" title="Deploy"></a>Deploy</h3><h4 id="1-ONNX"><a href="#1-ONNX" class="headerlink" title="1.ONNX"></a>1.ONNX</h4><p>onnxsurgeon: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/664242857">https://zhuanlan.zhihu.com/p/664242857</a></p>
<p>custom op onnx export ：<a target="_blank" rel="noopener" href="https://github.com/onnx/tutorials/blob/master/PyTorchCustomOperator/README.md">https://github.com/onnx/tutorials/blob/master/PyTorchCustomOperator/README.md</a></p>
<p>打印node：<a target="_blank" rel="noopener" href="https://blog.csdn.net/u011622208/article/details/122260965">https://blog.csdn.net/u011622208/article/details/122260965</a></p>
<p>add node attribute: <a target="_blank" rel="noopener" href="https://github.com/onnx/onnx/issues/3546">https://github.com/onnx/onnx/issues/3546</a></p>
<p>tutorial: <a target="_blank" rel="noopener" href="https://github.com/onnx/tutorials/blob/master/PyTorchCustomOperator/README.md">https://github.com/onnx/tutorials/blob/master/PyTorchCustomOperator/README.md</a></p>
<h4 id="2-TensorRT"><a href="#2-TensorRT" class="headerlink" title="2.TensorRT"></a>2.TensorRT</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import pycuda.autoinit</span><br></pre></td></tr></table></figure>

<p>builder,engine,context简介：<a target="_blank" rel="noopener" href="https://blog.csdn.net/tengxunbc/article/details/116613328">https://blog.csdn.net/tengxunbc/article/details/116613328</a></p>
<p>[defaultAllocator.cpp::deallocate] Cuda Runtime (invalid argument)：<a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/issues/2052">https://github.com/NVIDIA/TensorRT/issues/2052</a></p>
<p>Error Code 1: Myelin (Compiled against cuBLASLt 10.2.2.0 but running against cuBLASLt 11.4.2.0.)：<a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/issues/1945">https://github.com/NVIDIA/TensorRT/issues/1945</a></p>
<p>最简python推理：<a target="_blank" rel="noopener" href="https://blog.csdn.net/JianguoChow/article/details/122684310">https://blog.csdn.net/JianguoChow/article/details/122684310</a></p>
<p>简单ResNet50：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/395590559">https://zhuanlan.zhihu.com/p/395590559</a></p>
<p>动态：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/548006090">https://zhuanlan.zhihu.com/p/548006090</a></p>
<p>​           <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/387853124">https://zhuanlan.zhihu.com/p/387853124</a></p>
<p>​           <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/299845547">https://zhuanlan.zhihu.com/p/299845547</a> （相应评论区）</p>
<p>C++接口解读：<a target="_blank" rel="noopener" href="https://blog.csdn.net/hjxu2016/article/details/109288673">https://blog.csdn.net/hjxu2016/article/details/109288673</a></p>
<p>int8量化配置撰写可参考：<a target="_blank" rel="noopener" href="https://github.com/ihongxx/Resnet50_TensorRT">https://github.com/ihongxx/Resnet50_TensorRT</a></p>
<p>YOLOv5 trt：<a target="_blank" rel="noopener" href="https://github.com/PICOPON/yolov5_engine">https://github.com/PICOPON/yolov5_engine</a></p>
<p>​                       <a target="_blank" rel="noopener" href="https://github.com/ihongxx/Yolov5_TensorRt">https://github.com/ihongxx/Yolov5_TensorRt</a></p>
<p>YOLOv7 &amp; others trt：<a target="_blank" rel="noopener" href="https://github.com/shouxieai/tensorRT_Pro">https://github.com/shouxieai/tensorRT_Pro</a></p>
<p>bilibili：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Xw411f7FW?p=4&vd_source=8683b4f3e93da577cf9216975b225ee5">https://www.bilibili.com/video/BV1Xw411f7FW?p=4&amp;vd_source=8683b4f3e93da577cf9216975b225ee5</a></p>
<p>TensorRT Plug-in：<a target="_blank" rel="noopener" href="https://github.com/wang-xinyu/tensorrtx">https://github.com/wang-xinyu/tensorrtx</a></p>
<p>TensorRT 简易：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/547624036">https://zhuanlan.zhihu.com/p/547624036</a></p>
<p>async vs sync：<a target="_blank" rel="noopener" href="https://gist.github.com/CasiaFan/c8a380aabdc08e1fdcf6310c78431106">https://gist.github.com/CasiaFan/c8a380aabdc08e1fdcf6310c78431106</a></p>
<p>dynamic输入trt报错：<a target="_blank" rel="noopener" href="https://blog.csdn.net/XCCCCZ/article/details/123009816">https://blog.csdn.net/XCCCCZ/article/details/123009816</a></p>
<h4 id="3-HAWP"><a href="#3-HAWP" class="headerlink" title="3.HAWP"></a>3.HAWP</h4><p>modes：<a target="_blank" rel="noopener" href="https://jetsonhacks.com/2017/03/25/nvpmodel-nvidia-jetson-tx2-development-kit/">https://jetsonhacks.com/2017/03/25/nvpmodel-nvidia-jetson-tx2-development-kit/</a></p>
<p>clock：<a target="_blank" rel="noopener" href="https://docs.nvidia.com/jetson/archives/r34.1/DeveloperGuide/text/SD/Clocks.html?highlight=clock%20frequency">https://docs.nvidia.com/jetson/archives/r34.1/DeveloperGuide/text/SD/Clocks.html?highlight=clock%20frequency</a></p>
<p>SpeedUp：<a target="_blank" rel="noopener" href="https://forums.developer.nvidia.com/t/extremely-slow-inference-in-tensorrt-for-live-semantic-segmentation-model/204266/7">https://forums.developer.nvidia.com/t/extremely-slow-inference-in-tensorrt-for-live-semantic-segmentation-model/204266/7</a></p>
<p>lower under continuous：<a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/issues/2042">https://github.com/NVIDIA/TensorRT/issues/2042</a></p>
<p>​                                               <a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/issues/2107">https://github.com/NVIDIA/TensorRT/issues/2107</a></p>
<p>Synchronize：<a target="_blank" rel="noopener" href="https://forums.developer.nvidia.com/t/understanding-stream-synchronization-with-trt-inference/143810">https://forums.developer.nvidia.com/t/understanding-stream-synchronization-with-trt-inference/143810</a></p>
<p>execute_async：<a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/issues/930">https://github.com/NVIDIA/TensorRT/issues/930</a></p>
<p>Cupy：<a target="_blank" rel="noopener" href="https://github.com/cupy/cupy/issues/6104">https://github.com/cupy/cupy/issues/6104</a></p>
<h4 id="4-Nvidia-Orin"><a href="#4-Nvidia-Orin" class="headerlink" title="4.Nvidia Orin"></a>4.Nvidia Orin</h4><p>Docker：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/553091318">https://zhuanlan.zhihu.com/p/553091318</a></p>
<p>Deepstream：<a target="_blank" rel="noopener" href="https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_Overview.html">https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_Overview.html</a></p>
<p>​                          <a target="_blank" rel="noopener" href="https://github.com/marcoslucianops/DeepStream-Yolo">https://github.com/marcoslucianops/DeepStream-Yolo</a></p>
<p>Jetson-inference：<a target="_blank" rel="noopener" href="https://github.com/dusty-nv/jetson-inference">https://github.com/dusty-nv/jetson-inference</a></p>
<p>trt whl zoo：<a target="_blank" rel="noopener" href="https://blog.csdn.net/kunhe0512/article/details/124993478">https://blog.csdn.net/kunhe0512/article/details/124993478</a></p>
<p>查看 jetpack version：sudo apt-cache show nvidia-jetpack</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">7</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
